== BasicOperators

`BasicOperators` is a `Strategy` of link:spark-sql-SparkPlanner.adoc[SparkPlanner] and link:spark-sql-queryplanner.adoc#HiveSessionState[Hive-specific `QueryPlanner`] that in most cases simply translates link:spark-sql-LogicalPlan.adoc[logical operators] to their link:spark-sql-catalyst-SparkPlan.adoc[physical counterparts].

.``BasicOperators``'s Logical to Physical Operator Mapping
[frame="topbot",options="header",width="100%"]
|======================
| Logical Operator | Physical Operator
| `RunnableCommand` | `ExecutedCommandExec`
| `MemoryPlan` | `LocalTableScanExec`
| `DeserializeToObject` | `DeserializeToObjectExec`
| `SerializeFromObject` | `SerializeFromObjectExec`
| `MapPartitions` | `MapPartitionsExec`
| `MapElements` | `MapElementsExec`
| `AppendColumns` | `AppendColumnsExec`
| `AppendColumnsWithObject` | `AppendColumnsWithObjectExec`
| `MapGroups` | `MapGroupsExec`
| `CoGroup` | `CoGroupExec`
| `Repartition` (with shuffle enabled) | link:spark-sql-spark-plan-ShuffleExchange.adoc[ShuffleExchange]
| `Repartition` | link:spark-sql-spark-plan-CoalesceExec.adoc[CoalesceExec]
| `SortPartitions` | `SortExec`
| `Sort` | `SortExec`
| `Project` | `ProjectExec`
| `Filter` | `FilterExec`
| `TypedFilter` | `FilterExec`
| `Expand` | `ExpandExec`
| `Window` | `WindowExec`
| `Sample` | `SampleExec`
| `LocalRelation` | `LocalTableScanExec`
| `LocalLimit` | `LocalLimitExec`
| `GlobalLimit` | `GlobalLimitExec`
| `Union` | `UnionExec`
| `Generate` | `GenerateExec`
| `OneRowRelation` | `RDDScanExec`
| `Range` | `RangeExec`
| `RepartitionByExpression` | link:spark-sql-spark-plan-ShuffleExchange.adoc[ShuffleExchange]
| `ExternalRDD` | `ExternalRDDScanExec`
| `LogicalRDD` | `RDDScanExec`
| `BroadcastHint` | `PlanLater`
|======================

TIP: Confirm the operator mapping in the link:++https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala#L321++[source code of `BasicOperators`].

NOTE: `BasicOperators` expects that `Distinct`, `Intersect`, and `Except` logical operators are not used in a link:spark-sql-LogicalPlan.adoc[logical plan] and throws a `IllegalStateException` if not.
