== YarnRMClient

`YarnRMClient` is responsible for registering and unregistering a Spark application with the *YARN ResourceManager* (aka _RM_).

NOTE: YARN ResourceManager http://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/index.html[manages the global assignment of compute resources to applications], e.g. memory, cpu, disk, network, etc.

=== [[allocateResources]] allocateResources

CAUTION: FIXME

=== [[register]] Registering ApplicationMaster with YARN ResourceManager (register method)

[source, scala]
----
register(
  driverUrl: String,
  driverRef: RpcEndpointRef,
  conf: YarnConfiguration,
  sparkConf: SparkConf,
  uiAddress: String,
  uiHistoryAddress: String,
  securityMgr: SecurityManager,
  localResources: Map[String, LocalResource]): YarnAllocator
----

`register` registers the application master with the YARN ResourceManager. It creates a link:spark-yarn-YarnAllocator.adoc[YarnAllocator] that...FIXME

=== [[unregister]] unregister method

=== [[getMaxRegAttempts]] Maximum Number of Attempts to Register ApplicationMaster (getMaxRegAttempts method)

[source, scala]
----
getMaxRegAttempts(sparkConf: SparkConf, yarnConf: YarnConfiguration): Int
----

`getMaxRegAttempts` uses link:spark-configuration.adoc[SparkConf] and YARN's https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/conf/YarnConfiguration.html[YarnConfiguration] to read configuration settings and return the maximum number of application attempts before registering link:spark-yarn-applicationmaster.adoc[ApplicationMaster] with YARN is considered unsuccessful (and hence the entire Spark application afterwards).

It reads YARN's `yarn.resourcemanager.am.max-attempts` (available as https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/conf/YarnConfiguration.html#RM_AM_MAX_ATTEMPTS[YarnConfiguration.RM_AM_MAX_ATTEMPTS]) or falls back to https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/conf/YarnConfiguration.html#DEFAULT_RM_AM_MAX_ATTEMPTS[YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS] (which is `2`).

The return value is the minimum of the configuration settings of YARN and Spark.

=== [[getAttemptId]] Getting ApplicationAttemptId of Spark Application (getAttemptId method)

[source, scala]
----
getAttemptId(): ApplicationAttemptId
----

`getAttemptId` returns YARN's `ApplicationAttemptId` (of the Spark application to which the container was assigned).

Internally, it uses YARN-specific methods like link:spark-yarn-YarnSparkHadoopUtil.adoc#getContainerId[ConverterUtils.toContainerId] and https://hadoop.apache.org/docs/current/api/index.html?org/apache/hadoop/yarn/client/api/YarnClient.html[ContainerId.getApplicationAttemptId].
