== YarnRMClient

`YarnRMClient` is responsible for registering and unregistering a Spark application with the *YARN ResourceManager* (aka _RM_).

NOTE: YARN ResourceManager http://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/index.html[manages the global assignment of compute resources to applications], e.g. memory, cpu, disk, network, etc.

[TIP]
====
Enable `INFO` logging level for `org.apache.spark.deploy.yarn.YarnRMClient` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.deploy.yarn.YarnRMClient=INFO
```

Refer to link:spark-logging.adoc[Logging].
====

=== [[register]] Registering ApplicationMaster with YARN ResourceManager (register method)

When link:spark-yarn-applicationmaster.adoc#registerAM[registering `ApplicationMaster`] (for a Spark application) with the YARN ResourceManager, Spark uses `register`.

[source, scala]
----
register(
  driverUrl: String,
  driverRef: RpcEndpointRef,
  conf: YarnConfiguration,
  sparkConf: SparkConf,
  uiAddress: String,
  uiHistoryAddress: String,
  securityMgr: SecurityManager,
  localResources: Map[String, LocalResource]): YarnAllocator
----

`register` instantiates YARN's https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/client/api/AMRMClient.html[AMRMClient], initializes it (using `conf` input parameter) and starts immediately. It saves `uiHistoryAddress` input parameter internally for later use.

You should see the following INFO message in the logs (in stderr in YARN):

```
INFO YarnRMClient: Registering the ApplicationMaster
```

It then link:++https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/client/api/AMRMClient.html#registerApplicationMaster(java.lang.String, int, java.lang.String)++[registers the application master] using the local host, port `0`, and `uiAddress` input parameter for the URL at which the master info can be seen.

The internal `registered` flag is enabled.

Ultimately, it link:spark-yarn-YarnAllocator.adoc#creating-instance[creates a new `YarnAllocator`] with the input parameters of `register` passed in and the just-created YARN https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/client/api/AMRMClient.html[AMRMClient].

=== [[unregister]] unregister method

=== [[getMaxRegAttempts]] Maximum Number of Attempts to Register ApplicationMaster (getMaxRegAttempts method)

[source, scala]
----
getMaxRegAttempts(sparkConf: SparkConf, yarnConf: YarnConfiguration): Int
----

`getMaxRegAttempts` uses link:spark-configuration.adoc[SparkConf] and YARN's https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/conf/YarnConfiguration.html[YarnConfiguration] to read configuration settings and return the maximum number of application attempts before registering link:spark-yarn-applicationmaster.adoc[ApplicationMaster] with YARN is considered unsuccessful (and hence the entire Spark application afterwards).

It reads YARN's `yarn.resourcemanager.am.max-attempts` (available as https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/conf/YarnConfiguration.html#RM_AM_MAX_ATTEMPTS[YarnConfiguration.RM_AM_MAX_ATTEMPTS]) or falls back to https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/conf/YarnConfiguration.html#DEFAULT_RM_AM_MAX_ATTEMPTS[YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS] (which is `2`).

The return value is the minimum of the configuration settings of YARN and Spark.

=== [[getAttemptId]] Getting ApplicationAttemptId of Spark Application (getAttemptId method)

[source, scala]
----
getAttemptId(): ApplicationAttemptId
----

`getAttemptId` returns YARN's `ApplicationAttemptId` (of the Spark application to which the container was assigned).

Internally, it uses YARN-specific methods like link:spark-yarn-YarnSparkHadoopUtil.adoc#getContainerId[ConverterUtils.toContainerId] and https://hadoop.apache.org/docs/current/api/index.html?org/apache/hadoop/yarn/client/api/YarnClient.html[ContainerId.getApplicationAttemptId].
