== [[Expression]] Expression -- Executable Node in Catalyst Tree

`Expression` is a executable link:spark-sql-catalyst-TreeNode.adoc[node] (in a Catalyst tree) that can be <<eval, evaluated>> to a value given input values, i.e. can produce a JVM object per `InternalRow` (in a link:spark-sql-Dataset.adoc[Dataset]).

`Expression` can <<genCode, generate a Java source code>> that is then used in evaluation.

[[specialized-expressions]]
.Specialized Expressions
[cols="1,2,2,1",options="header",width="100%"]
|===
| Name
| Scala Kind
| Behaviour
| Examples

| [[BinaryExpression]] `BinaryExpression`
| abstract class
|
a|

* link:spark-sql-Expression-UnixTimestamp.adoc[UnixTimestamp]

| [[CodegenFallback]] `CodegenFallback`
| trait
|
|

| [[ExpectsInputTypes]] `ExpectsInputTypes`
| trait
|
|

| [[LeafExpression]] `LeafExpression`
| abstract class
| Has no link:spark-sql-catalyst-TreeNode.adoc#children[child expressions] (and hence "terminates" the expression tree).
a|

* link:spark-sql-Expression-Attribute.adoc[Attribute]
* link:spark-sql-Expression-Literal.adoc[Literal]

| [[NamedExpression]] `NamedExpression`
|
| Can later be referenced in a dataflow graph.
|

| <<Nondeterministic, Nondeterministic>>
| trait
|
|

| [[NonSQLExpression]] `NonSQLExpression`
| trait
| Expression with no SQL representation

Gives the only custom <<sql, sql>> method that is non-overridable (i.e. `final`).

When requested <<sql, SQL representation>>, `NonSQLExpression` transforms link:spark-sql-Expression-Attribute.adoc[Attributes] to be ``PrettyAttribute``s to build text representation.
a|

* link:spark-sql-Expression-ImperativeAggregate-ScalaUDAF.adoc[ScalaUDAF]
* link:spark-sql-Expression-StaticInvoke.adoc[StaticInvoke]
* link:spark-sql-Expression-TimeWindow.adoc[TimeWindow]

| [[TernaryExpression]] `TernaryExpression`
| abstract class
|
|

| [[TimeZoneAwareExpression]] `TimeZoneAwareExpression`
| trait
| Timezone-aware expressions
a|

* link:spark-sql-Expression-UnixTimestamp.adoc[UnixTimestamp]
* link:spark-sql-Expression-JsonToStructs.adoc[JsonToStructs]

| [[UnaryExpression]] `UnaryExpression`
| abstract class
|
a|

* link:spark-sql-Expression-Generator.adoc#ExplodeBase[ExplodeBase]
* link:spark-sql-Expression-JsonToStructs.adoc[JsonToStructs]

| [[Unevaluable]] `Unevaluable`
| trait
| Cannot be evaluated, i.e. <<eval, eval>> and <<doGenCode, doGenCode>> are not supported and report an `UnsupportedOperationException`.

Replaced by some other expressions during link:spark-sql-Analyzer.adoc[analysis] or link:spark-sql-Optimizer.adoc[optimization].

a|

* link:spark-sql-Expression-AggregateExpression.adoc[AggregateExpression]
* `CurrentDatabase`
* link:spark-sql-Expression-TimeWindow.adoc[TimeWindow]
* link:spark-sql-Expression-WindowExpression.adoc[WindowExpression]
* link:spark-sql-Expression-WindowSpecDefinition.adoc[WindowSpecDefinition]
|===

=== [[contract]] Expression Contract

[source, scala]
----
abstract class Expression extends TreeNode[Expression] {
  // only required methods with no implementation
  def nullable: Boolean
  def eval(input: InternalRow = null): Any
  def doGenCode(ctx: CodegenContext, ev: ExprCode): ExprCode
  def dataType: DataType
}
----

.(Subset of) Expression Contract (in alphabetical order)
[cols="1,2",options="header",width="100%"]
|===
| Method
| Description

| [[canonicalized]] `canonicalized`
|

| [[checkInputDataTypes]] `checkInputDataTypes`
|

| [[childrenResolved]] `childrenResolved`
|

| [[dataType]] `dataType`
|

| [[deterministic]] `deterministic`
|

| [[doGenCode]] `doGenCode`
| Generates a Java source code (that is used to <<eval, evaluate the expression>>).

Used as part of <<genCode, genCode>>.

| [[eval]] `eval`
a| Evaluates the expression to a JVM object for a given link:spark-sql-InternalRow.adoc[InternalRow].

NOTE: By default accepts `EmptyRow`, i.e. `null`.

| [[foldable]] `foldable`
|

| [[genCode]] `genCode`
| Generates a Java source code (that is used to <<eval, evaluate the expression>>).

Similar to <<doGenCode, doGenCode>> but supports expression reuse (aka _subexpression elimination_).

| [[nullable]] `nullable`
|

| [[prettyName]] `prettyName`
|

| [[references]] `references`
|

| [[resolved]] `resolved`
|

| [[semanticEquals]] `semanticEquals`
|

| [[semanticHash]] `semanticHash`
|

| [[sql]] `sql`
a| SQL representation

<<prettyName, prettyName>> followed by `sql` of link:spark-sql-catalyst-TreeNode.adoc#children[children] in the round brackets and concatenated using the comma (`,`), e.g.

```
import org.apache.spark.sql.catalyst.dsl.expressions._
import org.apache.spark.sql.catalyst.expressions.Sentences
val sentences = Sentences("Hi there! Good morning.", "en", "US")

import org.apache.spark.sql.catalyst.expressions.Expression
val expr: Expression = count("*") === 5 && count(sentences) === 5
scala> expr.sql
res0: String = ((count('*') = 5) AND (count(sentences('Hi there! Good morning.', 'en', 'US')) = 5))
```
|===

=== [[Nondeterministic]] `Nondeterministic` Expression

`Nondeterministic` expressions are non-deterministic and non-<<foldable, foldable>>, i.e. `deterministic` and `foldable` properties are disabled (i.e. `false`). They require explicit initialization before evaluation.

`Nondeterministic` expressions have two additional methods:

1. `initInternal` for internal initialization (called before `eval`)
2. `evalInternal` to ``eval``uate a link:spark-sql-InternalRow.adoc[InternalRow] into a JVM object.

NOTE: `Nondeterministic` is a Scala trait.

`Nondeterministic` expressions have the additional `initialized` flag that is enabled (i.e. `true`) after the other additional `initInternal` method has been called.

Examples of `Nondeterministic` expressions are `InputFileName`, `MonotonicallyIncreasingID`, `SparkPartitionID` functions and the abstract `RDG` (that is the base for `Rand` and `Randn` functions).

NOTE: `Nondeterministic` expressions are the target of `PullOutNondeterministic` logical plan rule.
