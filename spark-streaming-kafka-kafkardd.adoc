== KafkaRDD

`KafkaRDD` class represents a link:spark-rdd.adoc[RDD dataset] from Apache Kafka. It uses `KafkaRDDPartition` for partitions that know their preferred locations as the host of the topic (not port however!). It then nicely maps a RDD partition to a Kafka partition.

TIP: Studying `KafkaRDD` class can greatly improve understanding of Spark (core) in general, i.e. how RDDs are used for distributed computations.

`KafkaRDD` overrides methods of `RDD` class to base them on `offsetRanges`, i.e. partitions.

You can create `KafkaRDD` using `KafkaUtils.createRDD(sc: SparkContext, kafkaParams: Map[String, String], offsetRanges: Array[OffsetRange])`.

[TIP]
====
Enable `INFO` logging level for `org.apache.spark.streaming.kafka.KafkaRDD` logger to see what happens in KafkaRDD.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.streaming.kafka.KafkaRDD=INFO
```
====

=== [[compute]] compute

To `compute` a partition, `KafkaRDD`, checks for validity of beginning and ending offsets (so they range over at least one element) and returns an (internal) `KafkaRDDIterator`.

You should see the following INFO message in the logs:

```
INFO Computing topic [topic], partition [partition] offsets [fromOffset] -> [toOffset]
```
