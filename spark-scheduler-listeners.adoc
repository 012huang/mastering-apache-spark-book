== Scheduler Listeners

=== [[events]] Events

A Spark listener can receive events about:

* when a stage completes successfully or fails
* when a stage is submitted
* when a task starts
* when a task begins remotely fetching its result
* when a task ends
* when a job starts
* when a job ends
* when environment properties have been updated
* when a new block manager has joined
* when an existing block manager has been removed
* when an RDD is manually unpersisted by the application
* when the application starts (as `SparkListenerApplicationStart`)
* when the application ends (as `SparkListenerApplicationEnd`)
* when the driver receives task metrics from an executor in a heartbeat.
* <<SparkListenerExecutorAdded, when the driver registers a new executor>> (FIXME or is this to let the driver know about the new executor?).
* when the driver removes an executor.
* when the driver receives a block update info.

* *SparkListenerEnvironmentUpdate*
* <<SparkListenerExecutorMetricsUpdate, SparkListenerExecutorMetricsUpdate>>

==== [[SparkListenerExecutorMetricsUpdate]] SparkListenerExecutorMetricsUpdate

`SparkListenerExecutorMetricsUpdate` triggers link:spark-SparkListener.adoc#SparkListenerInterface[SparkListenerInterface.onExecutorMetricsUpdate].

==== [[SparkListenerApplicationStart]] SparkListenerApplicationStart

FIXME

==== [[SparkListenerExecutorAdded]] SparkListenerExecutorAdded

`SparkListenerExecutorAdded` is posted as a result of:

* A `RegisterExecutor` event having been received by link:spark-scheduler-backends-coarse-grained.adoc[CoarseGrainedSchedulerBackend]

* Calling link:spark-mesos.adoc#MesosSchedulerBackend[MesosSchedulerBackend.resourceOffers].

* link:spark-local.adoc#LocalBackend[LocalBackend being started].

`SparkListenerExecutorAdded` is passed along to link:spark-SparkListener.adoc[SparkListeners] using `SparkListener.onExecutorAdded(executorAdded)` method.
