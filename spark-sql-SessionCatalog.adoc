== [[SessionCatalog]] SessionCatalog

`SessionCatalog` is a proxy between link:spark-sql-sparksession.adoc[SparkSession] and the underlying metastore, e.g. `HiveSessionCatalog`.

`SessionCatalog` <<creating-instance, is created>> when `SessionState` link:spark-sql-SessionState.adoc#catalog[sets `catalog`] (lazily).

You can access the `SessionCatalog` for a link:spark-sql-sparksession.adoc[SparkSession] through link:spark-sql-SessionState.adoc[SessionState].

[source, scala]
----
sparkSession.sessionState.catalog
----

=== [[lookupFunction]] `lookupFunction` Method

CAUTION: FIXME

=== [[functionExists]] `functionExists` Method

CAUTION: FIXME

=== [[alterTempViewDefinition]] `alterTempViewDefinition` Method

[source, scala]
----
alterTempViewDefinition(name: TableIdentifier, viewDefinition: LogicalPlan): Boolean
----

`alterTempViewDefinition` alters the temporary view by <<createTempView, updating an in-memory temporary table>> (when a database is not specified and the table has already been registered) or a global temporary table (when a database is specified and it is for global temporary tables).

NOTE: "Temporary table" and "temporary view" are synonyms.

`alterTempViewDefinition` returns `true` when an update could be executed and finished successfully.

=== [[createTempView]] `createTempView` Method

CAUTION: FIXME

=== [[createGlobalTempView]] `createGlobalTempView` Method

CAUTION: FIXME

=== [[createTable]] `createTable` Method

CAUTION: FIXME

=== [[alterTable]] `alterTable` Method

CAUTION: FIXME

=== [[creating-instance]] Creating SessionCatalog Instance

`SessionCatalog` takes the following when created:

* [[externalCatalog]] link:spark-sql-ExternalCatalog.adoc[ExternalCatalog]
* [[globalTempViewManager]] `GlobalTempViewManager`
* [[functionResourceLoader]] `FunctionResourceLoader`
* [[functionRegistry]] link:spark-sql-FunctionRegistry.adoc[FunctionRegistry]
* [[conf]] link:spark-sql-catalyst-CatalystConf.adoc[CatalystConf]
* [[hadoopConf]] Hadoop's https://hadoop.apache.org/docs/current/api/org/apache/hadoop/conf/Configuration.html[Configuration]
* [[parser]] link:spark-sql-sql-parsers.adoc#ParserInterface[ParserInterface]

`SessionCatalog` initializes the <<internal-registries, internal registries and counters>>.
