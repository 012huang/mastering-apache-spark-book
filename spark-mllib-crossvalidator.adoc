== CrossValidator

CAUTION: FIXME Needs more love to be finished, and looks as if I were crossing mostly-Scala boundary and entering a ML land (which I'm not prepared yet for).

`CrossValidator` is an link:spark-mllib-estimators.adoc[Estimator] for link:spark-mllib-models.adoc[CrossValidatorModel].

It belongs to `org.apache.spark.ml.tuning` package.

`CrossValidator` accepts `numFolds` parameter (amongst the others).

[source, scala]
----
import org.apache.spark.ml.tuning._
val cv = new CrossValidator

scala> println(cv.explainParams)
estimator: estimator for selection (undefined)
estimatorParamMaps: param maps for the estimator (undefined)
evaluator: evaluator used to select hyper-parameters that maximize the validated metric (undefined)
numFolds: number of folds for cross validation (>= 2) (default: 3)
seed: random seed (default: -1191137437)

import org.apache.spark.mllib.linalg._
val features = Vectors.sparse(3, Array(1), Array(1d))
val df = Seq((0, "hello world", 0.5, features)).toDF("id", "text", "label", "features")

import org.apache.spark.ml.classification._
val lr = new LogisticRegression

import org.apache.spark.ml.evaluation.RegressionEvaluator
val regEval = new RegressionEvaluator

val paramGrid = new ParamGridBuilder().build()
cv.setEstimatorParamMaps(paramGrid).setEstimator(lr).setEvaluator(regEval)

val model = cv.fit(df)

// FIXME
java.lang.UnsupportedOperationException: empty.max
  at scala.collection.TraversableOnce$class.max(TraversableOnce.scala:227)
  at scala.collection.AbstractTraversable.max(Traversable.scala:104)
  at org.apache.spark.ml.classification.MultiClassSummarizer.numClasses(LogisticRegression.scala:739)
  at org.apache.spark.ml.classification.MultiClassSummarizer.histogram(LogisticRegression.scala:743)
  at org.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:288)
  at org.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:261)
  at org.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:160)
  at org.apache.spark.ml.Predictor.fit(Predictor.scala:90)
  at org.apache.spark.ml.Predictor.fit(Predictor.scala:71)
  at org.apache.spark.ml.Estimator.fit(Estimator.scala:59)
  at org.apache.spark.ml.Estimator$$anonfun$fit$1.apply(Estimator.scala:78)
  at org.apache.spark.ml.Estimator$$anonfun$fit$1.apply(Estimator.scala:78)
  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
  at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
  at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
  at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
  at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
  at org.apache.spark.ml.Estimator.fit(Estimator.scala:78)
  at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:110)
  at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:105)
  at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
  at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
  at org.apache.spark.ml.tuning.CrossValidator.fit(CrossValidator.scala:105)
  ... 55 elided
----
