== SQL Parser Framework

*SQL Parser Framework* in Spark SQL uses ANTLR to parse a SQL text and then creates link:spark-sql-DataType.adoc[data types], Catalyst's link:spark-sql-catalyst-Expression.adoc[Expression], `TableIdentifier`, and link:spark-sql-LogicalPlan.adoc[LogicalPlan].

The contract of the SQL Parser Framework is described by <<ParserInterface, ParserInterface>> interface. The contract is then abstracted in link:spark-sql-AbstractSqlParser.adoc[AbstractSqlParser] class so subclasses have only to provide custom link:spark-sql-AstBuilder.adoc[AstBuilder].

There are two concrete implementations of `AbstractSqlParser`:

1. link:spark-sql-SparkSqlParser.adoc[SparkSqlParser] that is the default parser of the SQL expressions into Spark's types.
2. link:spark-sql-CatalystSqlParser.adoc[CatalystSqlParser] that is used to parse data types from their canonical string representation.

=== [[ParserInterface]] ParserInterface -- SQL Parser Contract

`ParserInterface` is the parser contract for extracting link:spark-sql-LogicalPlan.adoc[LogicalPlan], Catalyst `Expressions` (to create link:spark-sql-columns.adoc[Columns] from), and `TableIdentifiers` from a given SQL string.

[source, scala]
----
package org.apache.spark.sql.catalyst.parser

trait ParserInterface {
  def parsePlan(sqlText: String): LogicalPlan

  def parseExpression(sqlText: String): Expression

  def parseTableIdentifier(sqlText: String): TableIdentifier
}
----

It has the only single abstract subclass link:spark-sql-AbstractSqlParser.adoc[AbstractSqlParser].
