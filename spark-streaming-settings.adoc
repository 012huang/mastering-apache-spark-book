== Settings

The following list are the settings used to configure Spark Streaming applications.

* `spark.streaming.receiver.writeAheadLog.enable` (default: `false`) controls what link:spark-streaming-receivedblockhandlers.adoc[ReceivedBlockHandler] to use: `WriteAheadLogBasedBlockHandler` or `BlockManagerBasedBlockHandler`.

* `spark.streaming.receiver.blockStoreTimeout` (default: `30`) time in seconds to wait until both writes to a write-ahead log and BlockManager complete successfully.

* `spark.streaming.clock` (default: `org.apache.spark.util.SystemClock`) specifies a fully-qualified class name that extends `org.apache.spark.util.Clock` to mock time.

* `spark.streaming.ui.retainedBatches` (default: `1000`)
* `spark.streaming.checkpoint.directory`
* `spark.streaming.receiverRestartDelay` (default: `2000`) - the time interval between a receiver is stopped and started again.

* `spark.streaming.concurrentJobs` (default: `1`) is the number of concurrent jobs, i.e. threads in link:spark-streaming-jobscheduler.adoc#streaming-job-executor[streaming-job-executor thread pool].

* `spark.streaming.stopSparkContextByDefault` (default: `true`) controls whether (`true`) or not (`false`) to stop the underlying SparkContext (regardless of whether this `StreamingContext` has been started).
