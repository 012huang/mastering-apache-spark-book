== [[Aggregation]] Aggregation Execution Planning Strategy

`Aggregation` is an link:spark-sql-SparkStrategy.adoc[execution planning strategy] (of link:spark-sql-SparkPlanner.adoc[SparkPlanner]) that...FIXME

[source, scala]
----
val spark: SparkSession = ...
// structured query with count aggregate function
val q = spark.range(5).
  groupBy($"id" % 2 as "group").
  agg(count("id") as "count")

import q.queryExecution.optimizedPlan
scala> println(optimizedPlan.numberedTreeString)
00 Aggregate [(id#38L % 2)], [(id#38L % 2) AS group#41L, count(1) AS count#46L]
01 +- Range (0, 5, step=1, splits=Some(8))

import spark.sessionState.planner.Aggregation
scala> println(Aggregation.apply(optimizedPlan).head.numberedTreeString)
00 HashAggregate(keys=[(id#38L % 2)#66L], functions=[count(1)], output=[group#41L, count#46L])
01 +- HashAggregate(keys=[(id#38L % 2) AS (id#38L % 2)#66L], functions=[partial_count(1)], output=[(id#38L % 2)#66L, count#59L])
02    +- PlanLater Range (0, 5, step=1, splits=Some(8))
----

=== [[apply]] Executing Planning Strategy -- `apply` Method

[source, scala]
----
apply(plan: LogicalPlan): Seq[SparkPlan]
----

`apply`...FIXME

NOTE: `apply` is a part of link:spark-sql-catalyst-GenericStrategy.adoc#apply[GenericStrategy Contract] to execute a planning strategy.

=== [[PhysicalAggregation]][[PhysicalAggregation-unapply]] Destructuring Logical Plan -- `PhysicalAggregation.unapply` Method

[source, scala]
----
unapply(a: Any): Option[ReturnType]
----

`unapply` destructures a link:spark-sql-LogicalPlan.adoc[logical plan], i.e. breaks a `LogicalPlan` into pieces.

CAUTION: FIXME What pieces?

[NOTE]
====
`ReturnType` is a type alias (aka _type synonym_) for a 4-element tuple with grouping, aggregate and result link:spark-sql-Expression.adoc[expressions], and child link:spark-sql-LogicalPlan.adoc[logical operator].

[source, scala]
----
type ReturnType =
  (Seq[NamedExpression], Seq[AggregateExpression], Seq[NamedExpression], LogicalPlan)
----
====

NOTE: `PhysicalAggregation` is a Scala http://docs.scala-lang.org/tutorials/tour/extractor-objects.html[extractor object] with a single <<PhysicalAggregation-unapply, unapply>> method.

=== [[planAggregateWithOneDistinct]][[AggUtils-planAggregateWithOneDistinct]] `AggUtils.planAggregateWithOneDistinct` Method

CAUTION: FIXME

=== [[AggUtils-createAggregate]] Creating Aggregate Physical Operator Per Aggregate Expressions -- `AggUtils.createAggregate` Internal Method

[source, scala]
----
createAggregate(
  requiredChildDistributionExpressions: Option[Seq[Expression]] = None,
  groupingExpressions: Seq[NamedExpression] = Nil,
  aggregateExpressions: Seq[AggregateExpression] = Nil,
  aggregateAttributes: Seq[Attribute] = Nil,
  initialInputBufferOffset: Int = 0,
  resultExpressions: Seq[NamedExpression] = Nil,
  child: SparkPlan): SparkPlan
----

`createAggregate` creates a link:spark-sql-SparkPlan.adoc[physical operator] given the input `aggregateExpressions`.

.createAggregate and Selecting Physical Operator (in execution order)
[cols="1,2",options="header",width="100%"]
|===
| Operator
| Conditions (for selection)

| link:spark-sql-SparkPlan-HashAggregateExec.adoc[HashAggregateExec]
a| Builds a schema from link:spark-sql-Expression-AggregateFunction.adoc#aggBufferAttributes[aggBufferAttributes] (of every `AggregateFunction`) of every link:spark-sql-Expression-AggregateExpression.adoc[AggregateExpression] (in the input `aggregateExpressions`) and checks for any non-mutable fields (that _cannot_ be updated in place in link:spark-sql-UnsafeRow.adoc[UnsafeRows]). When not found, `HashAggregateExec` is selected.

Mutable field types include:

* `NullType`
* `BooleanType`
* `ByteType`
* `ShortType`
* `IntegerType`
* `LongType`
* `FloatType`
* `DoubleType`
* `DateType`
* `TimestampType`
* `DecimalType`

| `ObjectHashAggregateExec`
| When link:spark-sql-SQLConf.adoc#spark.sql.execution.useObjectHashAggregateExec[spark.sql.execution.useObjectHashAggregateExec] intenal flag enabled (it is by default) and `aggregateExpressions` contains at least one `TypedImperativeAggregate`.

| `SortAggregateExec`
| When all the above conditions fail.
|===

NOTE: `createAggregate` is used in <<AggUtils-planAggregateWithoutDistinct, AggUtils.planAggregateWithoutDistinct>>, <<AggUtils-planAggregateWithOneDistinct, AggUtils.planAggregateWithOneDistinct>> and `planStreamingAggregation` (for Structured Streaming's `StatefulAggregationStrategy`).

=== [[AggUtils]][[AggUtils-planAggregateWithoutDistinct]] `AggUtils.planAggregateWithoutDistinct` Method

[source, scala]
----
planAggregateWithoutDistinct(
  groupingExpressions: Seq[NamedExpression],
  aggregateExpressions: Seq[AggregateExpression],
  resultExpressions: Seq[NamedExpression],
  child: SparkPlan): Seq[SparkPlan]
----

`planAggregateWithoutDistinct` is a two-step physical operator generator.

`planAggregateWithoutDistinct` first <<AggUtils-createAggregate, creates an aggregate physical operator>> with `aggregateExpressions` in `Partial` mode.

In the end, `planAggregateWithoutDistinct` <<AggUtils-createAggregate, creates another aggregate physical operator>> with `aggregateExpressions` in `Final` mode and the first aggregate operator as the child.

NOTE: `planAggregateWithoutDistinct` is used exclusively when `Aggregation` execution planning strategy <<apply, is executed>> (with no `AggregateExpressions` being link:spark-sql-Expression-AggregateExpression.adoc#isDistinct[distinct]).
