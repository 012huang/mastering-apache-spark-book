== [[AbstractSqlParser]] AbstractSqlParser -- Base SQL Parsing Infrastructure

`AbstractSqlParser` is a base link:spark-sql-ParserInterface.adoc[ParserInterface] for the SQL parsing infrastructure in Spark SQL with <<implementations, two concrete implementations available>>.

[[implementations]]
.AbstractSqlParser's Implementations (in alphabetical order)
[width="100%",cols="1,2",options="header"]
|===
| Name
| Description

| link:spark-sql-SparkSqlParser.adoc[SparkSqlParser]
|

| link:spark-sql-CatalystSqlParser.adoc[CatalystSqlParser]
|
|===

`AbstractSqlParser` creates an layer of indirection and expects that subclasses provide custom link:spark-sql-AstBuilder.adoc[AstBuilder] (that is responsible for the final transformation of SQL strings into their Spark SQL equivalent entities, i.e. link:spark-sql-DataType.adoc[DataType], link:spark-sql-catalyst-Expression.adoc[Expression], link:spark-sql-LogicalPlan.adoc[LogicalPlan] or `TableIdentifier`).

`AbstractSqlParser` simply routes all the final parsing calls to translate a SQL string into a respective Spark SQL object to that custom `AstBuilder`.

When parsing a SQL string, `AbstractSqlParser` uses its own <<parse, parse>> method that sets up a proper ANTLR parsing infrastructure.

=== [[contract]] AbstractSqlParser Contract

[source, scala]
----
abstract class AbstractSqlParser extends ParserInterface {
  def astBuilder: AstBuilder
  def parse[T](command: String)(toResult: SqlBaseParser => T): T
  def parseDataType(sqlText: String): DataType
  def parsePlan(sqlText: String): LogicalPlan
  def parseExpression(sqlText: String): Expression
  def parseTableIdentifier(sqlText: String): TableIdentifier
  def parseTableSchema(sqlText: String): StructType
}
----

.AbstractSqlParser Contract (in alphabetical order)
[cols="1,2",options="header",width="100%"]
|===
| Method
| Description

| [[astBuilder]] `astBuilder`
| Gives link:spark-sql-AstBuilder.adoc[AstBuilder] for the final SQL parsing.

Used in all the `parse` methods, i.e. <<parseDataType, parseDataType>>, <<parseExpression, parseExpression>>, <<parsePlan, parsePlan>>, <<parseTableIdentifier, parseTableIdentifier>>, and <<parseTableSchema, parseTableSchema>>.

NOTE: Both <<implementations, implementations>>, i.e. link:spark-sql-SparkSqlParser.adoc[SparkSqlParser] and link:spark-sql-CatalystSqlParser.adoc[CatalystSqlParser], come with their own `astBuilder` method.

| <<parse, parse>>
| Used when...

| [[parseDataType]] `parseDataType`
| Used when...

| [[parseExpression]] `parseExpression`
| Used when...

| [[parsePlan]] `parsePlan`
a| Creates a link:spark-sql-LogicalPlan.adoc[LogicalPlan] for a given SQL textual statement.

`parsePlan` <<parse, builds a `SqlBaseParser`>> and requests <<astBuilder, AstBuilder>> to link:spark-sql-AstBuilder.adoc#visitSingleStatement[parse a single SQL statement].

When a SQL statement could not be parsed, `parsePlan` reports a `ParseException`:

```
Unsupported SQL statement
```

| [[parseTableIdentifier]] `parseTableIdentifier`
| Used when...

| [[parseTableSchema]] `parseTableSchema`
| Used when...
|===

=== [[parse]] `parse` Method

[source, scala]
----
parse[T](command: String)(toResult: SqlBaseParser => T): T
----

`parse` is a protected method that sets up a proper ANTLR parsing infrastructure with `SqlBaseLexer` and `SqlBaseParser` with are the ANTLR-specific classes of Spark SQL that are auto-generated at build time.

TIP: Review the definition of ANTLR grammar for Spark SQL in https://github.com/apache/spark/blob/master/sql/catalyst/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBase.g4[sql/catalyst/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBase.g4].

When called, `parse` prints out the following INFO message to the logs:

```
INFO SparkSqlParser: Parsing command: [command]
```

TIP: Enable `INFO` logging level for link:spark-sql-SparkSqlParser.adoc[SparkSqlParser] or link:spark-sql-CatalystSqlParser.adoc[CatalystSqlParser] to see the INFO message.
