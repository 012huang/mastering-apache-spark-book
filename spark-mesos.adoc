== Spark on Mesos

TODO:

* What does `spark.mesos.coarse=true` do?

*Coarse grain mode* pre-starts all the Spark executor backends, so has the least overhead comparing to *fine grain*.

From https://developer.ibm.com/bluemix/2015/09/09/four-reasons-pay-attention-to-apache-mesos/[Four reasons to pay attention to Apache Mesos]:

> Spark workloads can also be sensitive to the physical characteristics of the infrastructure, such as memory size of the node, access to fast solid state disk, or proximity to the data source.

> to run Spark workloads well you need a resource manager that not only can handle the rapid swings in load inherent in analytics processing, but one that can do to smartly. Matching of the task to the RIGHT resources is crucial and awareness of the physical environment is a must. Mesos is designed to manage this problem on behalf of workloads like Spark.

Review https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/cluster/mesos/MesosClusterScheduler.scala[MesosClusterScheduler.scala] class.

* There are some variables/properties used.
