== Spark on Mesos

From https://developer.ibm.com/bluemix/2015/09/09/four-reasons-pay-attention-to-apache-mesos/[Four reasons to pay attention to Apache Mesos]:

> Spark workloads can also be sensitive to the physical characteristics of the infrastructure, such as memory size of the node, access to fast solid state disk, or proximity to the data source.

> to run Spark workloads well you need a resource manager that not only can handle the rapid swings in load inherent in analytics processing, but one that can do to smartly. Matching of the task to the RIGHT resources is crucial and awareness of the physical environment is a must. Mesos is designed to manage this problem on behalf of workloads like Spark.

[CAUTION]
====
Review:

*  https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/cluster/mesos/MesosClusterScheduler.scala[MesosClusterScheduler.scala]
* MesosExternalShuffleService
====

=== Introduction to Mesos

* Mesos is _a scheduler of schedulers_
* Mesos is _a distributed systems kernel_
* Mesos essentially uses a container architecture but is abstracted enough to allow seamless execution of multiple, sometimes identical, distributed systems on the same architecture, minus the resource overhead of virtualization systems. This includes appropriate resource isolation while still allowing for data locality needed for frameworks like MapReduce.
* Mesos assigns jobs
* Mesos itself is really an additional layer of scheduling on top of application frameworks that each bring their own brand of scheduling. Application schedulers interface with a Mesos master setup in a familiar Zookeeper-coordinated active-passive architecture, which passes jobs down to compute slaves to run the application of choice.
* Mesos uses Zookeeper for master election and discovery. Apache Auroa is a scheduler that runs on Mesos.
* Mesos slaves, masters, schedulers, executors, tasks, frameworks
* Mesos makes use of event-driven message passing.
* Mesos is written in C++, not Java, and includes support for Docker along with other frameworks. Mesos, then, is the core of the Mesos Data Center Operating System, or DCOS, as it was coined by Mesosphere.
* This Operating System includes other handy components such as Marathon and Chronos. Marathon provides cluster-wide “init” capabilities for application in containers like Docker or cgroups. This allows one to programmatically automate the launching of large cluster-based applications. Chronos acts as a Mesos API for longer-running batch type jobs while the core Mesos SDK provides an entry point for other applications like Hadoop and Spark.
* The true goal is a full shared, generic and reusable on demand distributed architecture.
* https://mesosphere.com/infinity/[Infinity] to package and integrate the deployment of clusters
** Out of the box it will include Cassandra, Kafka, Spark, and Akka.
** an early access project
* Apache Myriad = Integrate YARN with Mesos
** making the execution of YARN work on Mesos scheduled systems transparent, multi-tenant, and smoothly managed
** to allow Mesos to centrally schedule YARN work via a Mesos based framework, including a REST API for scaling up or down
** includes a Mesos executor for launching the node manager
* Mesos frameworks
** Chronos, Spark, YARN (Myriad), Jenkins, Marathon
* Spark on Mesos supports link:spark-dynamic-allocation.adoc[dynamic allocation] in the Mesos coarse-grained scheduler

=== Schedulers in Mesos

* the coarse-grained scheduler
* `spark.mesos.coarse=true`

*Coarse grain mode* pre-starts all the Spark executor backends, so has the least overhead comparing to *fine grain*.

=== Commands

The following command is how you could execute a Spark application on Mesos:

```
./bin/spark-submit --master mesos://iq-cluster-master:5050 --total-executor-cores 2 --executor-memory 3G --conf spark.mesos.role=dev ./examples/src/main/python/pi.py 100
```
