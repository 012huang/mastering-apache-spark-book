== Whole-Stage Code Generation (aka Whole-Stage CodeGen)

NOTE: Review https://issues.apache.org/jira/browse/SPARK-12795[SPARK-12795 Whole stage codegen] to learn about the work to support it.

*Whole-Stage Code Generation* (aka _Whole-Stage CodeGen_) fuses multiple operators (as a subtree of plans that link:spark-sql-CodegenSupport.adoc[support code generation]) together into a single Java function that is aimed at improving execution performance. It collapses a query into a single optimized function that eliminates virtual function calls and leverages CPU registers for intermediate data.

NOTE: Whole-Stage Code Generation is enabled by default (using link:spark-sql-settings.adoc#spark.sql.codegen.wholeStage[spark.sql.codegen.wholeStage] property).

NOTE: Whole stage codegen is used by some modern massively parallel processing (MPP) databases to archive great performance. See http://www.vldb.org/pvldb/vol4/p539-neumann.pdf[Efficiently Compiling Efficient Query Plans for Modern Hardware (PDF)].

NOTE: Janino is used to compile a Java source code into a Java class.

Before a query is executed, <<CollapseCodegenStages, CollapseCodegenStages>> case class is used to find the plans that support codegen and collapse them together as `WholeStageCodegen`. It is part of the sequence of rules link:spark-sql-QueryExecution.adoc#preparations[QueryExecution.preparations] that will be applied in order to the physical plan before execution.

=== [[CollapseCodegenStages]] CollapseCodegenStages

`CollapseCodegenStages` is a `Rule[SparkPlan]`, i.e. a transformation of link:spark-sql-SparkPlan.adoc[SparkPlan] into another `SparkPlan`.

NOTE: `CollapseCodegenStages` is used in link:spark-sql-QueryExecution.adoc#preparations[the sequence of rules to apply to a SparkPlan before query execution].

It searches for sub-plans (aka _stages_) that support codegen and collapse them together as a `WholeStageCodegen`.

NOTE: Only link:spark-sql-CodegenSupport.adoc[CodegenSupport] SparkPlans support codegen for which `supportCodegen` is enabled (`true`).

It is assumed that all `Expression` instances (but link:spark-sql-Expression.adoc#CodegenFallback[CodegenFallback]) support codegen.

`CollapseCodegenStages` uses the internal setting `spark.sql.codegen.maxFields` (default: `200`) to control the number of fields in input and output schemas before deactivating whole-stage codegen. It counts the fields included in complex types, i.e. link:spark-sql-StructType.adoc[StructType], `MapType`, `ArrayType`, `UserDefinedType`, and their combinations, recursively. See https://issues.apache.org/jira/browse/SPARK-14554[SPARK-14554].

It inserts `InputAdapter` leaf nodes in a SparkPlan recursively that is then used to generate code that consumes an RDD iterator of link:spark-sql-InternalRow.adoc[InternalRow].

=== [[BenchmarkWholeStageCodegen]] BenchmarkWholeStageCodegen -- Performance Benchmark

`BenchmarkWholeStageCodegen` class provides a benchmark to measure whole stage codegen performance.

You can execute it using the command:

```
build/sbt 'sql/testOnly *BenchmarkWholeStageCodegen'
```

NOTE: You need to un-ignore tests in `BenchmarkWholeStageCodegen` by replacing `ignore` with `test`.

```
$ build/sbt 'sql/testOnly *BenchmarkWholeStageCodegen'
...
Running benchmark: range/limit/sum
  Running case: range/limit/sum codegen=false
22:55:23.028 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
  Running case: range/limit/sum codegen=true

Java HotSpot(TM) 64-Bit Server VM 1.8.0_77-b03 on Mac OS X 10.10.5
Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz

range/limit/sum:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative
-------------------------------------------------------------------------------------------
range/limit/sum codegen=false             376 /  433       1394.5           0.7       1.0X
range/limit/sum codegen=true              332 /  388       1581.3           0.6       1.1X

[info] - range/limit/sum (10 seconds, 74 milliseconds)
```
