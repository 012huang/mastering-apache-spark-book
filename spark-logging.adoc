== Logging

Spark uses log4j for logging.

The valid log levels are "ALL", "DEBUG", "ERROR", "FATAL", "INFO", "OFF", "TRACE", "WARN" (FIXME: importance)

=== conf/log4j.properties

You can set up the default logging for Spark shell in `conf/log4j.properties`. Use `conf/log4j.properties.template` as a starting point.

=== SparkContext.setLogLevel

To adjust logging level temporarily in Spark shell use `sc.setLogLevel("INFO")`.

[TIP]
====
`sc.setLogLevel("INFO")` becomes `org.apache.log4j.Level.toLevel(logLevel)` and `org.apache.log4j.Logger.getRootLogger().setLevel(l)` internally.

See https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/SparkContext.scala#L367-L378[org/apache/spark/SparkContext.scala].
====

=== Spark applications

In standalone Spark applications, use the following:

[source, scala]
----
import org.apache.log4j.Logger
import org.apache.log4j.Level

def main(args: Array[String]) {
  Logger.getLogger("org").setLevel(Level.OFF)
  Logger.getLogger("akka").setLevel(Level.OFF)

  // your code goes here...
}
----
