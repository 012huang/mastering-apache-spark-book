== YarnAllocator -- Container Allocator

`YarnAllocator` requests containers from the YARN ResourceManager to run Spark link:spark-executor.adoc[executors] on and kills them when link:spark-yarn-applicationmaster.adoc[ApplicationMaster] no longer needs them.

It uses YARN's https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/client/api/AMRMClient.html[AMRMClient] API.

It is used in link:spark-yarn-applicationmaster.adoc[ApplicationMaster] (via an internal `allocator`) and is created when link:spark-yarn-yarnrmclient.adoc#register[`YarnRMClient` registers an application master with the YARN ResourceManager].

.ApplicationMaster uses YarnAllocator (via allocator attribute)
image::images/spark-yarn-YarnAllocator.png[align="center"]

[TIP]
====
Enable `INFO` or `DEBUG` logging level for `org.apache.spark.deploy.yarn.YarnAllocator` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.deploy.yarn.YarnAllocator=DEBUG
```

Refer to link:spark-logging.adoc[Logging].
====

=== [[requestTotalExecutorsWithPreferredLocalities]] Requesting Executors with Locality Preferences (requestTotalExecutorsWithPreferredLocalities method)

[source, scala]
----
requestTotalExecutorsWithPreferredLocalities(
  requestedTotal: Int,
  localityAwareTasks: Int,
  hostToLocalTaskCount: Map[String, Int]): Boolean
----

`requestTotalExecutorsWithPreferredLocalities` returns `true` if the current requested total is different than the new value (as the input `requestedTotal`).

`requestTotalExecutorsWithPreferredLocalities` sets the internal `numLocalityAwareTasks` and `hostToLocalTaskCounts` attributes to the input `localityAwareTasks` and `hostToLocalTaskCount` arguments, respectively.

If the input `requestedTotal` is different than the internal `targetNumExecutors` attribute you should see the following INFO message in the logs:

```
INFO Driver requested a total number of [requestedTotal] executor(s).
```

It sets the internal `targetNumExecutors` attribute to the input `requestedTotal` and returns `true`. Otherwise, it returns `false`.

NOTE: `requestTotalExecutorsWithPreferredLocalities` is executed in response to `RequestExecutors` message to link:spark-yarn-AMEndpoint.adoc[ApplicationMaster].

=== [[updateResourceRequests]] updateResourceRequests

[source, scala]
----
updateResourceRequests(): Unit
----

CAUTION: FIXME

=== [[handleAllocatedContainers]] handleAllocatedContainers

[source, scala]
----
handleAllocatedContainers(allocatedContainers: Seq[Container]): Unit
----

CAUTION: FIXME

=== [[processCompletedContainers]] processCompletedContainers

[source, scala]
----
processCompletedContainers(completedContainers: Seq[ContainerStatus]): Unit
----

CAUTION: FIXME

=== [[allocateResources]] allocateResources

[source, scala]
----
allocateResources(): Unit
----

`allocateResources` is...???

It starts by executing <<updateResourceRequests, updateResourceRequests>>. It then link:++https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/client/api/AMRMClient.html#allocate(float)++[requests additional containers from YARN's `AMRMClient`] with progress indicator of `0.1f`.

It link:++https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/api/protocolrecords/AllocateResponse.html#getAllocatedContainers()++[gets the list of newly-allocated containers by the YARN ResourceManager].

If the number of allocated containers is greater than `0`, you should see the following DEBUG message in the logs (in stderr on YARN):

```
DEBUG YarnAllocator: Allocated containers: [allocatedContainersSize]. Current executor count: [numExecutorsRunning]. Cluster resources: [availableResources].
```

It <<handleAllocatedContainers, launches executors on the allocated YARN containers>>.

It link:++https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/api/protocolrecords/AllocateResponse.html#getCompletedContainersStatuses()++[gets the list of completed containers' statuses from YARN].

If the number of completed containers is greater than `0`, you should see the following DEBUG message in the logs (in stderr on YARN):

```
DEBUG YarnAllocator: Completed [completedContainersSize] containers
```

It <<processCompletedContainers, processes completed containers>>.

You should see the following DEBUG message in the logs (in stderr on YARN):

```
DEBUG YarnAllocator: Finished processing [completedContainersSize] completed containers. Current running executor count: [numExecutorsRunning].
```

It is executed when link:spark-yarn-applicationmaster.adoc#registerAM[`ApplicationMaster` is registered to the YARN ResourceManager].

=== [[creating-instance]] Creating YarnAllocator Instance

When `YarnAllocator` is created, it sets the `org.apache.hadoop.yarn.util.RackResolver` logger to `WARN` (unless set to some log level already).

It creates an empty <<releasedContainers, releasedContainers>> and sets the internal `numExecutorsRunning` variable to `0`.

It sets the internal `executorIdCounter` counter to the link:spark-yarn-cluster-YarnSchedulerEndpoint.adoc#RetrieveLastAllocatedExecutorId[last allocated executor id].

It creates an empty <<failedExecutorsTimeStamps, failedExecutorsTimeStamps>> queue.

It sets the internal `executorFailuresValidityInterval` to link:spark-yarn-settings.adoc#spark.yarn.executor.failuresValidityInterval[spark.yarn.executor.failuresValidityInterval].

It sets the internal `targetNumExecutors` counter to link:spark-yarn-YarnSparkHadoopUtil.adoc#getInitialTargetExecutorNumber[the initial number of executors].

It creates an empty <<pendingLossReasonRequests, pendingLossReasonRequests>> collection of...FIXME

It creates an empty <<releasedExecutorLossReasons, releasedExecutorLossReasons>> collection of...FIXME

It creates an empty <<executorIdToContainer, executorIdToContainer>> collection of...FIXME

It sets the internal `numUnexpectedContainerRelease` counter to `0L`.

It creates an empty <<containerIdToExecutorId, containerIdToExecutorId>> collection of...FIXME

It sets the internal `executorMemory` to link:spark-executor.adoc#spark.executor.memory[spark.executor.memory].

It sets the internal `memoryOverhead` to link:spark-yarn-settings.adoc#spark.yarn.executor.memoryOverhead[spark.yarn.executor.memoryOverhead]. If unavailable, it is set to the maximum of 10% of `executorMemory` and `384`.

It sets the internal `executorCores` to link:spark-executor.adoc#spark.executor.cores[spark.executor.cores].

It creates the internal `resource` to Hadoop YARN's https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/api/records/Resource.html[Resource] with both `executorMemory + memoryOverhead` memory and `executorCores` CPU cores.

It creates the internal `launcherPool` called *ContainerLauncher* with maximum link:spark-yarn-settings.adoc#spark.yarn.containerLauncherMaxThreads[spark.yarn.containerLauncherMaxThreads] threads.

It sets the internal `launchContainers` to link:spark-yarn-settings.adoc#spark.yarn.launchContainers[spark.yarn.launchContainers].

It sets the internal `labelExpression` to link:spark-yarn-settings.adoc#spark.yarn.executor.nodeLabelExpression[spark.yarn.executor.nodeLabelExpression].

It sets the internal `nodeLabelConstructor` to...FIXME

CAUTION: FIXME nodeLabelConstructor?

It creates an empty <<hostToLocalTaskCounts, hostToLocalTaskCounts>> collection of...FIXME

It sets the internal `numLocalityAwareTasks` counter to `0`.

It sets the internal `containerPlacementStrategy` to...FIXME

CAUTION: FIXME LocalityPreferredContainerPlacementStrategy?

=== [[internal-registries]] Internal Registries

==== [[hostToLocalTaskCounts]] hostToLocalTaskCounts

CAUTION: FIXME

==== [[containerIdToExecutorId]] containerIdToExecutorId

CAUTION: FIXME

==== [[executorIdToContainer]] executorIdToContainer

CAUTION: FIXME

==== [[releasedExecutorLossReasons]] releasedExecutorLossReasons

CAUTION: FIXME

==== [[pendingLossReasonRequests]] pendingLossReasonRequests

CAUTION: FIXME

==== [[failedExecutorsTimeStamps]] failedExecutorsTimeStamps

CAUTION: FIXME

==== [[releasedContainers]] releasedContainers

`releasedContainers` contains containers of no use anymore by their globally unique identifier https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/api/records/ContainerId.html[ContainerId] (for a `Container` in the cluster).

NOTE: Hadoop YARN's https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/api/records/Container.html[Container] represents an allocated resource in the cluster. The YARN ResourceManager is the sole authority to allocate any `Container` to applications. The allocated `Container` is always on a single node and has a unique `ContainerId`. It has a specific amount of `Resource` allocated.
