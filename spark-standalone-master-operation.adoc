== Operating Spark master

You start link:spark-standalone.adoc[Spark Standalone]'s *master* using <<start-script, sbin/start-master.sh>> and later stop it using <<stop-script, sbin/stop-master.sh>>.

The initialization is as follows:

* Start <<rpcenv, sparkMaster RPC Environment>>
* ...

=== [[start-script]] sbin/start-master.sh

`sbin/start-master.sh` script starts a Spark master on the machine this script is executed on.

```
./sbin/start-master.sh
```

The script prepares the command line to start `org.apache.spark.deploy.master.Master`.

It has support for starting Tachyon using `--with-tachyon` command line option. It assumes `tachyon/bin/tachyon` command be available in Spark's home directory.

The script uses the following helper scripts:

* `sbin/spark-config.sh`
* `bin/load-spark-env.sh`

Ultimately, the script calls `sbin/spark-daemon.sh start` to kick off `org.apache.spark.deploy.master.Master` with parameter `1` and `--ip`, `--port`, and `--webui-port`.

==== Command-line options

You can use the following command-line options:

* `--host` or `-h` - the hostname to listen on; similar to `SPARK_MASTER_HOST`.
* `--port` or `-p` - similar to `SPARK_MASTER_PORT`
* `--webui-port` - similar to `SPARK_MASTER_WEBUI_PORT`
* `--properties-file` (default: `conf/spark-defaults.conf`) - the path to a custom Spark properties file
* `--help`

=== [[stop-script]] sbin/stop-master.sh

`sbin/stop-master.sh` script stops a Spark master on the machine this script is executed on.

```
./sbin/stop-master.sh
```

CAUTION: FIXME Review the script

It effectively sends SIGTERM to the master's process.

You should see the ERROR in master's logs:

```
ERROR Master: RECEIVED SIGNAL 15: SIGTERM
```

=== System environment variables

Master uses the following system environment variables (directly or indirectly):

* `SPARK_MASTER_PORT` (default: `7077`)
* `SPARK_MASTER_IP` (default: `hostname` command's output)
* `SPARK_MASTER_WEBUI_PORT` (default: `8080`)
* `SPARK_PUBLIC_DNS` (default: hostname) - master's public hostname for WebUI's http URL

=== States

Master can be in the following states:

* `STANDBY`
* `ALIVE`
* `RECOVERING`
* `COMPLETING_RECOVERY`

FIXME

=== Spark properties

After loading the default Spark properties file or `--properties-file`, if `spark.master.ui.port` is specified, it is used as web UI's port.

=== [[rpcenv]] RPC environment

The `org.apache.spark.deploy.master.Master` class starts its own link:spark-rpc.adoc[sparkMaster RPC environment] with `Master` endpoint.

The following INFO shows up when the Master Endpoint starts up (`Master#onStart` is called):

```
INFO Master: Starting Spark master at spark://japila.local:7077
INFO Master: Running Spark version 1.6.0-SNAPSHOT
```

The Master endpoint starts the daemon single-thread scheduler pool `master-forward-message-thread`. It is used for worker management, i.e. removing any timed-out workers.

```
"master-forward-message-thread" #46 daemon prio=5 os_prio=31 tid=0x00007ff322abb000 nid=0x7f03 waiting on condition [0x000000011cad9000]
```

The Master is in fact the Master RPC Endpoint that you can access using RPC port (low-level operation communication) or link:spark-webui.adoc[WebUI].

=== [[metrics]] Metrics

Master uses link:spark-metrics.adoc[Spark Metrics System] (via `MasterSource`) to report metrics about its execution.

The name of the source is *master*.

It emits the following metrics:

* `workers` - the number of all workers (any state)
* `aliveWorkers` - the number of alive workers
* `apps` - the number of applications
* `waitingApps` - the number of waiting applications

FIXME How to access the metrics for master? See `Master#onStart`

=== [[properties]] Properties

Master uses the following properties:

* `spark.worker.timeout` (default: `60`) - time (in seconds) when no heartbeat from a worker means it's lost.
* `spark.deploy.retainedApplications` (default: `200`)
* `spark.deploy.retainedDrivers` (default: `200`)
* `spark.dead.worker.persistence` (default: `15`)
* `spark.deploy.recoveryMode` (default: `NONE`) - possible modes: `ZOOKEEPER`, `FILESYSTEM`, or `CUSTOM`. Refer to <<recovery-mode, Recovery Mode>>.
* `spark.deploy.recoveryMode.factory` - the class name of the custom `StandaloneRecoveryModeFactory`.
* `spark.deploy.recoveryDirectory` (default: empty) - the directory to persist recovery state
* `spark.deploy.spreadOut` (default: `true`) - perform round-robin scheduling across the nodes (spreading out each app among all the nodes). Refer to <<round-robin-scheduling, Round-robin Scheduling Across Nodes>>
* `spark.deploy.defaultCores` (default: `Int.MaxValue`, i.e. unbounded)- the number of maxCores for applications that don't specify it.
* `spark.master.rest.enabled` (default: `true`) - <<rest-server, master's REST Server>> for alternative application submission that is supposed to work across Spark versions.
* `spark.master.rest.port` (default: `6066`) - the port of <<rest-server, master's REST Server>>
* `spark.ui.killEnabled` (default: `true`)

=== [[recovery-mode]] Recovery Mode

Master can run with *recovery mode* enabled and be able to recover state among the available swarm of masters. By default, there is no recovery, i.e. no persistence and no election.

It uses `spark.deploy.recoveryMode` to define the recovery mode for master (see <<properties, spark.deploy.recoveryMode>>).

The Recovery Mode enables election of the leader master among the masters.

FIXME Why would I want to have many masters? What are the use cases?

=== [[rest-server]] REST Server

Master starts REST Server for alternative application submission that is supposed to work across Spark versions. It enabled by default (see <<properties, spark.master.rest.enabled>>).

FIXME StandaloneRestServer

The following INFOs show up when the Master Endpoint starts up (`Master#onStart` is called) with REST Server enabled:

```
INFO Utils: Successfully started service on port 6066.
INFO StandaloneRestServer: Started REST server for submitting applications on port 6066
```

=== [[round-robin-scheduling]] Round-robin Scheduling Across Nodes

<<properties, spark.deploy.spreadOut>> property controls whether or not to perform round-robin scheduling across the nodes (spreading out each app among all the nodes). It defaults to `true`.

FIXME

=== Master WebUI

FIXME MasterWebUI

```
INFO Utils: Successfully started service 'MasterUI' on port 8080.
INFO MasterWebUI: Started MasterWebUI at http://192.168.1.4:8080
```

=== [[leader-election]] Leader Election

FIXME

=== Messages

Master communicates with drivers, executors and sets itself up using *messages*.

The following message types are accepted by master (see `Master#receive` or `Master#receiveAndReply` methods):

* `ElectedLeader` for <<leader-election, Leader Election>>)
* `CompleteRecovery`
* `RevokedLeadership`
* `RegisterApplication`
* `ExecutorStateChanged`
* `DriverStateChanged`
* `Heartbeat`
* `MasterChangeAcknowledged`
* `WorkerSchedulerStateResponse`
* `UnregisterApplication`
* `CheckForWorkerTimeOut`
* `RegisterWorker`
* `RequestSubmitDriver`
* `RequestKillDriver`
* `RequestDriverStatus`
* `RequestMasterState`
* `BoundPortsRequest`
* `RequestExecutors`
* `KillExecutors`

=== Internals of org.apache.spark.deploy.master.Master

When `Master` (`main`) starts, it creates <<spark-configuration.adoc#default-configuration, the default SparkConf>>.

It parses command-line arguments for the master using `MasterArguments` class.

It uses the following environment variables:

* `SPARK_MASTER_HOST` (not `SPARK_MASTER_IP` as used in the script above!)
