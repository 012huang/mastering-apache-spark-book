== [[SessionState]] SessionState

`SessionState` is the <<attributes, state separation layer>> between Spark SQL sessions, including SQL configuration, tables, functions, UDFs, SQL parser, and everything else that depends on a link:spark-sql-SQLConf.adoc[SQLConf].

NOTE: `SessionState` is a `private[sql]` class and, given the package `org.apache.spark.sql.internal`, `SessionState` should be considered _internal_.

[[attributes]]
.SessionState's (Lazily-Initialized) Attributes (in alphabetical order)
[cols="1,1,2",options="header",width="100%"]
|===
| Name
| Type
| Description

| [[analyzer]] `analyzer`
| link:spark-sql-Analyzer.adoc[Analyzer]
| FIXME

Used when...FIXME

| [[catalog]] `catalog`
| link:spark-sql-SessionCatalog.adoc[SessionCatalog]
| Manages tables and databases.

Used when...FIXME

| [[conf]] `conf`
| link:spark-sql-SQLConf.adoc[SQLConf]
| FIXME

Used when...FIXME

| [[experimentalMethods]] `experimentalMethods`
| link:spark-sql-ExperimentalMethods.adoc[ExperimentalMethods]
| FIXME

Used when...FIXME

| [[functionRegistry]] `functionRegistry`
| link:spark-sql-FunctionRegistry.adoc[FunctionRegistry]
| FIXME

Used when...FIXME

| [[functionResourceLoader]] `functionResourceLoader`
| `FunctionResourceLoader`
| FIXME

Used when...FIXME

| [[listenerManager]] `listenerManager`
| link:spark-sql-sparksession.adoc#ExecutionListenerManager[ExecutionListenerManager]
| FIXME

Used when...FIXME

| [[optimizer]] `optimizer`
| link:spark-sql-SparkOptimizer.adoc[SparkOptimizer]
| Logical query plan optimizer

Used exclusively when `QueryExecution`  link:spark-sql-QueryExecution.adoc#optimizedPlan[creates an optimized logical plan].

| [[planner]] `planner`
| link:spark-sql-SparkPlanner.adoc[SparkPlanner]
| FIXME

Used when...FIXME

| [[sqlParser]] `sqlParser`
| link:spark-sql-ParserInterface.adoc[ParserInterface]
| FIXME

Used when...FIXME

| [[streamingQueryManager]] `streamingQueryManager`
| `StreamingQueryManager`
| FIXME

Used when...FIXME

| [[udf]] `udf`
| link:spark-sql-UDFRegistration.adoc[UDFRegistration]
| Interface to register user-defined functions.

Used when...FIXME
|===

=== [[creating-instance]] Creating SessionState Instance

`SessionState` takes the following when created:

* [[sparkContext]] link:spark-sparkcontext.adoc[SparkContext]
* [[sharedState]] link:spark-sql-sparksession.adoc#SharedState[SharedState]
* [[conf]] link:spark-sql-SQLConf.adoc[SQLConf]
* [[experimentalMethods]] link:spark-sql-ExperimentalMethods.adoc[ExperimentalMethods]
* [[functionRegistry]] link:spark-sql-FunctionRegistry.adoc[FunctionRegistry]
* [[catalog]] link:spark-sql-SessionCatalog.adoc[SessionCatalog]
* link:spark-sql-ParserInterface.adoc[ParserInterface]
* [[analyzer]] link:spark-sql-Analyzer.adoc[Analyzer]
* [[streamingQueryManager]] `StreamingQueryManager`
* [[queryExecutionCreator]] link:spark-sql-LogicalPlan.adoc[LogicalPlan] Transformation to produce a link:spark-sql-QueryExecution.adoc[QueryExecution]

`SessionState` initializes the <<attributes, attributes>>.

NOTE: `SessionState` is created when...FIXME

=== [[apply]] `apply` Factory Methods

CAUTION: FIXME

[source, scala]
----
apply(sparkSession: SparkSession): SessionState // <1>
apply(sparkSession: SparkSession, sqlConf: SQLConf): SessionState
----
<1> Passes `sparkSession` to the other `apply` with a new `SQLConf`

NOTE: `apply` is used when `SparkSession` link:spark-sql-sparksession.adoc#instantiateSessionState[is requested for the current `SessionState`] and `HiveSessionState` link:spark-sql-HiveSessionState.adoc#apply[is created].

=== [[clone]] `clone` Method

CAUTION: FIXME

NOTE: `clone` is used when...

=== [[createAnalyzer]] `createAnalyzer` Internal Method

[source, scala]
----
createAnalyzer(
  sparkSession: SparkSession,
  catalog: SessionCatalog,
  sqlConf: SQLConf): Analyzer
----

`createAnalyzer` creates a logical query plan link:spark-sql-Analyzer.adoc[Analyzer] with rules specific to a non-Hive `SessionState`.

[[batches]]
.Analyzer's Evaluation Rules for non-Hive SessionState (in the order of execution)
[cols="2,1,3",options="header",width="100%"]
|===
^.^| Method
| Rules
| Description

.2+^.^| extendedResolutionRules
| FindDataSourceTable
| Replaces `InsertIntoTable` (with `CatalogRelation`) and `CatalogRelation` logical plans with `LogicalRelation`.

| ResolveSQLOnFile
|

.3+^.^| postHocResolutionRules
| PreprocessTableCreation
|

| PreprocessTableInsertion
|

| DataSourceAnalysis
|

.2+^.^| extendedCheckRules
| PreWriteCheck
|

| HiveOnlyCheck
|
|===

NOTE: `createAnalyzer` is used when `SessionState` is <<apply, created>> or <<clone, cloned>>.

=== [[executePlan]] Executing Logical Plan -- `executePlan` Method

[source, scala]
----
executePlan(plan: LogicalPlan): QueryExecution
----

`executePlan` executes the input link:spark-sql-LogicalPlan.adoc[LogicalPlan] to produce a link:spark-sql-QueryExecution.adoc[QueryExecution] in the current link:spark-sql-sparksession.adoc[SparkSession].

=== [[refreshTable]] `refreshTable` Method

`refreshTable` is...

=== [[addJar]] `addJar` Method

`addJar` is...

=== [[analyze]] `analyze` Method

`analyze` is...

=== [[newHadoopConf]] Creating New Hadoop Configuration -- `newHadoopConf` Method

[source, scala]
----
newHadoopConf(): Configuration
----

`newHadoopConf` returns Hadoop's `Configuration` that it builds using link:spark-sparkcontext.adoc#hadoopConfiguration[SparkContext.hadoopConfiguration] (through link:spark-sql-sparksession.adoc[SparkSession]) with all configuration settings added.

NOTE: `newHadoopConf` is used by link:spark-sql-HiveSessionState.adoc[HiveSessionState] (for `HiveSessionCatalog`), `ScriptTransformation`, `ParquetRelation`, `StateStoreRDD`, and `SessionState` itself, and few other places.

CAUTION: FIXME What is `ScriptTransformation`? `StateStoreRDD`?
