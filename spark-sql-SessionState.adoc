== [[SessionState]] SessionState

`SessionState` is the <<attributes, state separation layer>> between Spark SQL sessions, including SQL configuration, tables, functions, UDFs, SQL parser, and everything else that depends on a link:spark-sql-SQLConf.adoc[SQLConf].

NOTE: `SessionState` is a `private[sql]` class and, given the package `org.apache.spark.sql.internal`, `SessionState` should be considered _internal_.

[[attributes]]
.SessionState's (Lazily-Initialized) Attributes (in alphabetical order)
[cols="1,1,2",options="header",width="100%"]
|===
| Name
| Type
| Description

| [[analyzer]] `analyzer`
| link:spark-sql-Analyzer.adoc[Analyzer]
| FIXME

Used when...FIXME

| [[catalog]] `catalog`
| link:spark-sql-SessionCatalog.adoc[SessionCatalog]
| Manages tables and databases.

Used when...FIXME

| [[conf]] `conf`
| link:spark-sql-SQLConf.adoc[SQLConf]
| FIXME

Used when...FIXME

| [[experimentalMethods]] `experimentalMethods`
| link:spark-sql-ExperimentalMethods.adoc[ExperimentalMethods]
| FIXME

Used when...FIXME

| [[functionRegistry]] `functionRegistry`
| link:spark-sql-FunctionRegistry.adoc[FunctionRegistry]
| FIXME

Used when...FIXME

| [[functionResourceLoader]] `functionResourceLoader`
| `FunctionResourceLoader`
| FIXME

Used when...FIXME

| [[listenerManager]] `listenerManager`
| link:spark-sql-sparksession.adoc#ExecutionListenerManager[ExecutionListenerManager]
| FIXME

Used when...FIXME

| [[optimizer]] `optimizer`
| link:spark-sql-catalyst-Optimizer.adoc[Optimizer]
| FIXME

Used when...FIXME

| [[planner]] `planner`
| link:spark-sql-SparkPlanner.adoc[SparkPlanner]
| FIXME

Used when...FIXME

| [[sqlParser]] `sqlParser`
| link:spark-sql-sql-parsers.adoc#ParserInterface[ParserInterface]
| FIXME

Used when...FIXME

| [[streamingQueryManager]] `streamingQueryManager`
| `StreamingQueryManager`
| FIXME

Used when...FIXME

| [[udf]] `udf`
| `UDFRegistration`
| FIXME

Used when...FIXME
|===

=== [[executePlan]] Preparing Logical Plan for Execution -- `executePlan` Method

[source, scala]
----
executePlan(plan: LogicalPlan): QueryExecution
----

`executePlan` executes the input link:spark-sql-LogicalPlan.adoc[LogicalPlan] to produce a link:spark-sql-query-execution.adoc[QueryExecution] in the current link:spark-sql-sparksession.adoc[SparkSession].

=== [[refreshTable]] `refreshTable` Method

`refreshTable` is...

=== [[addJar]] `addJar` Method

`addJar` is...

=== [[analyze]] `analyze` Method

`analyze` is...

=== [[newHadoopConf]] Creating New Hadoop Configuration -- `newHadoopConf` Method

[source, scala]
----
newHadoopConf(): Configuration
----

`newHadoopConf` returns Hadoop's `Configuration` that it builds using link:spark-sparkcontext.adoc#hadoopConfiguration[SparkContext.hadoopConfiguration] (through link:spark-sql-sparksession.adoc[SparkSession]) with all configuration settings added.

NOTE: `newHadoopConf` is used by link:spark-sql-HiveSessionState.adoc[HiveSessionState] (for `HiveSessionCatalog`), `ScriptTransformation`, `ParquetRelation`, `StateStoreRDD`, and `SessionState` itself, and few other places.

CAUTION: FIXME What is `ScriptTransformation`? `StateStoreRDD`?
