== Client

`org.apache.spark.deploy.yarn.Client` is a standalone application used for link:spark-submit.adoc#submit[application submission] to a YARN cluster (regardless of the link:spark-submit.adoc#deploy-mode[deploy mode]).

Precisely, it is <<main, Client.main>> method that is invoked.

Depending on the deploy mode in use (`spark.submit.deployMode`) it calls link:spark-yarn-applicationmaster.adoc[org.apache.spark.deploy.yarn.ApplicationMaster] or ApplicationMaster's wrapper link:spark-yarn-applicationmaster.adoc#ExecutorLauncher[org.apache.spark.deploy.yarn.ExecutorLauncher] by their class names (so the instantiation is implicit and dynamic, i.e. happens at runtime).

=== [[main]] main

`main` method is invoked while a Spark application is being deployed to a YARN cluster.

NOTE: It is executed by link:spark-submit.adoc#submit[spark-submit] with `--master yarn` command-line argument.

[NOTE]
====
When you start the `main` method when starting the `Client` standalone application, say using `./bin/spark-class org.apache.spark.deploy.yarn.Client`, you will see the following WARNING message in the logs unless you set `SPARK_SUBMIT` system property.

```
WARN Client: WARNING: This client is deprecated and will be removed in a future version of Spark. Use ./bin/spark-submit with "--master yarn"
```
====

`main` first sets `SPARK_YARN_MODE` system property to `true`.

CAUTION: FIXME Why is this property needed?

It then instantiates link:spark-configuration.adoc[SparkConf], parses command-line arguments (using <<ClientArguments, ClientArguments>>) and passes the call on to <<run, Client.run>> method.

=== [[run]] run

`run` <<submitApplication, submits a Spark application>> to a link:spark-yarn-introduction.adoc[YARN ResourceManager] (RM).

If `LauncherBackend` is not connected to a RM, i.e. `LauncherBackend.isConnected` returns `false`, and `fireAndForget` is enabled, ...FIXME

CAUTION: FIXME When could `LauncherBackend` lost the connection since it was connected in <<submitApplication, submitApplication>>?

CAUTION: FIXME What is `fireAndForget`?

Otherwise, when `LauncherBackend` is connected or `fireAndForget` is disabled, <<monitorApplication, monitorApplication>> is called. It returns a pair of `yarnApplicationState` and `finalApplicationStatus` that is checked against three different states that lead to a `SparkException` being thrown:

* `YarnApplicationState.KILLED` or `FinalApplicationStatus.KILLED` lead to `SparkException` with the message "Application [appId] is killed".

* `YarnApplicationState.FAILED` or `FinalApplicationStatus.FAILED` lead to `SparkException` with the message "Application [appId] finished with failed status".

* `FinalApplicationStatus.UNDEFINED` leads to `SparkException` with the message "The final status of application [appId] is undefined".

CAUTION: FIXME What are `YarnApplicationState` and `FinalApplicationStatus` statuses?

=== [[monitorApplication]] monitorApplication

`monitorApplication` ...

=== [[submitApplication]] submitApplication

`submitApplication` submits a Spark application to a YARN ResourceManager. It waits until the application is running and eventually returns its unique https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/api/records/ApplicationId.html[ApplicationId].

NOTE: `submitApplication` is used in <<run, Client.run>> and link:spark-yarn.adoc#YarnClientSchedulerBackend[YarnClientSchedulerBackend.start].

Internally, it executes `LauncherBackend.connect` first and then executes `Client.setupCredentials` to set up credentials for future calls.

CAUTION: FIXME What's `LauncherBackend`?

It creates a YARN client (using Hadoop's https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/client/api/YarnClient.html#createYarnClient()[YarnClient.createYarnClient]), https://hadoop.apache.org/docs/current/api/org/apache/hadoop/service/AbstractService.html#init(org.apache.hadoop.conf.Configuration)[inits it] with a https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/conf/YarnConfiguration.html[YarnConfiguration] and https://hadoop.apache.org/docs/current/api/org/apache/hadoop/service/AbstractService.html#start()[starts it]. All this happens using Hadoop API.

CAUTION: FIXME How to configure `YarnClient`? What is `getYarnClusterMetrics`?

You should see the following INFO in the logs:

```
INFO Client: Requesting a new application from cluster with [yarnClient.getYarnClusterMetrics.getNumNodeManagers] NodeManagers
```

It then https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/client/api/YarnClient.html#createApplication()[YarnClient.createApplication()] to create a new application in YARN and obtains the application id.

The `LauncherBackend` instance changes state to SUBMITTED with the application id.

CAUTION: FIXME Why is this important?

`submitApplication` verifies whether the cluster has resources for the ApplicationManager (using <<verifyClusterResources, verifyClusterResources>>).

It then <<createContainerLaunchContext, createContainerLaunchContext>> and <<createApplicationSubmissionContext, createApplicationSubmissionContext>>.

It submits the application to YARN ResourceManager.

```
INFO Client: Submitting application [applicationId.getId] to ResourceManager
```

And finally submits a new application to YARN (using Hadoop's https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/client/api/YarnClient.html#submitApplication(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext)[YarnClient.submitApplication]) and waits until it is accepted by YARN ResourceManager.

=== [[verifyClusterResources]] verifyClusterResources

```
INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
```

=== [[createContainerLaunchContext]] createContainerLaunchContext

=== [[createApplicationSubmissionContext]] createApplicationSubmissionContext

=== [[ClientArguments]] ClientArguments
