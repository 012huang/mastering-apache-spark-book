== Client

`org.apache.spark.deploy.yarn.Client` is a standalone application used for link:spark-submit.adoc#submit[application submission] to a YARN cluster (regardless of the link:spark-submit.adoc#deploy-mode[deploy mode]).

Precisely, it is <<main, Client.main>> method that is invoked.

Depending on the deploy mode in use (`spark.submit.deployMode`) it calls link:spark-yarn-applicationmaster.adoc[org.apache.spark.deploy.yarn.ApplicationMaster] or ApplicationMaster's wrapper link:spark-yarn-applicationmaster.adoc#ExecutorLauncher[org.apache.spark.deploy.yarn.ExecutorLauncher] by their class names (so the instantiation is implicit and dynamic, i.e. happens at runtime).

[TIP]
====
Enable `DEBUG` logging level for `org.apache.spark.deploy.yarn.Client` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.deploy.yarn.Client=DEBUG
```

Refer to link:spark-logging.adoc[Logging].
====

=== [[main]] main

`main` method is invoked while a Spark application is being deployed to a YARN cluster.

NOTE: It is executed by link:spark-submit.adoc#submit[spark-submit] with `--master yarn` command-line argument.

[NOTE]
====
When you start the `main` method when starting the `Client` standalone application, say using `./bin/spark-class org.apache.spark.deploy.yarn.Client`, you will see the following WARNING message in the logs unless you set `SPARK_SUBMIT` system property.

```
WARN Client: WARNING: This client is deprecated and will be removed in a future version of Spark. Use ./bin/spark-submit with "--master yarn"
```
====

`main` first sets `SPARK_YARN_MODE` system property to `true`.

CAUTION: FIXME Why is this property needed?

It then instantiates link:spark-configuration.adoc[SparkConf], parses command-line arguments (using <<ClientArguments, ClientArguments>>) and passes the call on to <<run, Client.run>> method.

=== [[run]] run

`run` <<submitApplication, submits a Spark application>> to a link:spark-yarn-introduction.adoc[YARN ResourceManager] (RM).

If `LauncherBackend` is not connected to a RM, i.e. `LauncherBackend.isConnected` returns `false`, and `fireAndForget` is enabled, ...FIXME

CAUTION: FIXME When could `LauncherBackend` lost the connection since it was connected in <<submitApplication, submitApplication>>?

CAUTION: FIXME What is `fireAndForget`?

Otherwise, when `LauncherBackend` is connected or `fireAndForget` is disabled, <<monitorApplication, monitorApplication>> is called. It returns a pair of `yarnApplicationState` and `finalApplicationStatus` that is checked against three different states that lead to a `SparkException` being thrown:

* `YarnApplicationState.KILLED` or `FinalApplicationStatus.KILLED` lead to `SparkException` with the message "Application [appId] is killed".

* `YarnApplicationState.FAILED` or `FinalApplicationStatus.FAILED` lead to `SparkException` with the message "Application [appId] finished with failed status".

* `FinalApplicationStatus.UNDEFINED` leads to `SparkException` with the message "The final status of application [appId] is undefined".

CAUTION: FIXME What are `YarnApplicationState` and `FinalApplicationStatus` statuses?

=== [[monitorApplication]] monitorApplication

[source, scala]
----
monitorApplication(
  appId: ApplicationId,
  returnOnRunning: Boolean = false,
  logApplicationReport: Boolean = true): (YarnApplicationState, FinalApplicationStatus)
----

`monitorApplication` continuously reports the status of an application `appId` every link:spark-yarn.adoc#spark.yarn.report.interval[spark.yarn.report.interval].

NOTE: It is used in <<run, Client.run>> and link:spark-yarn.adoc#YarnClientSchedulerBackend[YarnClientSchedulerBackend] (inside `waitForApplication` and `MonitorThread.run`).

It gets the application's report from the ResourceManager to access `YarnApplicationState`.

TIP: It uses Hadoop's `YarnClient.getApplicationReport(appId)`.

Unless `logApplicationReport` is disabled, it prints the following INFO message to the logs:

```
INFO Client: Application report for [appId] (state: $state)
```

If `logApplicationReport` and DEBUG log level are enabled, it prints report details every time interval to the logs:

```
16/04/23 13:21:36 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1461410495109
	 final status: UNDEFINED
	 tracking URL: http://japila.local:8088/proxy/application_1461410200840_0001/
	 user: jacek
```

For INFO log level it prints report details only when the application changes state.

When the application's state changes, `LauncherBackend` is notified (using `LauncherBackend.setState`).

NOTE: The application's state is Hadoop's `YarnApplicationState`.

For states `FINISHED`, `FAILED` or `KILLED`, `cleanupStagingDir(appId)` is called and the method returns a pair of the current state and the final application status.

For cases where `returnOnRunning` is enabled (it is not by default) and the application's state is indeed `RUNNING`, the method returns a pair of the current state `RUNNING` and the final application status.

The current state is recorded for future checks (in the loop).

=== [[submitApplication]] submitApplication

`submitApplication` submits a Spark application to a YARN ResourceManager. It waits until the application is running and eventually returns its unique https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/api/records/ApplicationId.html[ApplicationId].

NOTE: `submitApplication` is used in <<run, Client.run>> and link:spark-yarn.adoc#YarnClientSchedulerBackend[YarnClientSchedulerBackend.start].

Internally, it executes `LauncherBackend.connect` first and then executes `Client.setupCredentials` to set up credentials for future calls.

CAUTION: FIXME What's `LauncherBackend`?

It creates a YARN client (using Hadoop's https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/client/api/YarnClient.html#createYarnClient()[YarnClient.createYarnClient]), https://hadoop.apache.org/docs/current/api/org/apache/hadoop/service/AbstractService.html#init(org.apache.hadoop.conf.Configuration)[inits it] with a https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/conf/YarnConfiguration.html[YarnConfiguration] and https://hadoop.apache.org/docs/current/api/org/apache/hadoop/service/AbstractService.html#start()[starts it]. All this happens using Hadoop API.

CAUTION: FIXME How to configure `YarnClient`? What is `getYarnClusterMetrics`?

You should see the following INFO in the logs:

```
INFO Client: Requesting a new application from cluster with [yarnClient.getYarnClusterMetrics.getNumNodeManagers] NodeManagers
```

It then https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/client/api/YarnClient.html#createApplication()[YarnClient.createApplication()] to create a new application in YARN and obtains the application id.

The `LauncherBackend` instance changes state to SUBMITTED with the application id.

CAUTION: FIXME Why is this important?

`submitApplication` verifies whether the cluster has resources for the ApplicationManager (using <<verifyClusterResources, verifyClusterResources>>).

It then <<createContainerLaunchContext, createContainerLaunchContext>> and <<createApplicationSubmissionContext, createApplicationSubmissionContext>>.

It submits the application to YARN ResourceManager.

```
INFO Client: Submitting application [applicationId.getId] to ResourceManager
```

And finally submits a new application to YARN (using Hadoop's https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/client/api/YarnClient.html#submitApplication(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext)[YarnClient.submitApplication]) and waits until it is accepted by YARN ResourceManager.

=== [[verifyClusterResources]] verifyClusterResources

```
INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
```

=== [[createContainerLaunchContext]] createContainerLaunchContext

=== [[createApplicationSubmissionContext]] createApplicationSubmissionContext

=== [[ClientArguments]] ClientArguments
