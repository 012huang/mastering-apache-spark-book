== Executors

*Executors* are distributed agents that execute link:spark-taskscheduler-tasks.adoc#execution[tasks].

They _typically_ (i.e. not always) run for the entire lifetime of a Spark application. Executors send <<heartbeats-and-active-task-metrics, active task metrics>> to a link:spark-driver.adoc[driver] and inform link:spark-executor-backends.adoc[executor backends] about task status updates (task results including).

NOTE: Executors are managed solely by link:spark-executor-backends.adoc[executor backends].

Executors provide in-memory storage for RDDs that are cached in Spark applications (via link:spark-blockmanager.adoc[Block Manager]).

When executors are started they register themselves with the driver and communicate directly to execute tasks.

*Executor offers* are described by executor id and the host on which an executor runs (see <<resource-offers, Resource Offers>> in this document).

Executors use a <<thread-pool, thread pool>> for <<metrics, sending metrics>> and <<launching-tasks, launching tasks>> (by means of <<TaskRunner, TaskRunner>>).

Each executor can run multiple tasks over its lifetime, both in parallel and sequentially.

It is recommended to have as many executors as data nodes and as many cores as you can get from the cluster.

Executors are described by their *id*, *hostname*, *environment* (as `SparkEnv`), and *classpath* (and, less importantly, and more for internal optimization, whether they run in link:spark-local.adoc[local] or link:spark-cluster.adoc[cluster mode]).

[TIP]
====
Enable `INFO` or `DEBUG` logging level for `org.apache.spark.executor.Executor` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.executor.Executor=INFO
```

Refer to link:spark-logging.adoc[Logging].
====

=== Starting Executor

When an executor is started you should see the following INFO messages in the logs:

```
INFO Executor: Starting executor ID [executorId] on host [executorHostname]
INFO Executor: Using REPL class URI: http://[executorHostname]:56131
```

It creates an RPC endpoint for communication with the driver.

(only for non-local mode) Executors initialize the application using link:spark-blockmanager.adoc#initialize[BlockManager.initialize()].

Executors maintain a mapping between task ids and running tasks (as instances of <<TaskRunner,TaskRunner>>) in `runningTasks` internal map. Consult <<launching-tasks, Launching Tasks>> section.

A worker requires the additional services (beside the common ones like ...):

* executorActorSystemName
* link:spark-rpc.adoc[RPC Environment] (for Akka only)
* link:spark-service-mapoutputtracker.adoc#MapOutputTrackerWorker[MapOutputTrackerWorker]
* link:spark-metrics.adoc[MetricsSystem] with the name `executor`

CAUTION: FIXME How many cores are assigned per executor?

=== [[coarse-grained-executor]] Coarse-Grained Executors

*Coarse-grained executors* are executors that use link:spark-executor-backends-coarse-grained.adoc[CoarseGrainedExecutorBackend] for task scheduling.

=== [[launching-tasks]] Launching Tasks

`Executor.launchTask` creates a <<TaskRunner,TaskRunner>> that is then executed on <<thread-pool, Executor task launch worker Thread Pool>>.

.Launching tasks on executor using TaskRunners
image::images/executor-taskrunner-executorbackend.png[align="center"]

It accepts the context (as link:spark-executor-backends.adoc[ExecutorBackend]), attempt number, and the id, name and serialized form of the task.

The newly-created `TaskRunner` is registered in the internal `runningTasks` map.

=== [[heartbeats-and-active-task-metrics]] Heartbeats with Active Tasks Metrics

Executors keep sending <<metrics, active tasks metrics>> to a driver every <<settings, spark.executor.heartbeatInterval>>.

.Executors use HeartbeatReceiver endpoint to report task metrics
image::images/executor-heartbeatReceiver-endpoint.png[align="center"]

The structure sent is an array of `(Long, TaskMetrics)`.

TIP: Read about `TaskMetrics` in link:spark-taskscheduler-taskmetrics.adoc[TaskMetrics].

[CAUTION]
====
FIXME

* What's in `taskRunner.task.metrics`?
* What's in `Heartbeat`? Why is `blockManagerId` sent?
* What's in `RpcUtils.makeDriverRef`?
====

Executors use internal `driver-heartbeater` daemon single-thread scheduled pool executor, i.e. `ScheduledThreadPoolExecutor`.

=== [[TaskRunner]] TaskRunner

*TaskRunner* is a thread of execution that runs a task.

NOTE: TaskRunner can run a single task only. When TaskRunner finishes, it is removed from the internal `runningTasks` map.

It requires a link:spark-executor-backends.adoc[ExecutorBackend] (to send status updates to), task and attempt ids, task name, and serialized version of the task (as `ByteBuffer`). It sends updates about task execution to the link:spark-executor-backends.adoc[ExecutorBackend].

Sending task status updates to link:spark-executor-backends.adoc[ExecutorBackend] is a mechanism to inform the executor backend about task being started (`TaskState.RUNNING`), task finish together with the serialized result (`TaskState.FINISHED`), task being killed (`TaskState.KILLED`) and task failures (`TaskState.FAILED`).

When a `TaskRunner` starts running, it prints the following INFO message to the logs:

```
INFO Executor: Running [taskName] (TID [taskId])
```

`taskId` is the id of the task being executed in <<thread-pool, Executor task launch worker-[taskId]>>.

Information about it is sent to the driver using link:spark-executor-backends.adoc[ExecutorBackend] as `TaskState.RUNNING` and zero-byte `ByteBuffer`.

CAUTION: FIXME TaskMemoryManager and task serialization and deserialization

It first deserializes the task (using `Task.deserializeWithDependencies`), `updateDependencies(taskFiles, taskJars)`, and deserializes the task bytes into a `Task` instance (using the globally-configured `Serializer`). The `Task` instance has the link:spark-taskscheduler.adoc#TaskMemoryManager[TaskMemoryManager] set.

This is the moment when a task can stop its execution if it was killed while being deserialized. If not killed, `TaskRunner` continues executing the task.

You should see the following DEBUG message in the logs:

```
DEBUG Task [taskId]'s epoch is [task.epoch]
```

TaskRunner sends update of the epoch of the task to link:spark-service-mapoutputtracker.adoc[MapOutputTracker].

CAUTION: FIXME Why is `MapOutputTracker.updateEpoch` needed?

Task runs (with `taskId`, `attemptNumber`, and the globally-configured `MetricsSystem`). See link:spark-taskscheduler-tasks.adoc#execution[Task Execution].

When a task finishes, it returns a value and `accumUpdates`, i.e. the result of link:spark-taskscheduler-tasks.adoc#collectAccumulatorUpdates[Task.collectAccumulatorUpdates] that collects the latest values of accumulators used.

The result value is serialized (using the other instance of `Serializer`, i.e. `serializer`).

NOTE: There are two `Serializer` instances in `SparkContext.env`.

It creates an instance of `DirectTaskResult` with the serialized result and the accumulators' values (as `accumUpdates`).

`run` serializes the `DirectTaskResult` (using `SparkEnv.closureSerializer`) and calculates the result's size.

If `maxResultSize` is set and the size of the serialized result exceeds it, a `SparkException` is reported.

```
$ ./bin/spark-shell -c spark.driver.maxResultSize=1m

scala> sc.getConf.get("spark.driver.maxResultSize")
res0: String = 1m

scala> sc.range(0, 1024 * 1024 + 10, 1).collect
...
org.apache.spark.SparkException: Job aborted due to stage failure: Total size of serialized results of 1 tasks (1031.4 KB) is bigger than spark.driver.maxResultSize (1024.0 KB)
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
```

CAUTION: FIXME Complete me.

A successful execution is "announced" as INFO to the logs:

```
INFO Executor: Finished [taskName] (TID [taskId]). [resultSize] bytes result sent to driver
```

The serialized result is sent to the driver using link:spark-executor-backends.adoc[ExecutorBackend] as `TaskState.FINISHED` and `serializedResult`.

=== [[FetchFailedException]] FetchFailedException

CAUTION: FIXME

`FetchFailedException` exception is thrown when an executor (more specifically <<TaskRunner, TaskRunner>>) has failed to fetch a shuffle block.

It contains the following:

* the unique identifier for a BlockManager (as `BlockManagerId`)
* `shuffleId`
* `mapId`
* `reduceId`
* `message` - a short exception message
* `cause` - a `Throwable` object

TaskRunner catches it and informs link:spark-executor-backends.adoc[ExecutorBackend] about the case (using `statusUpdate` with `TaskState.FAILED` task state).

CAUTION: FIXME Image with the call to ExecutorBackend.

=== [[resource-offers]] Resource Offers

Read link:spark-taskschedulerimpl.adoc#resourceOffers[resourceOffers] in TaskSchedulerImpl and link:spark-tasksetmanager.adoc##resourceOffers[resourceOffer] in TaskSetManager.

=== [[thread-pool]] Executor task launch worker Thread Pool

Executors use daemon cached thread pools called *Executor task launch worker-ID* (with `ID` being the task id) for <<launching-tasks, launching tasks>>.

=== [[memory]] Executor Memory - spark.executor.memory or SPARK_EXECUTOR_MEMORY settings

You can control the amount of memory per executor using <<settings, spark.executor.memory>> setting. It sets the available memory equally for all executors per application.

NOTE: The amount of memory per executor is looked up when link:spark-sparkcontext.adoc#initialization[SparkContext is created].

You can change the assigned memory per executor per node in link:spark-standalone.adoc[standalone cluster] using link:spark-sparkcontext.adoc#environment-variables[SPARK_EXECUTOR_MEMORY] environment variable.

You can find the value displayed as *Memory per Node* in link:spark-standalone-master.adoc[web UI for standalone Master] (as depicted in the figure below).

.Memory per Node in Spark Standalone's web UI
image::images/spark-standalone-webui-memory-per-node.png[align="center"]

The above figure shows the result of running link:spark-shell.adoc[Spark shell] with the amount of memory per executor defined explicitly (on command line), i.e.

```
./bin/spark-shell --master spark://localhost:7077 -c spark.executor.memory=2g
```

=== [[metrics]] Metrics

Executors use link:spark-metrics.adoc[Metrics System] (via `ExecutorSource`) to report metrics about internal status.

NOTE: Metrics are only available for cluster modes, i.e. `local` mode turns metrics off.

The name of the source is *executor*.

It emits the following numbers:

* *threadpool.activeTasks* - the approximate number of threads that are actively executing tasks (using http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ThreadPoolExecutor.html[ThreadPoolExecutor.getActiveCount()])
* *threadpool.completeTasks* - the approximate total number of tasks that have completed execution (using http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ThreadPoolExecutor.html[ThreadPoolExecutor.getCompletedTaskCount()])
* *threadpool.currentPool_size* - the current number of threads in the pool (using http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ThreadPoolExecutor.html[ThreadPoolExecutor.getPoolSize()])
* *threadpool.maxPool_size* - the maximum allowed number of threads that have ever simultaneously been in the pool (using http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ThreadPoolExecutor.html[ThreadPoolExecutor.getMaximumPoolSize()])
* *filesystem.hdfs* / *read_bytes* using https://hadoop.apache.org/docs/current/api/org/apache/hadoop/fs/FileSystem.html[FileSystem.getAllStatistics()] and `getBytesRead()`
* *filesystem.hdfs.write_bytes* using https://hadoop.apache.org/docs/current/api/org/apache/hadoop/fs/FileSystem.html[FileSystem.getAllStatistics()] and `getBytesWritten()`
* *filesystem.hdfs.read_ops* using https://hadoop.apache.org/docs/current/api/org/apache/hadoop/fs/FileSystem.html[FileSystem.getAllStatistics()] and `getReadOps()`
* *filesystem.hdfs.largeRead_ops* using https://hadoop.apache.org/docs/current/api/org/apache/hadoop/fs/FileSystem.html[FileSystem.getAllStatistics()] and `getLargeReadOps()`
* *filesystem.hdfs.write_ops* using https://hadoop.apache.org/docs/current/api/org/apache/hadoop/fs/FileSystem.html[FileSystem.getAllStatistics()] and `getWriteOps()`
* *filesystem.file.read_bytes*
* *filesystem.file.write_bytes*
* *filesystem.file.read_ops*
* *filesystem.file.largeRead_ops*
* *filesystem.file.write_ops*

=== [[settings]] Settings

* `spark.executor.cores` - the number of cores for an executor
* `spark.executor.extraClassPath` - a list of URLs representing the user classpath. Each entry is separated by system-dependent path separator, i.e. `:` on Unix/MacOS systems and `;` on Microsoft Windows.
* `spark.executor.extraJavaOptions` - extra Java options for executors
* `spark.executor.extraLibraryPath` - a list of additional library paths separated by system-dependent path separator, i.e. `:` on Unix/MacOS systems and `;` on Microsoft Windows.
* `spark.executor.userClassPathFirst` (default: `false`) controls whether to load classes in user jars before those in Spark jars.
* `spark.executor.heartbeatInterval` (default: `10s`) - the interval after which an executor reports heartbeat and metrics for active tasks to the driver. Refer to <<heartbeats-and-partial-metrics, Sending heartbeats and partial metrics for active tasks>>.
* `spark.executor.id`
* `spark.executor.instances` - the number of executors. When greater than `0`, it disables link:spark-dynamic-allocation.adoc[Dynamic Allocation].
* `spark.executor.logs.rolling.maxSize`
* `spark.executor.logs.rolling.maxRetainedFiles`
* `spark.executor.logs.rolling.strategy`
* `spark.executor.logs.rolling.time.interval`
* `spark.executor.memory` (default: `1024` mebibytes) - the amount of memory to use per executor process (equivalent to link:spark-sparkcontext.adoc#environment-variables[SPARK_EXECUTOR_MEMORY] environment variable). See <<memory, Executor Memory - spark.executor.memory setting>> in this document.
* `spark.executor.port`
* `spark.executor.uri` - equivalent to `SPARK_EXECUTOR_URI`
* `spark.repl.class.uri` (default: `null`) used when in `spark-shell` to create REPL ClassLoader to load new classes defined in the Scala REPL as a user types code.
+
Enable `INFO` logging level for `org.apache.spark.executor.Executor` logger to have the value printed out to the logs:
+
```
INFO Using REPL class URI: [classUri]
```
* `spark.akka.frameSize` (default: `128` MB, maximum: `2047` MB) - the configured max frame size for Akka messages. If a task result is bigger, executors use link:spark-blockmanager.adoc[block manager] to send results back.
* `spark.driver.maxResultSize` (default: `1g`)

CAUTION: FIXME `spark.driver.maxResultSize` is used in few other pages so decide where it should belong to and link the other places.
