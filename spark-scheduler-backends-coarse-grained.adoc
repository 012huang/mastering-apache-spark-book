== CoarseGrainedSchedulerBackend

*CoarseGrainedSchedulerBackend* is a link:spark-scheduler-backends.adoc[scheduler backend] that waits for link:spark-executor-backends-coarse-grained.adoc[coarse-grained executors] to connect to it (using link:spark-rpc.adoc[RPC Environment]) and <<launching-tasks, launch tasks>>. It talks to a cluster manager for resources for executors (register, remove).

This backend holds executors for the duration of the Spark job rather than relinquishing executors whenever a task is done and asking the scheduler to launch a new executor for each new task.

It requires a link:spark-taskscheduler.adoc[Task Scheduler], and a link:spark-rpc.adoc[RPC Environment].

It uses link:spark-scheduler-listeners.adoc[Listener Bus].

It registers <<CoarseGrainedScheduler, CoarseGrainedScheduler RPC Endpoint>> that executors use for RPC communication.

It tracks:

* the total number of cores in the cluster (using `totalCoreCount`)
* the total number of executors that are currently registered
* executors (`ExecutorData`)
* executors to be removed (`executorsPendingToRemove`)
* hosts and the number of possible tasks possibly running on them
* lost executors with no real exit reason
* tasks per slaves (`taskIdsOnSlave`)

CAUTION: FIXME Where are these counters used?

[TIP]
====
Enable `DEBUG` logging level for `org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend=DEBUG
```
====

=== [[launching-tasks]] Launching Tasks

`launchTasks` gets called when making offers (using `makeOffers` method).

CAUTION: FIXME Why is there `Seq[Seq[TaskDescription]]`?

Tasks are serialized and their size checked to fit <<settings, spark.akka.frameSize>>.

If the serialized task's size is over the frame size, the TaskSetManager of the task is called using link:spark-tasksetmanager.adoc#aborting-taskset[TaskSetManager.abort] method. It is link:spark-taskscheduler.adoc[TaskSchedulerImpl] to be queried for the TaskSetManager of the task.

CAUTION: FIXME At that point, tasks have their executor assigned. When and how did that happen?

The number of free cores of the executor for the task is decremented (by link:spark-taskscheduler.adoc#settings[spark.task.cpus]) and link:spark-executor-backends-coarse-grained.adoc#LaunchTask[LaunchTask] message is sent to it.

=== [[defaultParallelism]] Default Level of Parallelism

The default parallelism is controlled by <<settings, spark.default.parallelism>> or is at least `2` or `totalCoreCount`.

=== [[reviveOffers]] reviveOffers

It sends <<ReviveOffers, ReviveOffers>> message to `driverEndpoint`.

CAUTION: FIXME Image

=== Stopping

`stop()` method stops <<CoarseGrainedScheduler, CoarseGrainedScheduler RPC Endpoint>> and executors (using `stopExecutors()`).

NOTE: When called with no `driverEndpoint` both `stop()` and `stopExecutors()` do nothing. `driverEndpoint` is initialized in `start` and the initialization order matters.

It prints INFO to the logs:

```
INFO Shutting down all executors
```

It then sends <<StopExecutors, StopExecutors>> message to `driverEndpoint`. It disregards the response.

It sends <<StopDriver, StopDriver>> message to `driverEndpoint`. It disregards the response.

=== [[isReady]] isReady - Delaying Task Launching

`CoarseGrainedSchedulerBackend` comes with its own implementation of `isReady()` method (see link:spark-scheduler-backends.adoc#contract[SchedulerBackend Contract]).

It starts by ensuring that sufficient resources are available to launch tasks using its own `sufficientResourcesRegistered` method. It gives custom implementations of itself a way to handle the question properly. It assumes resources are available by default.

It prints out the following INFO to the logs:

```
INFO SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: [minRegisteredRatio]
```

`minRegisteredRatio` in the logs above is in the range 0 to 1 (uses <<settings, spark.scheduler.minRegisteredResourcesRatio>>) to denote the minimum ratio of registered resources to total expected resources before submitting tasks.

In case there are no sufficient resources available yet (the above requirement does not hold), it checks whether the time from the startup passed <<settings, spark.scheduler.maxRegisteredResourcesWaitingTime>> to give a way to submit tasks (despite minRegisteredRatio not being reached yet).

You should see the following INFO in the logs:

```
INFO SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: [maxRegisteredWaitingTimeMs](ms)
```

Otherwise, it keeps delaying task launching until enough resources register or <<settings, spark.scheduler.maxRegisteredResourcesWaitingTime>> passes.

=== [[CoarseGrainedScheduler]] CoarseGrainedScheduler RPC Endpoint

When CoarseGrainedSchedulerBackend starts, it registers *CoarseGrainedScheduler* RPC endpoint (`driverEndpoint` internal field).

It is called *standalone scheduler's driver endpoint* internally.

CAUTION: FIXME Why is the field's name `driverEndpoint`?

It tracks:

* Executor addresses (host and port) for executors (`addressToExecutorId`) - it is set when an executor connects to register itself. See <<RegisterExecutor, RegisterExecutor>> RPC message.
* Total number of core count (`totalCoreCount`) - the sum of all cores on all executors. See <<RegisterExecutor, RegisterExecutor>> RPC message.
* The number of executors available (`totalRegisteredExecutors`). See <<RegisterExecutor, RegisterExecutor>> RPC message.
* `ExecutorData` for each registered executor (`executorDataMap`). See <<RegisterExecutor, RegisterExecutor>> RPC message.

It uses `driver-revive-thread` daemon single-thread thread pool for ...FIXME

CAUTION: FIXME A potential issue with `driverEndpoint.asInstanceOf[NettyRpcEndpointRef].toURI` - doubles `spark://` prefix.

* `spark.scheduler.revive.interval` (default: `1s`) - time between reviving offers.

=== [[messages]] RPC Messages

====  KillTask(taskId, executorId, interruptThread)

==== RemoveExecutor

==== RetrieveSparkProps

==== [[ReviveOffers]] ReviveOffers

`ReviveOffers` calls `makeOffers()` that makes fake resource offers on all executors that are alive.

CAUTION: FIXME When is an executor alive? What other states can an executor be in?

CAUTION: FIXME What is *fake resource offers*?

A collection of `WorkerOffer` for each active executor is offered to `TaskSchedulerImpl` (refer to link:spark-taskschedulerimpl.adoc#resourceOffers[resourceOffers] in TaskSchedulerImpl).

It then <<launching-tasks, launches tasks>> for the resource offers.

==== StatusUpdate(executorId, taskId, state, data)

==== [[StopDriver]] StopDriver

`StopDriver` message stops the RPC endpoint.

==== StopExecutors

`StopExecutors` message is receive-reply and blocking. When received, the following INFO message appears in the logs:

```
INFO Asking each executor to shut down
```

It then sends a link:spark-executor-backends-coarse-grained.adoc#StopExecutor[StopExecutor] message to every registered executor (from `executorDataMap`).

==== [[RegisterExecutor]] RegisterExecutor

`RegisterExecutor(executorId, executorRef, hostPort, cores, logUrls)` is sent by link:spark-executor-backends-coarse-grained.adoc[CoarseGrainedExecutorBackend] to register itself.

.Executor registration (RegisterExecutor RPC message flow)
image::images/CoarseGrainedSchedulerBackend-RegisterExecutor-event.png[align="center"]

Only one executor can register as `executorId`.

```
INFO Registered executor [executorRef] ([executorAddress]) with ID [executorId]
```

It does internal bookkeeping like updating `addressToExecutorId`, `totalCoreCount`, and `totalRegisteredExecutors`, `executorDataMap`.

When `numPendingExecutors` is more than `0`, the following is printed out to the logs:

```
DEBUG Decremented number of pending executors ([numPendingExecutors] left)
```

It replies with `RegisteredExecutor(executorAddress.host)` (consult link:spark-executor-backends.adoc#messages[RPC Messages] of CoarseGrainedExecutorBackend).

It then announces the new executor by posting `SparkListenerExecutorAdded` on link:spark-scheduler-listeners.adoc#listener-bus[LiveListenerBus].

`makeOffers` is called. It is described as _"Make fake resource offers on all executors"_.

CAUTION: FIXME What are *fake resource offers*? Review `makeOffers` in `DriverEndpoint`.

=== [[settings]] Settings

* `spark.akka.frameSize` (default: `128` and not greater than `2047m` - `200k` for extra data in an Akka message) - largest frame size for Akka messages (serialized tasks or task results) in MB.
* `spark.default.parallelism` (default: maximum of `totalCoreCount` and 2) - link:spark-scheduler-backends.adoc#defaultParallelism[default parallelism] for the scheduler backend.
* `spark.scheduler.minRegisteredResourcesRatio` (default: `0`) - a double value between 0 and 1 (including) that controls the minimum ratio of (registered resources / total expected resources) before submitting tasks. See <<isReady, isReady>>.
* `spark.scheduler.maxRegisteredResourcesWaitingTime` (default: `30s`) - the time to wait for sufficient resources available. See <<isReady, isReady>>.
