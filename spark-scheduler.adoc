== DAGScheduler

[NOTE]
====
The introduction that follows was highly influenced by the scaladoc of https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala[org.apache.spark.scheduler.DAGScheduler]. As DAGScheduler is a private class it does not appear in the official API documentation. You are strongly encouraged to read https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala[the sources] and read the page afterwards.

_"Reading the sources"_, you say?! Yes, I _am_ kidding!
====

=== Introduction

*DAGScheduler* is the present and only scheduling layer in Apache Spark that implements stage-oriented scheduling, i.e. RDD actions trigger jobs that become stages with parallel tasks (see link:spark-execution-model.adoc[Execution Model]).

DAGScheduler does three things in Spark (thorough explanations follow):

* It computes an *execution DAG*, i.e. DAG of stages, for a job.
* It determines the <<preferred-locations, preferred locations>> to run each task on.
* It handles failures due to *shuffle output files* being lost.

It computes https://en.wikipedia.org/wiki/Directed_acyclic_graph[a directed acyclic graph (DAG)] of stages for each job, keeps track of which RDDs and stage outputs are materialized, and finds a minimal schedule to run jobs. It then submits stages to link:spark-taskscheduler.adoc[TaskScheduler] that spawns tasks to compute results (link:spark-local.adoc[locally] or link:spark-cluster.adoc[on cluster]).

In addition to coming up with the execution DAG, DAGScheduler also determines the preferred locations to run each task on, based on the current cache status, and passes the information to link:spark-taskscheduler.adoc[TaskScheduler].

Furthermore, it handles failures due to shuffle output files being lost, in which case old stages may need to be resubmitted. Failures within a stage that are not caused by shuffle file loss are handled by the TaskScheduler itself, which will retry each task a small number of times before cancelling the whole stage.

DAGScheduler uses an *event queue architecture* in which a thread can post `DAGSchedulerEvent` events, e.g. a new job or stage being submitted, that DAGScheduler reads and executes sequentially. See the section <<event-loop, Internal Event Loop - dag-scheduler-event-loop>>.

[TIP]
====
Turn `DEBUG` or more detailed `TRACE` logging to see what happens inside `DAGScheduler`.

Add the following line to `conf/log4j.properties` with requested log level - `DEBUG` or `TRACE`:

```
log4j.logger.org.apache.spark.scheduler.DAGScheduler=TRACE
```
====

DAGScheduler needs link:spark-sparkcontext.adoc[SparkContext], link:spark-taskscheduler.adoc[Task Scheduler], link:spark-scheduler-listeners.adoc[Listener Bus], link:spark-service-mapoutputtracker.adoc[MapOutputTracker] and link:spark-blockmanager.adoc[Block Manager] for work. However, at the very minimum, DAGScheduler needs SparkContext only (and asks SparkContext for the other services).

DAGScheduler reports metrics about its execution (refer to the section <<metrics, Metrics>>).

=== [[jobs]] Jobs

A *job* (aka _action job_ or _active job_) is a top-level work item (computation) submitted to DAGScheduler to <<stages, compute a stage>>.

.A single actions triggers a single jobs
image::diagrams/action-job.png[align="center"]

Computing a job is equivalent to computing the partitions of the RDD the action has been executed upon.

.Computing a job is computing the partitions of an RDD
image::diagrams/rdd-job-partitions.png[align="center"]

Note that not all partitions have always to be computed for <<ResultStage, ResultStages>> for actions like `first()` and `lookup()`.

Internally, a job is represented by an instance of https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/ActiveJob.scala[private[spark\] class org.apache.spark.scheduler.ActiveJob].

[CAUTION]
====
FIXME

* Where are instances of ActiveJob used?
====

A job can be one of two logical types (that are only distinguished by an internal `finalStage` field of `ActiveJob`):

* *Map-stage job* that computes the map output files for a <<ShuffleMapStage, ShuffleMapStage>> (for `submitMapStage`) before any downstream stages are submitted.
+
It is also used for <<adaptive-query-planning, adaptive query planning>>, to look at map output statistics before submitting later stages.
* *Result job* that computes a <<ResultStage, ResultStage>> to execute an action.

Jobs track how many partitions have already been computed (using `finished` array of `Boolean` elements).

==== [[job-listener]] Job Listener and Completion Events

You can listen for job completion or failure events after submitting a job to the DAGScheduler using `JobListener`.

The job listener is notified each time a task succeeds, as well as if the whole job fails (and no further `taskSucceeded` events will happen).

The following are the job listeners used:

* `JobWaiter` waits until DAGScheduler completes the job and passes the results of tasks to a `resultHandler` function.
* `ApproximateActionListener` FIXME

=== [[stages]] Stages

A *stage* is a set of parallel tasks, one per a partition of an RDD, that compute partial results of a function executed as part of a Spark job.

.Stage, tasks and submitting a job
image::diagrams/stage-tasks.png[align="center"]

A stage can depend on other stages and so submitting a single job can trigger execution of a series of dependent parent stages.

.Submitting a job triggers execution of the stage and its parent stages
image::diagrams/job-stage.png[align="center"]

There are two types of stages:

* <<ShuffleMapStage, ShuffleMapStage>> is an intermediate stage (in the execution DAG) that produces data for other stage(s). It writes *map output files* for a shuffle. It can also be the final stage in a job in <<adaptive-query-planning, adaptive query planning>>.
* <<ResultStage, ResultStage>> is the final stage that executes link:spark-rdd.adoc#actions[a Spark action] in a user program by running a function on an RDD.

A stage has an *id*. When a stage is created, DAGScheduler increments internal counter `nextStageId` to track the number of stage submissions.

When a job is submitted, a new stage is created with the parent ShuffleMapStages linked -- they can be created from scratch or linked to, i.e. shared, if other jobs use them already.

.DAGScheduler and Stages for a job
image::diagrams/scheduler-job-shuffles-result-stages.png[align="center"]

A stage knows about the jobs it belongs to (using `jobIds` internal field).

DAGScheduler splits up a job into a collection of stages. Each stage contains a sequence of link:spark-rdd.adoc[narrow transformations] that can be completed without link:spark-rdd-shuffle.adoc[shuffling] the entire data set, separated at *shuffle boundaries*, i.e. where shuffle occurs. Stages are thus a result of breaking the RDD graph at shuffle boundaries.

Shuffle boundaries introduce a barrier where stages/tasks must wait for the previous stage to finish before they fetch map outputs.

.DAGScheduler splits a job into stages
image::diagrams/scheduler-job-splits-into-stages.png[align="center"]

RDD operations with link:spark-rdd.adoc[narrow dependencies], like `map()` and `filter()`, are pipelined together into one set of tasks in each stage, but operations with shuffle dependencies require multiple stages, i.e. one to write a set of map output files, and another to read those files after a barrier.

In the end, every stage will have only shuffle dependencies on other stages, and may compute multiple operations inside it. The actual pipelining of these operations happens in the `RDD.compute()` functions of various RDDs, e.g. `MappedRDD`, `FilteredRDD`, etc.

DAGScheduler runs stages in topological order.

`DAGScheduler` keeps track of stages in different execution states:

* waiting
* running
* failed

At some point of time in a stage's life, every partition of the stage gets transformed into a task - <<spark-taskscheduler.adoc#shufflemaptask, ShuffleMapTask>> or `ResultTask` for `ShuffleMapStage` and `ResultStage`, respectively.

Partitions are computed in jobs, and result stages may not always need to compute all partitions in their target RDD, e.g. for actions like `first()` and `lookup()`.

`DAGScheduler` prints the following INFO message when there are tasks to submit:

```
INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (ShuffledRDD[86] at reduceByKey at <console>:24)
```

There is also the following DEBUG message with pending partitions:

```
DEBUG DAGScheduler: New pending partitions: Set(0)
```

Tasks are later submitted to link:spark-taskscheduler.adoc[Task Scheduler] (via `taskScheduler.submitTasks`).

When no tasks in a stage can be submitted, the following DEBUG message shows in the logs:

```
FIXME
```

Each stage has also a `firstJobId`, identifying the job that first submitted the stage.

==== [[stage-sharing]] ShuffleMapStage sharing

ShuffleMapStages can be shared across multiple jobs, if these jobs reuse the same RDDs.

When a ShuffleMapStage is submitted to DAGScheduler to execute, `getShuffleMapStage` is called (as part of <<MapStageSubmitted, handleMapStageSubmitted>> while `newResultStage` - note the `new` part - for <<JobSubmitted, handleJobSubmitted>>).

[source, scala]
----
scala> val rdd = sc.parallelize(0 to 5).map((_,1)).sortByKey()  // <1>

scala> rdd.count  // <2>

scala> rdd.count  // <3>
----
<1> Shuffle at `sortByKey()`
<2> Submits a job with two stages with two being executed
<3> Intentionally repeat the last action that submits a new job with two stages with one being shared as already-being-computed

.Skipped Stages are already-computed ShuffleMapStages
image::images/dagscheduler-webui-skipped-stages.png[align="center"]

==== [[ShuffleMapStage]] ShuffleMapStage

A *ShuffleMapStage* (aka *shuffle map stage*, or simply *map stage*) is an intermediate stage in the execution DAG that produces data for link:spark-rdd-shuffle.adoc[shuffle operation]. It is an input for the other following stages in the DAG of stages. That is why it is also called a *shuffle dependency's map side* (see link:spark-rdd-dependencies.adoc#shuffle-dependency[ShuffleDependency])

ShuffleMapStages usually contain multiple pipelined operations, e.g. `map` and `filter`, before shuffle operation.

CAUTION: FIXME: Show the example and the logs + figures

A single ShuffleMapStage can be part of many jobs -- refer to the section <<stage-sharing, ShuffleMapStage sharing>>.

A ShuffleMapStage is a stage with a link:spark-rdd-dependencies.adoc#shuffle-dependency[ShuffleDependency] - the shuffle that it is part of and `outputLocs` and `numAvailableOutputs` track how many map outputs are ready.

NOTE: ShuffleMapStages can also be submitted independently as jobs with `DAGScheduler.submitMapStage` for <<adaptive-query-planning, Adaptive Query Planning>>.

When executed, ShuffleMapStages save *map output files* that can later be fetched by reduce tasks.

CAUTION: FIXME Figure with ShuffleMapStages saving files

The number of the partitions of an RDD is exactly the number of the tasks in a ShuffleMapStage.

The output locations (`outputLocs`) of a ShuffleMapStage are the same as used by its link:spark-rdd-dependencies.adoc#shuffle-dependency[ShuffleDependency]. Output locations can be missing, i.e. partitions have not been cached or are lost.

ShuffleMapStages are registered to DAGScheduler that tracks the mapping of shuffles (by their ids from SparkContext) to corresponding ShuffleMapStages that compute them, stored in `shuffleToMapStage`.

A new ShuffleMapStage is created from an input <<spark-rdd-dependencies.adoc#shuffle-dependency, ShuffleDependency>> and a job's id (in `DAGScheduler#newOrUsedShuffleStage`).

FIXME: Where's `shuffleToMapStage` used?

* getShuffleMapStage - see <<stage-sharing, Stage sharing>>
* getAncestorShuffleDependencies
* cleanupStateForJobAndIndependentStages
* FetchFailed in `handleTaskCompletion`
* handleExecutorLost

When there is no ShuffleMapStage for a shuffle id (of a ShuffleDependency), one is created with the ancestor shuffle dependencies of the RDD (of a ShuffleDependency) that are registered to link:spark-service-mapoutputtracker.adoc[MapOutputTrackerMaster].

FIXME Where is `ShuffleMapStage` used?

* newShuffleMapStage - the proper way to create shuffle map stages (with the additional setup steps)
* <<MapStageSubmitted, MapStageSubmitted>>
* `getShuffleMapStage` - see <<stage-sharing, Stage sharing>>

[CAUTION]
====
FIXME

* What's `ShuffleMapStage.outputLocs` and `MapStatus`?
* `newShuffleMapStage`
====

==== [[ResultStage]] ResultStage

A *ResultStage* is the final stage in running a job (as a result of executing an RDD action) that applies a function on one or more partitions of the target RDD and returns a value of the action.

.Job creates ResultStage as the first stage
image::diagrams/dagscheduler-job-resultstage.png[align="center"]

To calculate a list of the parent stages of a stage DAGScheduler uses an RDD and a job's id. The parent stages are actually only the instances of <<ShuffleMapStage, ShuffleMapStage>>.

...FIXME...IMAGE with parent stages being ShuffleMapStage only.

It then traverses the RDD's dependencies and for every link:spark-rdd-dependencies.adoc#shuffle-dependency[ShuffleDependency] gets or creates a new <<ShuffleMapStage, ShuffleMapStage>>.

...FIXME...IMAGE with ShuffleDependencies queried

=== [[runJob]] RDD, job execution, stages, and partitions

When DAGScheduler schedules a job as a result of link:spark-rdd.adoc#actions[executing an action on a RDD] or link:spark-sparkcontext.adoc#running-jobs[calling SparkContext.runJob() method directly], it spawns parallel tasks to compute (partial) results per partition.

The number of partition in a job depends on the type of a stage - <<ResultStage, ResultStage>> or <<ShuffleMapStage, ShuffleMapStage>>.

A job starts with a single target RDD, but can ultimately include other RDDs that are all link:spark-rdd#lineage[the target RDD's lineage].

`DAGScheduler.runJob` triggers `DAGScheduler.submitJob` and then waits till a result comes using `JobWaiter` object. A job can succeed or fail. Since JobWaiter object is a `JobListener` it gets notifications about `taskSucceeded` and `jobFailed`. When the total number of tasks (that equals the number of partitions to compute) equals the number of `taskSucceeded`, the JobWaiter instance is marked succeeded. A `jobFailed` event marks the JobWaiter instance failed.

When a job succeeds, the following INFO shows up in the logs:

```
Job %d finished: %s, took %f s
```

When a job fails, the following INFO shows up in the logs:

```
Job %d failed: %s, took %f s
```

Job ids are tracked by DAGScheduler and incremented by one every `submitJob`.

Ultimately, `submitJob` posts `JobSubmitted` event on <<event-loop, dag-scheduler-event-loop>> (that releases the current thread and let the event loop handle the event on a separate thread - asynchronously).

=== [[event-loop]] Internal Event Loop - dag-scheduler-event-loop

`DAGScheduler.eventProcessLoop` (of type `DAGSchedulerEventProcessLoop`) - is the event process loop to which Spark (by <<runJob, DAGScheduler.submitJob>>) posts jobs to schedule their execution. Later on, link:spark-taskscheduler.adoc#tasksetmanager[TaskSetManager] talks back to DAGScheduler to inform about the status of the tasks using the same "communication channel".

...IMAGE...FIXME

Internally, DAGSchedulerEventProcessLoop uses https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/LinkedBlockingDeque.html[java.util.concurrent.LinkedBlockingDeque] blocking deque that grows indefinitely (i.e. up to https://docs.oracle.com/javase/7/docs/api/java/lang/Integer.html#MAX_VALUE[Integer.MAX_VALUE] events).

The name of the single "logic" thread that reads events and takes decisions is *dag-scheduler-event-loop*.

```
"dag-scheduler-event-loop" #89 daemon prio=5 os_prio=31 tid=0x00007f809bc0a000 nid=0xc903 waiting on condition [0x0000000125826000]
```

The following are the current types of `DAGSchedulerEvent` events that are handled by `DAGScheduler`:

* <<JobSubmitted, JobSubmitted>> - posted when an action job is submitted to DAGScheduler (via `submitJob` or `runApproximateJob`).
* <<MapStageSubmitted, MapStageSubmitted>> - posted when a ShuffleMapStage is submitted (via `submitMapStage`).
* `StageCancelled`
* `JobCancelled`
* `JobGroupCancelled`
* `AllJobsCancelled`
* `BeginEvent` - posted when `TaskSetManager` reports that a task is starting.
+
`dagScheduler.handleBeginEvent` is executed in turn.
* `GettingResultEvent` - posted when `TaskSetManager` reports that a task has completed and results are being fetched remotely.
+
`dagScheduler.handleGetTaskResult` executes in turn.
* <<CompletionEvent, CompletionEvent>> - posted when link:spark-taskscheduler.adoc#tasksetmanager[TaskSetManager] reports that a task has completed successfully or failed.
* `ExecutorAdded`
* `ExecutorLost`
* `TaskSetFailed`
* `ResubmitFailedStages`

[CAUTION]
====
FIXME

* What is an approximate job (as in `DAGScheduler.runApproximateJob`)?
* statistics? `MapOutputStatistics`?
====

==== [[MapStageSubmitted]] MapStageSubmitted and handleMapStageSubmitted

When a *MapStageSubmitted* event is posted, it triggers execution of `DAGScheduler.handleMapStageSubmitted` method.

.DAGScheduler.handleMapStageSubmitted handles MapStageSubmitted events
image::diagrams/scheduler-handlemapstagesubmitted.png[align="center"]

It is called with a job id (for a new job to be created), a link:spark-rdd-dependencies.adoc#shuffle-dependency[ShuffleDependency], and a JobListener.

CAUTION: FIXME `clearCacheLocs` clears an internal field is called in handle* methods. How many instances of DAGScheduler are created and when?

You should see the following INFOs in the logs:

```
Got map stage job %s (%s) with %d output partitions
Final stage: [finalStage] ([finalStage.name])
Parents of final stage: [finalStage.parents]
Missing parents: [list of stages]
```

A SparkListenerJobStart event is posted to `listenerBus` (so other event listeners know about the event - not only DAGScheduler).

The execution procedure of MapStageSubmitted events is then exactly (FIXME ?) as for <<JobSubmitted, JobSubmitted>>.

[TIP]
====
The difference between `handleMapStageSubmitted` and <<JobSubmitted, handleJobSubmitted>>:

* `handleMapStageSubmitted` has `ShuffleDependency` among the input parameters while `handleJobSubmitted` has `finalRDD`, `func`, and `partitions`.
* `handleMapStageSubmitted` initializes `finalStage` as `getShuffleMapStage(dependency, jobId)` while `handleJobSubmitted` as `finalStage = newResultStage(finalRDD, func, partitions, jobId, callSite)`
* `handleMapStageSubmitted` INFO logs `Got map stage job %s (%s) with %d output partitions` with `dependency.rdd.partitions.length` while `handleJobSubmitted` does `Got job %s (%s) with %d output partitions` with `partitions.length`.
* FIXME: Could the above be cut to `ActiveJob.numPartitions`?
* `handleMapStageSubmitted` adds a new job with `finalStage.addActiveJob(job)` while `handleJobSubmitted` sets with `finalStage.setActiveJob(job)`.
* `handleMapStageSubmitted` checks if the final stage has already finished, tells the listener and removes it using the code:
+
[source, scala]
----
if (finalStage.isAvailable) {
  markMapStageJobAsFinished(job, mapOutputTracker.getStatistics(dependency))
}
----
====

==== [[JobSubmitted]] JobSubmitted and handleJobSubmitted

When DAGScheduler receives *JobSubmitted* event it calls `dagScheduler.handleJobSubmitted` method.

`handleJobSubmitted` has access to the final RDD, the partitions to compute, and the JobListener for the job, i.e. JobWaiter.

It creates a new <<ResultStage, ResultStage>> (FIXME review `newResultStage`) and instantiates `ActiveJob`.

You should see the following INFOs in the logs:

```
scala> sc.parallelize(0 to 5, 2).map((_,1)).reduceByKey(_ + _).count
...
INFO DAGScheduler: Got job 1 (count at <console>:25) with 2 output partitions
INFO DAGScheduler: Final stage: ResultStage 2 (count at <console>:25)
INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
...
```

Then, the stage is told about the ActiveJob instance and some housekeeping is performed to track the job.

`SparkListenerJobStart` event is posted to `listenerBus` (so other event listeners know about the event - not only DAGScheduler).

When DAGScheduler executes a job it first submits the final stage (using `DAGScheduler.submitStage(finalStage)`) that in turn submits any missing parents of the stage (recursively).

Two DEBUG messages show up in the logs:

```
DEBUG DAGScheduler: submitStage(ResultStage 2)
DEBUG DAGScheduler: missing: List(ShuffleMapStage 1)
```

When the current stage has no parent stages to submit, it is submitted and the INFO message shows up in the logs:

```
INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at map at <console>:25), which has no missing parents
```

CAUTION: FIXME: Review `getMissingParentStages`

And <<submitMissingTasks, submitMissingTasks>> is called. It is the moment when the stage's parents are available.

If however there are missing parent stages for the stage, all stages are `submitStage`.

If there's no active job for a stage, the stage and all the dependent jobs are aborted.

```
Job aborted due to stage failure: No active job for stage [stage.id]
```

No dependent jobs lead to the INFO message:

```
Ignoring failure of [failedStage] because all jobs depending on it are done
```

`submitWaitingStages()` called at the end.

===== [[submitMissingTasks]] submitMissingTasks

`DAGScheduler.submitMissingTasks` is called when the parent stages of the current stage are already finished and it is now possible to run tasks for the current stage.

In the logs you should see the following DEBUG message:

```
DEBUG DAGScheduler: submitMissingTasks(ResultStage 4)
```

The method marks the current stage running.

`outputCommitCoordinator.stageStart` is called. FIXME

`SparkListenerStageSubmitted` is posted.

`closureSerializer.serialize` is called to calculate `taskBinaryBytes` that is then `sc.broadcast`.

For each partition to compute for the stage, a collection of <<spark-taskscheduler.adoc#shufflemaptask, ShuffleMapTask>> and
`ResultTask` is created.

...IMAGE...FIXME...DAGScheduler calls taskScheduler.submitTasks

The following INFO and DEBUG messages are in the logs:

```
INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at map at <console>:25)
DEBUG DAGScheduler: New pending partitions: Set(0, 1)
```

The task collection becomes a `TaskSet` for `taskScheduler.submitTasks`.

In case of no tasks to be submitted for a stage, a DEBUG message shows up in the logs.

For ShuffleMapStage:

```
DEBUG DAGScheduler: Stage [stage] is actually done; (available: ${stage.isAvailable},available outputs: ${stage.numAvailableOutputs},partitions: ${stage.numPartitions})
```

For ResultStage:

```
DEBUG DAGScheduler: Stage ${stage} is actually done; (partitions: ${stage.numPartitions})
```

==== [[CompletionEvent]] CompletionEvent

CAUTION: FIXME Unfinished

DAGScheduler is told about a task end through `DAGScheduler.handleTaskCompletion` event handler.

FIXME Who's calling the handle and when?

It causes `updateAccumulators` call.

When a task has finished, it triggers  link:spark-taskscheduler.adoc#tasksetmanager[TaskSetManager] to send a `CompletionEvent` message to DAGScheduler.

FIXME Communication Flow Diagram

Internally, link:spark-taskscheduler.adoc#tasksetmanager[TaskSetManager] calls `DAGScheduler.taskEnded` to post the `CompletionEvent` event on `eventProcessLoop`.

* `DAGScheduler.onReceive` calls `dagScheduler.handleTaskCompletion(completion)`

=== [[stage-attempts]] Fault recovery - stage attempts

A single stage can be re-executed in multiple *attempts* due to fault recovery. The number of attempts is configured (FIXME).

If `TaskScheduler` reports that a task failed because a map output file from a previous stage was lost, the DAGScheduler resubmits that lost stage. This is detected through a `CompletionEvent` with `FetchFailed`, or an `ExecutorLost` event. `DAGScheduler` will wait a small amount of time to see whether other nodes or tasks fail, then resubmit `TaskSets` for any lost stage(s) that compute the missing tasks.

Please note that tasks from the old attempts of a stage could still be running.

A stage object tracks multiple `StageInfo` objects to pass to Spark listeners or the web UI.

The latest `StageInfo` for the most recent attempt for a stage is accessible through `latestInfo`.

=== [[cache-tracking]] Cache Tracking

DAGScheduler tracks which RDDs are cached to avoid recomputing them and likewise remembers which shuffle map stages have already produced output files to avoid redoing the map side of a shuffle.

The internal `cacheLocs` is a map with keys being RDD ids and the values being arrays indexed by partition numbers. Each array value is the set of locations where that RDD partition is cached.

[CAUTION]
====
FIXME:

* A diagram would be awesome.
* Review the use of `cacheLocs`
====

If link:spark-rdd-caching.adoc[a storage level of an RDD is NONE], there is no need to get locations from link:spark-blockmanager.adoc[block manager]. Otherwise, `RDDBlockId` is created and Block Manager gets asked for locations.

CAUTION: FIXME Review `TaskLocation`

=== [[preferred-locations]] Preferred Locations

DAGScheduler computes where to run each task in a stage based on link:spark-rdd.adoc#preferred-locations[the preferred locations of its underlying RDDs], or <<cache-tracking, the location of cached or shuffle data>>.

=== [[adaptive-query-planning]] Adaptive Query Planning

See https://issues.apache.org/jira/browse/SPARK-9850[SPARK-9850 Adaptive execution in Spark] for the design document. The work is currently in progress.

https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala#L661[DAGScheduler.submitMapStage] method is used for adaptive query planning, to run map stages and look at statistics about their outputs before submitting downstream stages.

=== [[metrics]] Metrics

Spark's DAGScheduler uses link:spark-metrics.adoc[Spark Metrics System] (via `DAGSchedulerSource`) to report metrics about its execution.

The name of the source is *DAGScheduler*.

It emits the following numbers:

* stage / failedStages - the number of failed stages
* stage / runningStages - the number of running stages
* stage / waitingStages - the number of waiting stages
* job / allJobs - the number of all jobs
* job / activeJobs - the number of active jobs

=== ScheduledExecutorService daemon services

DAGScheduler uses the following ScheduledThreadPoolExecutors (with the policy of removing cancelled tasks from a work queue at time of cancellation):

* `dag-scheduler-message` - a daemon thread pool using `j.u.c.ScheduledThreadPoolExecutor` with core pool size `1`. It is used to post `ResubmitFailedStages` when `FetchFailed` is reported.

They are created using `ThreadUtils.newDaemonSingleThreadScheduledExecutor` method that uses Guava DSL to instantiate a ThreadFactory.
