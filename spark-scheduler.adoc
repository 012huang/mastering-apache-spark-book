== DAGScheduler

[NOTE]
====
The introduction that follows is an almost exact copy of scaladoc of https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala[org.apache.spark.scheduler.DAGScheduler]. As DAGScheduler is a private class it does not appear in the official API documentation. You are strongly encouraged to read https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala[the sources] and read the page afterwards.

_"Reading the sources"_?! Yes, I _am_ kidding!
====

=== Introduction

*DAGScheduler* is the present and only scheduling layer in Apache Spark that implements stage-oriented scheduling, i.e. actions trigger jobs that become stages with tasks (see link:spark-execution-model.adoc[Execution Model]).

DAGScheduler does three things in Spark (detailed explanations follow):

* It computes a *DAG of stages* for a job.
* It determines the <<preferred-locations, preferred locations>> to run each task on.
* It handles failures due to *shuffle output files* being lost.

It computes https://en.wikipedia.org/wiki/Directed_acyclic_graph[a directed acyclic graph (DAG)] of stages for each job, keeps track of which RDDs and stage outputs are materialized, and finds a minimal schedule to run the job. It then submits stages to link:spark-taskscheduler.adoc[TaskScheduler] that spawns tasks to compute results (link:spark-local.adoc[locally] or link:spark-cluster.adoc[on cluster]).

In addition to coming up with the DAG of stages, DAGScheduler also determines the preferred locations to run each task on, based on the current cache status, and passes these to link:spark-taskscheduler.adoc[TaskScheduler].

Furthermore, it handles failures due to shuffle output files being lost, in which case old stages may need to be resubmitted. Failures *within* a stage that are not caused by shuffle file loss are handled by the TaskScheduler, which will retry each task a small number of times before cancelling the whole stage.

*DAGScheduler* uses an event queue architecture in which a thread can post an `DAGSchedulerEvent` event, e.g. a new job being submitted (`JobSubmitted`), that the scheduler reads and executes, sequentially.

[TIP]
====
Add the following line to `conf/log4j.properties` to see what happens under the covers of `DAGScheduler`:

```
log4j.logger.org.apache.spark.scheduler.DAGScheduler=DEBUG
```
====

DAGScheduler has a direct dependency on link:spark-taskscheduler.adoc[Task Scheduler], link:spark-scheduler-listeners.adoc[Listener Bus], spark-service-mapoutputtracker.adoc#MapOutputTrackerMaster[MapOutputTrackerMaster] and link:spark-blockmanager.adoc[Block Manager]. It also  reports metrics about its execution (refer to the section <<metrics, Metrics>>).

=== [[jobs]] Jobs

A *job* (aka _action job_ or _active job_) is a top-level work item (computation) submitted to DAGScheduler to <<stages, compute a stage>> as either <<ResultStage, ResultStage>> that is <<spark-rdd.adoc#actions,a result of executing an action on an RDD>> in a Spark user program or (_still work in progress_) <<ShuffleMapStage, ShuffleMapStage>> for <<adaptive-query-planning, adaptive query planning>>.

.Job "wraps" a stage that can be many other stages
image::diagrams/job-stage.png[align="center"]

The stage of a job can depend on other stages and so execution of a single job can trigger execution of a series of stages.

Computing a job is equivalent to computing the partitions of the RDD the action has been executed upon.

.Computing a job is computing the partitions of an RDD
image::diagrams/rdd-job-partitions.png[align="center"]

Note that not all partitions have always to be computed for <<ResultStage, ResultStages>> for actions like `first()` and `lookup()`.

Internally, a job is represented by an instance of https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/ActiveJob.scala[private[spark\] class org.apache.spark.scheduler.ActiveJob].

[CAUTION]
====
FIXME

* Where are instances of ActiveJob used?
====

A job can be one of two logical types (that are only distinguished by an internal `finalStage` field of `ActiveJob`):

* *Map-stage job* that computes the map output files for a <<ShuffleMapStage, ShuffleMapStage>> (for `submitMapStage`) before any downstream stages are submitted. It is used for <<adaptive-query-planning, adaptive query planning>>, to look at map output statistics before submitting later stages.
* *Result job* that computes a <<ResultStage, ResultStage>> to execute an action

Jobs track how many partitions have already been computed (using `finished` array of `Boolean` field).

==== Job Listener and Events

You can listen for job completion or failure events after submitting a job to the DAGScheduler using `JobListener`.

The job listener is notified each time a task succeeds, as well as if the whole job fails (and no further `taskSucceeded` events will happen).

The following are the job listeners used:

* `JobWaiter` waits until DAGScheduler completes the job and passes the results of tasks to a `resultHandler` function.
* `ApproximateActionListener` FIXME

=== [[stages]] Stages (and a bit on job submission)

When a job is submitted, a new <<ResultStage, ResultStage>> stage is created (with the parent stages linked in `newResultStage`).

The stage is then transformed into a set of (parallel) tasks that all compute results of a function on partitions of a RDD that need to run as part of a Spark job.

Stages are created by breaking the RDD graph at shuffle boundaries. DAGScheduler splits up a job into a collection of one or many stages. Stages are split up at the boundaries where shuffle occurs, called *shuffle boundaries*.

*Shuffle boundaries* introduce a barrier where stages/tasks must wait for the previous stage to finish to fetch outputs.

.DAGScheduler splits a job into stages
image::diagrams/scheduler-job-splits-into-stages.png[align="center"]

RDD operations with link:spark-rdd.adoc[narrow dependencies], like `map()` and `filter()`, are pipelined together into one set of tasks in each stage, but operations with shuffle dependencies require multiple stages, i.e. one to write a set of map output files, and another to read those files after a barrier.

In the end, every stage will have only shuffle dependencies on other stages, and may compute multiple operations inside it. The actual pipelining of these operations happens in the `RDD.compute()` functions of various RDDs, e.g. `MappedRDD`, `FilteredRDD`, etc.

Each stage contains a sequence of link:spark-rdd.adoc[narrow transformations] that can be completed without link:spark-rdd-shuffle.adoc[shuffling] the entire data set, separated at shuffle boundaries.

DAGScheduler runs stages in topological order.

There are two types of stages:

* <<ShuffleMapStage, ShuffleMapStage>> is an intermediate stage (in the execution of a DAG) that produces data for other stage(s). It writes *map output files* for a shuffle.
* <<ResultStage, ResultStage>> is the final stage that executes a Spark action, e.g. `count()`, `save()`, by running a function on an RDD.

.DAGScheduler and Stages for a job
image::diagrams/scheduler-job-shuffles-result-stages.png[align="center"]

The following INFO messages show in the logs:

```
15/10/13 08:30:16 INFO DAGScheduler: Got job 0 (count at <console>:25) with 2 output partitions
15/10/13 08:30:16 INFO DAGScheduler: Final stage: ResultStage 0 (count at <console>:25)
15/10/13 08:30:16 INFO DAGScheduler: Parents of final stage: List()
INFO DAGScheduler: Missing parents: List()
```

[CAUTION]
====
FIXME What's `ShuffleMapStage.outputLocs`?
====

`DAGScheduler` keeps track of stages in different states:

* waiting
* running
* failed

At some point of time in a stage's life, every partition of the stage gets transformed into a task - `ShuffleMapTask` or `ResultTask` for `ShuffleMapStage` and `ResultStage`, respectively.

Partitions are computed in jobs, and result stages may not always need to compute all partitions in their target RDD, e.g. for actions like `first()` and `lookup()`.

`DAGScheduler` prints the following INFO message when there are tasks to submit:

```
INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (ShuffledRDD[86] at reduceByKey at <console>:24)
```

There is also the following DEBUG message with pending partitions:

```
DEBUG DAGScheduler: New pending partitions: Set(0)
```

Tasks are later submitted to link:spark-taskscheduler.adoc[Task Scheduler] (via `taskScheduler.submitTasks`).

When no tasks in a stage can be submitted, the following DEBUG message shows in the logs:

```
FIXME
```

Each stage has also a `firstJobId`, identifying the job that first submitted the stage.

A stage has an *id*.

==== Stage sharing

Stages can be shared across multiple jobs, if these jobs reuse the same RDDs.

FIXME: Where in the code is this used?

==== [[ShuffleMapStage]] ShuffleMapStage

A *ShuffleMapStage* (represented by  https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/ShuffleMapStage.scala[org.apache.spark.scheduler.ShuffleMapStage]) is an intermediate stage (in the execution of a DAG) that produces data for link:spark-rdd-shuffle.adoc[a shuffle] and is an input for the other stages in the DAG of stages.

In other words, ShuffleMapStage is a stage with additional link:spark-rdd-dependencies.adoc#shuffle-dependency[ShuffleDependency] - the shuffle that it is part of.

NOTE: ShuffleMapStages can also be submitted independently as jobs with `DAGScheduler.submitMapStage` for <<adaptive-query-planning, Adaptive Query Planning>>.

The number of the partitions of an RDD is exactly the number of the tasks in a ShuffleMapStage.

The output locations (`outputLocs`) of a ShuffleMapStage are the same as used by its link:spark-rdd-dependencies.adoc#shuffle-dependency[ShuffleDependency]. Output locations can be missing, i.e. partitions have not been cached or are lost.

[CAUTION]
====
FIXME Where is `ShuffleMapStage` used?

* Review `ShuffleMapStage`'s scaladoc
* `newShuffleMapStage`
* `getShuffleMapStage`
* `newOrUsedShuffleStage`
* `handleMapStageSubmitted`
* `shuffleToMapStage` - `private[scheduler]` HashMap
====

==== [[ResultStage]] ResultStage

A *ResultStage* is the final stage that applies a function on some partitions of an RDD to compute the result of an action.

.Job creates ResultStage
image::diagrams/dagscheduler-job-resultstage.png[align="center"]

[CAUTION]
====
FIXME

* How is the stage used?
** DAGScheduler.newResultStage
====

=== [[adaptive-query-planning]] Adaptive Query Planning

See https://issues.apache.org/jira/browse/SPARK-9850[SPARK-9850 Adaptive execution in Spark] for the design document. The work is currently in progress.

https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala#L661[DAGScheduler.submitMapStage] method is used for adaptive query planning, to run map stages and look at statistics about their outputs before submitting downstream stages.

=== [[runJob]] RDD, job execution, stages, and partitions

When DAGScheduler schedules a job as a result of link:spark-rdd.adoc#actions[executing an action on a RDD] or link:spark-sparkcontext.adoc#running-jobs[calling SparkContext.runJob() method directly], it spawns parallel tasks to compute (partial) results per partition.

The number of partition in a job depends on the type of a stage - <<ResultStage, ResultStage>> or <<ShuffleMapStage, ShuffleMapStage>>.

A job starts with a single target RDD, but can ultimately include other RDDs that are all link:spark-rdd#lineage[the target RDD's lineage].

`DAGScheduler.runJob` triggers `DAGScheduler.submitJob` and then waits till a result comes using `JobWaiter` object. A job can succeed or fail. Since JobWaiter object is a `JobListener` it gets notifications about `taskSucceeded` and `jobFailed`. When the total number of tasks (that equals the number of partitions to compute) equals the number of `taskSucceeded`, the JobWaiter instance is marked succeeded. A `jobFailed` event marks the JobWaiter instance failed.

When a job succeeds, the following INFO shows up in the logs:

```
Job %d finished: %s, took %f s
```

When a job fails, the following INFO shows up in the logs:

```
Job %d failed: %s, took %f s
```

Job ids are tracked by DAGScheduler and incremented by one every `submitJob`.

Ultimately, `submitJob` posts `JobSubmitted` event on <<event-loop, dag-scheduler-event-loop>> (that releases the current thread and let the event loop handle the event on a separate thread - asynchronously).

=== [[execution-events]] Execution Events

A `SparkListenerJobStart` event is posted to link:spark-scheduler-listeners.adoc[listenerBus].

CAUTION: FIXME What events are posted and when?

=== [[event-loop]] Event loop - dag-scheduler-event-loop

`DAGScheduler.eventProcessLoop` (of type `DAGSchedulerEventProcessLoop`) - is the event process loop to which Spark (by <<runJob, DAGScheduler.submitJob>>) posts jobs to schedule their execution. Later on, link:spark-taskscheduler.adoc#tasksetmanager[TaskSetManager] talks back to DAGScheduler to inform about the status of the tasks using the same "communication channel".

...IMAGE...FIXME

Internally, DAGSchedulerEventProcessLoop uses https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/LinkedBlockingDeque.html[java.util.concurrent.LinkedBlockingDeque] blocking deque that grows indefinitely (i.e. up to https://docs.oracle.com/javase/7/docs/api/java/lang/Integer.html#MAX_VALUE[Integer.MAX_VALUE] events).

The name of the single "logic" thread that reads events and takes decisions is *dag-scheduler-event-loop*.

```
"dag-scheduler-event-loop" #89 daemon prio=5 os_prio=31 tid=0x00007f809bc0a000 nid=0xc903 waiting on condition [0x0000000125826000]
```

The following are the current types of `DAGSchedulerEvent` events that are handled by `DAGScheduler`:

* <<JobSubmitted, JobSubmitted>> - posted when an action job is submitted to DAGScheduler (via `submitJob` or `runApproximateJob`).
* `MapStageSubmitted` - posted when a shuffle map stage is submitted (via `submitMapStage`). It then calls `DAGScheduler.handleMapStageSubmitted`.
* `StageCancelled`
* `JobCancelled`
* `JobGroupCancelled`
* `AllJobsCancelled`
* `BeginEvent` - posted when `TaskSetManager` reports that a task is starting.
+
`dagScheduler.handleBeginEvent` is executed in turn.
* `GettingResultEvent` - posted when `TaskSetManager` reports that a task has completed and results are being fetched remotely.
+
`dagScheduler.handleGetTaskResult` executes in turn.
* <<CompletionEvent, CompletionEvent>> - posted when link:spark-taskscheduler.adoc#tasksetmanager[TaskSetManager] reports that a task has completed successfully or failed.
* `ExecutorAdded`
* `ExecutorLost`
* `TaskSetFailed`
* `ResubmitFailedStages`

[CAUTION]
====
FIXME

* What is an approximate job (as in `DAGScheduler.runApproximateJob`)?
* statistics? `MapOutputStatistics`?
====

==== [[JobSubmitted]] JobSubmitted and handleJobSubmitted

When DAGScheduler receives *JobSubmitted* event it calls `dagScheduler.handleJobSubmitted` method.

`handleJobSubmitted` has access to the final RDD, the partitions to compute, and the JobListener for the job, i.e. JobWaiter.

It creates a new <<ResultStage, ResultStage>> (FIXME review `newResultStage`) and instantiates `ActiveJob`.

You should see the following INFOs in the logs:

```
Got job %s (%s) with %d output partitions
Final stage: [finalStage] ([finalStage.name])
Parents of final stage: [finalStage.parents]
Missing parents:
```

Then, the stage is told about the ActiveJob instance and some housekeeping is performed to track the job.

`SparkListenerJobStart` event is posted to `listenerBus` (so other listeners know about the event - not only DAGScheduler).

When DAGScheduler executes a job it first submits the final stage (using `DAGScheduler.submitStage(finalStage)`) that in turn submits any missing parents of the stage (recursively).

A DEBUG message shows up in the logs (DAGScheduler logger):

```
submitStage([stage])
```

and then another DEBUG:

```
missing:
```

When the current stage has no parent stages to submit, it is submitted and the INFO message shows up in the logs:

```
INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[9] at map at <console>:25), which has no missing parents
```

CAUTION: FIXME: Review `getMissingParentStages`

And <<submitMissingTasks, submitMissingTasks>> is called. It is the moment when the stage's parents are available.

If however there are missing parent stages for the stage, all stages are `submitStage`.

If there's no active job for a stage, the stage and all the dependent jobs are aborted.

```
Job aborted due to stage failure: No active job for stage [stage.id]
```

No dependent jobs lead to the INFO message:

```
Ignoring failure of [failedStage] because all jobs depending on it are done
```

`submitWaitingStages()` called at the end.

[TIP]
====
Enable TRACE level for DAGScheduler to see statistics for running, waiting, and failed stages, i.e.

```
Checking for newly runnable parent stages
running:
waiting:
failed:
```
====

===== [[submitMissingTasks]] submitMissingTasks

`DAGScheduler.submitMissingTasks` is called when the current stage's parents are available and it can now do its task(s).

```
DEBUG DAGScheduler: submitMissingTasks(ResultStage 4)
```

DAGScheduler finds missing partitions of the target RDD to compute.

The stage is added to an internal set of running stages.

`outputCommitCoordinator.stageStart` is called.

`SparkListenerStageSubmitted` is posted.

`closureSerializer.serialize` is called to calculate `taskBinaryBytes` that is then `sc.broadcast`.

For each partition for the stage, `ShuffleMapTask` and
`ResultTask` are `taskScheduler.submitTasks`.

...IMAGE...FIXME...DAGScheduler calls taskScheduler.submitTasks

The following INFO and DEBUG messages are in the logs:

```
INFO Submitting " + tasks.size + " missing tasks from " + stage + " (" + stage.rdd + ")
DEBUG "New pending partitions: " + stage.pendingPartitions
```

In case of no tasks to be submitted for a stage, the DEBUG message shows up in the logs:

```
DEBUG Stage ${stage} is actually done;
```

==== [[CompletionEvent]] CompletionEvent

CAUTION: FIXME Unfinished

DAGScheduler is told about a task end through `DAGScheduler.handleTaskCompletion` event handler.

FIXME Who's calling the handle and when?

It causes `updateAccumulators` call.

When a task has finished, it triggers  link:spark-taskscheduler.adoc#tasksetmanager[TaskSetManager] to send a `CompletionEvent` message to DAGScheduler.

FIXME Communication Flow Diagram

Internally, link:spark-taskscheduler.adoc#tasksetmanager[TaskSetManager] calls `DAGScheduler.taskEnded` to post the `CompletionEvent` event on `eventProcessLoop`.

* `DAGScheduler.onReceive` calls `dagScheduler.handleTaskCompletion(completion)`

=== [[stage-attempts]] Fault recovery - stage attempts

A single stage can be re-executed in multiple *attempts* due to fault recovery. The number of attempts is configured (FIXME).

If `TaskScheduler` reports that a task failed because a map output file from a previous stage was lost, the DAGScheduler resubmits that lost stage. This is detected through a `CompletionEvent` with `FetchFailed`, or an `ExecutorLost` event. `DAGScheduler` will wait a small amount of time to see whether other nodes or tasks fail, then resubmit `TaskSets` for any lost stage(s) that compute the missing tasks.

Please note that tasks from the old attempts of a stage could still be running.

A stage object tracks multiple `StageInfo` objects to pass to Spark listeners or the web UI.

The latest `StageInfo` for the most recent attempt for a stage is accessible through `latestInfo`.

=== [[cache-tracking]] Cache Tracking

DAGScheduler tracks which RDDs are cached to avoid recomputing them and likewise remembers which shuffle map stages have already produced output files to avoid redoing the map side of a shuffle.

The internal `cacheLocs` is a map with keys being RDD ids and the values being arrays indexed by partition numbers. Each array value is the set of locations where that RDD partition is cached.

[CAUTION]
====
FIXME:

* A diagram would be awesome.
* Review the use of `cacheLocs`
====

If link:spark-rdd-caching.adoc[a storage level of an RDD is NONE], there is no need to get locations from link:spark-blockmanager.adoc[block manager]. Otherwise, `RDDBlockId` is created and Block Manager gets asked for locations.

CAUTION: FIXME Review `TaskLocation`

=== [[preferred-locations]] Preferred Locations

DAGScheduler computes where to run each task in a stage based on link:spark-rdd.adoc#preferred-locations[the preferred locations of its underlying RDDs], or <<cache-tracking, the location of cached or shuffle data>>.

=== [[metrics]] Metrics

Spark's DAGScheduler uses link:spark-metrics.adoc[Spark Metrics System] (via `DAGSchedulerSource`) to report metrics about its execution.

The name of the source is *DAGScheduler*.

It emits the following numbers:

* stage / failedStages - the number of failed stages
* stage / runningStages - the number of running stages
* stage / waitingStages - the number of waiting stages
* job / allJobs - the number of all jobs
* job / activeJobs - the number of active jobs

=== ScheduledExecutorService daemon services

DAGScheduler uses the following ScheduledThreadPoolExecutors (with the policy of removing cancelled tasks from a work queue at time of cancellation):

* `dag-scheduler-message` - a daemon thread pool using `j.u.c.ScheduledThreadPoolExecutor` with core pool size `1`. It is used to post `ResubmitFailedStages` when `FetchFailed` is reported.

They are created using `ThreadUtils.newDaemonSingleThreadScheduledExecutor` method that uses Guava DSL to instantiate a ThreadFactory.
