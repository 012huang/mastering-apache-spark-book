== DataStreamWriter

CAUTION: FIXME

[source, scala]
----
val df: DataFrame = ...

import org.apache.spark.sql.streaming.ProcessingTime
import scala.concurrent.duration._
df.writeStream
  .queryName("textStream")
  .trigger(ProcessingTime(10.seconds))
  .format("console")
  .start
----

=== [[outputMode]] outputMode

CAUTION: FIXME

=== [[trigger]] trigger

[source, scala]
----
trigger(trigger: Trigger): DataStreamWriter[T]
----

`trigger` sets the interval of trigger (batch) for the streaming query.

NOTE: `Trigger` specifies how often results should be produced by a link:spark-sql-StreamingQuery.adoc[StreamingQuery]. See link:spark-sql-trigger.adoc[Trigger].

The default trigger is `ProcessingTime(0L)` which means as fast as possible.

=== [[start]] start methods

[source, scala]
----
start(path: String): StreamingQuery
start(): StreamingQuery
----

=== [[foreach]] foreach
