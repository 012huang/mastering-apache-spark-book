== Settings

The following list are the settings used to configure Spark SQL applications.

* `spark.sql.allowMultipleContexts` (default: `true`) controls whether creating multiple SQLContexts/HiveContexts is allowed.

* [[autoBroadcastJoinThreshold]]`spark.sql.autoBroadcastJoinThreshold` (default: `10 * 1024 * 1024`) configures the maximum size in bytes for a table that will be broadcast to all worker nodes when performing a join. If the size of the statistics of the logical plan of a DataFrame is at most the setting, the DataFrame is broadcast for join.
+
Negative values or `0` disable broadcasting.
+
Consult link:spark-sql-joins.adoc#broadcast-join[Broadcast Join] for more information about the topic.

* `spark.sql.columnNameOfCorruptRecord`

* `spark.sql.dialect` - FIXME
