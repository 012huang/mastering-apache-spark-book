== Dependencies

* `def getDependencies: Seq[Dependency[_]]` returns how this RDD depends on parent RDDs.
+
```
scala> lines.dependencies
res3: Seq[org.apache.spark.Dependency[_]] = List(org.apache.spark.OneToOneDependency@56d5a50f)
```

=== [[narow-dependency]] NarrowDependency

FIXME

=== [[shuffle-dependency]] ShuffleDependency

A *ShuffleDependency* represents a dependency on the output of link:spark-scheduler.adoc#ShuffleMapStage[a shuffle stage] for a RDD.

It uses link:spark-rdd-partitions.adoc#partitioner[partitioner] to partition the shuffle output. It also uses link:spark-shuffle-service.adoc[ShuffleManager] to register itself and link:spark-service-contextcleaner.adoc[ContextCleaner] to register itself for cleanup.

The places where ShuffleDependency is used:

* `CoGroupedRDD` and `SubtractedRDD` when partitioner differs among RDDs
* link:spark-rdd-shuffledrdd.adoc[ShuffledRDD] and `ShuffledRowRDD` that are RDDs from a shuffle

The RDD operations that lead to use the above RDDs and hence shuffling:

* link:spark-rdd-partitions.adoc#coalesce[coalesce]
** `repartition`
* `cogroup`
** `intersection`
* `subtractByKey`
** `subtract`
* `sortByKey`
** `sortBy`
* `repartitionAndSortWithinPartitions`
* `combineByKeyWithClassTag`
** `combineByKey`
** `aggregateByKey`
** `foldByKey`
** `reduceByKey`
** `countApproxDistinctByKey`
** `groupByKey`
* `partitionBy`

Please note that there may be other methods that use the above.
