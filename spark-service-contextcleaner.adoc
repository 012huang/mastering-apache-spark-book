== [[ContextCleaner]] ContextCleaner

It does cleanup of shuffles, RDDs and broadcasts.

====
`ContextCleaner` is created and immediately started when link:spark-sparkcontext-creating-instance-internals.adoc#_cleaner[`SparkContext` starts] (and <<spark_cleaner_referenceTracking, `spark.cleaner.referenceTracking` Spark property>> is enabled, which it is by default).

`ContextCleaner` stops when link:spark-sparkcontext.adoc#stop[`SparkContext` is stopped].
====

[[internal-registries]]
.`ContextCleaner` Internal Registries and Counters
[frame="topbot",cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[referenceBuffer]] `referenceBuffer`
|

Used when ???

| [[referenceQueue]] `referenceQueue`
|

Used when ???

| [[listeners]] `listeners`
|

Used when ???
|===

It uses a daemon *Spark Context Cleaner* thread that cleans RDD, shuffle, and broadcast states (using `keepCleaning` method).

CAUTION: FIXME Review `keepCleaning`

link:spark-rdd-ShuffleDependency.adoc[ShuffleDependencies] <<registerShuffleForCleanup, register themselves for cleanup>>.

ContextCleaner uses a link:spark-sparkcontext.adoc[SparkContext].

[TIP]
====
Enable `INFO` or `DEBUG` logging level for `org.apache.spark.ContextCleaner` logger to see what happens in `ContextCleaner`.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.ContextCleaner=DEBUG
```

Refer to link:spark-logging.adoc[Logging].
====

=== [[creating-instance]] Creating `ContextCleaner` Instance

`ContextCleaner` takes a link:spark-sparkcontext.adoc[SparkContext].

`ContextCleaner` <<internal-registries, initializes the internal registries and counters>>.

=== [[cleaningThread]] Cleaning Thread -- `cleaningThread` Attribute

CAUTION: FIXME

=== [[doCleanupShuffle]] `doCleanupShuffle` Method

[source, scala]
----
doCleanupShuffle(shuffleId: Int, blocking: Boolean): Unit
----

`doCleanupShuffle`...FIXME

CAUTION: FIXME

=== [[start]] `start` Method

CAUTION: FIXME

=== [[registerShuffleForCleanup]] `registerShuffleForCleanup` Method

CAUTION: FIXME

=== [[registerBroadcastForCleanup]] `registerBroadcastForCleanup` Method

CAUTION: FIXME

=== [[registerRDDForCleanup]] `registerRDDForCleanup` Method

CAUTION: FIXME

=== [[registerAccumulatorForCleanup]] `registerAccumulatorForCleanup` Method

CAUTION: FIXME

=== [[stop]] `stop` Method

CAUTION: FIXME

=== [[settings]] Settings

.Spark Properties
[frame="topbot",cols="1,1,2",options="header",width="100%"]
|======================
| Spark Property | Default Value | Description

| [[spark_cleaner_periodicGC_interval]] `spark.cleaner.periodicGC.interval`
| `30min`
| Controls how often to trigger a garbage collection.

| [[spark_cleaner_referenceTracking]] `spark.cleaner.referenceTracking`
| `true`
| Controls whether a <<creating-instance, `ContextCleaner` should be created>> when a link:spark-sparkcontext.adoc#creating-instance[`SparkContext` initializes].

| [[spark_cleaner_referenceTracking_blocking]] `spark.cleaner.referenceTracking.blocking`
| `true`
| Controls whether the cleaning thread should block on cleanup tasks (other than shuffle, which is controlled by <<spark_cleaner_referenceTracking_blocking_shuffle, spark.cleaner.referenceTracking.blocking.shuffle>> Spark property).

It is `true` as a workaround to https://issues.apache.org/jira/browse/SPARK-3015[SPARK-3015 Removing broadcast in quick successions causes Akka timeout].

| [[spark_cleaner_referenceTracking_blocking_shuffle]] `spark.cleaner.referenceTracking.blocking.shuffle`
| `false`
| Controls whether the cleaning thread should block on shuffle cleanup tasks.

It is `false` as a workaround to https://issues.apache.org/jira/browse/SPARK-3139[SPARK-3139 Akka timeouts from ContextCleaner when cleaning shuffles].

| [[spark_cleaner_referenceTracking_cleanCheckpoints]] `spark.cleaner.referenceTracking.cleanCheckpoints`
| `false`
| Controls whether to clean checkpoint files if the reference is out of scope.
