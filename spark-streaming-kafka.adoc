== Data Ingestion using Apache Kafka

Kafka concepts:

* `broker`
* `leader`
* `topic`
* `partition`
* `offset`
* `exactly-once semantics`
* `Kafka high-level consumer`

There are two modes of ingesting data from Kafka:

* *Streaming mode* using `KafkaUtils.createDirectStream` that is particularly useful in Spark Streaming.
* *Non-streaming mode* using `KafkaUtils.createRDD` that just creates a link:spark-streaming-kafka-kafkardd.adoc[KafkaRDD] of key-value pairs, i.e. `RDD[(K, V)]`.

`DirectKafkaInputDStream` is an link:spark-streaming-inputdstreams.adoc[input stream] of link:spark-streaming-kafka-kafkardd.adoc[KafkaRDD] batches. It uses link:spark-streaming-settings.adoc[spark.streaming.kafka.maxRetries] setting while computing `latestLeaderOffsets` (i.e. a mapping of `kafka.common.TopicAndPartition` and <<LeaderOffset, LeaderOffset>>) .

The new API for both Kafka RDD and DStream is in the spark-streaming-kafka artifact.

=== [[LeaderOffset]] LeaderOffset

`LeaderOffset` is an internal class to represent an offset on the topic partition on the broker that works on a host and a port.

=== Recommended Reading

* http://blog.cloudera.com/blog/2015/03/exactly-once-spark-streaming-from-apache-kafka/[Exactly-once Spark Streaming from Apache Kafka]
