== SQLContext

*SQLContext* is the entry point for Spark SQL. Whatever you do in Spark SQL it has to start from <<creating-instance, creating an instance of SQLContext>>.

A `SQLContext` object requires a `SparkContext`, a `CacheManager`, and a `SQLListener`. They are all `transient` and do not participate in serializing a SQLContext.

=== [[creating-instance]] Creating SQLContext Instance

You can create a `SQLContext` using the following constructors:

* `SQLContext(sparkContext: SparkContext)`
* `SQLContext.getOrCreate`
* `newSession(): SQLContext` allows for creating a new instance of `SQLContext` with a separate SQL configuration (through a shared `SparkContext`).

=== Configuration Properties

You can set Spark SQL configuration properties using:

* `setConf(props: Properties): Unit`
* `setConf(key: String, value: String): Unit`

You can get the current value of a configuration property by key using:

* `getConf(key: String): String`
* `getConf(key: String, defaultValue: String): String`
* `getAllConfs: immutable.Map[String, String]`

NOTE: Properties that start with *spark.sql* are reserved for Spark SQL.

=== Creating DataFrames

==== emptyDataFrame

[source, scala]
----
emptyDataFrame: DataFrame
----

`emptyDataFrame` creates an empty DataFrame. It calls `createDataFrame` with an empty `RDD[Row]` and an empty schema `StructType(Nil)`.

=== Registering User-Defined Functions (UDF)

[source, scala]
----
udf: UDFRegistration
----

`udf` method gives access to `UDFRegistration` to manipulate user-defined functions.

=== Caching DataFrames in In-Memory Cache

[source, scala]
----
isCached(tableName: String): Boolean
----

`isCached` method asks `CacheManager` whether `tableName` table is cached in memory or not. It simply requests `CacheManager` for `CachedData` and when exists, it assumes the table is cached.

[source, scala]
----
cacheTable(tableName: String): Unit
----

You can cache a table in memory using `cacheTable`.

CAUTION: Why would I want to cache a table?

[source, scala]
----
uncacheTable(tableName: String)
clearCache(): Unit
----

`uncacheTable` and `clearCache` remove one or all in-memory cached tables.

=== Implicits - SQLContext.implicits

The `implicits` object is a helper class for converting Scala objects into DataFrames and ...FIXME

[source, scala]
----
val sqlContext = new SQLContext(sc)
import sqlContext.implicits._
----

It holds link:spark-sql-dataset.adoc#Encoder[Encoders] for Scala types like `Int`, `Double`, `String`, etc.
