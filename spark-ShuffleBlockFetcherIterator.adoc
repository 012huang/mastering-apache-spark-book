== [[ShuffleBlockFetcherIterator]] ShuffleBlockFetcherIterator

`ShuffleBlockFetcherIterator` is a Scala http://www.scala-lang.org/api/current/scala/collection/Iterator.html[Iterator] to <<next, iterate over a sequence of `(BlockId, InputStream)` pairs>>.

[TIP]
====
Enable `ERROR`, `WARN`, `INFO`, `DEBUG` or `TRACE` logging levels for `org.apache.spark.storage.ShuffleBlockFetcherIterator` logger to see what happens in `ShuffleBlockFetcherIterator`.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.storage.ShuffleBlockFetcherIterator=TRACE
```

Refer to link:spark-logging.adoc[Logging].
====

=== [[cleanup]] `cleanup` Method

CAUTION: FIXME

=== [[splitLocalRemoteBlocks]] `splitLocalRemoteBlocks` Method

CAUTION: FIXME

=== [[fetchUpToMaxBytes]] `fetchUpToMaxBytes` Method

CAUTION: FIXME

=== [[fetchLocalBlocks]] `fetchLocalBlocks` Method

CAUTION: FIXME

=== [[initialize]] Initializing ShuffleBlockFetcherIterator -- `initialize` Internal Method

[source, scala]
----
initialize(): Unit
----

`initialize` registers a task cleanup and fetches shuffle blocks from remote and local link:spark-blockmanager.adoc[BlockManagers].

Internally, `initialize` link:spark-taskscheduler-taskcontext.adoc#addTaskCompletionListener[registers a `TaskCompletionListener]` (that will <<cleanup, clean up>> right after the task finishes).

`initialize` <<splitLocalRemoteBlocks, splitLocalRemoteBlocks>>.

`initialize` <<fetchRequests, registers the new remote fetch requests (with `fetchRequests` internal registry)>>.

As `ShuffleBlockFetcherIterator` is in initialization phase, `initialize` makes sure that `reqsInFlight` and `bytesInFlight` are both `0`. Otherwise, `initialize` throws an exception.

`initialize` <<fetchUpToMaxBytes, fetches shuffle blocks>> (from remote link:spark-blockmanager.adoc[BlockManagers]).

You should see the following INFO message in the logs:

```
INFO ShuffleBlockFetcherIterator: Started [numFetches] remote fetches in [time] ms
```

`initialize` <<fetchLocalBlocks, fetches local shuffle blocks>>.

You should see the following DEBUG message in the logs:

```
DEBUG ShuffleBlockFetcherIterator: Got local blocks in  [time] ms
```

NOTE: `initialize` is used when <<creating-instance, `ShuffleBlockFetcherIterator` is created>>.

=== [[creating-instance]] Creating ShuffleBlockFetcherIterator Instance

When created, `ShuffleBlockFetcherIterator` takes the following:

1. link:spark-taskscheduler-taskcontext.adoc[TaskContext]
2. link:spark-shuffleclient.adoc[ShuffleClient]
3. link:spark-blockmanager.adoc[BlockManager]
4. `blocksByAddress` list of blocks to fetch per link:spark-blockmanager.adoc[BlockManager].
+
```
blocksByAddress: Seq[(BlockManagerId, Seq[(BlockId, Long)])]
```

5. `streamWrapper` function to wrap the returned input stream
+
```
streamWrapper: (BlockId, InputStream) => InputStream
```

6. Maximum size (in bytes) of map outputs to fetch simultaneously from each reduce task (`maxBytesInFlight` and controlled by link:spark-BlockStoreShuffleReader.adoc#spark_reducer_maxSizeInFlight[spark.reducer.maxSizeInFlight] Spark property)
7. The maximum number of remote requests to fetch blocks at any given point (`maxReqsInFlight` and controlled by link:spark-BlockStoreShuffleReader.adoc#spark_reducer_maxReqsInFlight[spark.reducer.maxReqsInFlight] Spark property)
8. `detectCorrupt` flag to detect any corruption in fetched blocks (controlled by link:spark-BlockStoreShuffleReader.adoc#spark_shuffle_detectCorrupt[spark.shuffle.detectCorrupt] Spark property)

CAUTION: FIXME

=== [[next]] `next` Method

CAUTION: FIXME

=== [[throwFetchFailedException]] Throwing FetchFailedException (for ShuffleBlockId) -- `throwFetchFailedException` Internal Method

[source, scala]
----
throwFetchFailedException(
  blockId: BlockId,
  address: BlockManagerId,
  e: Throwable): Nothing
----

`throwFetchFailedException` throws a link:spark-TaskRunner-FetchFailedException.adoc[FetchFailedException] when the input `blockId` is a `ShuffleBlockId`.

NOTE: `throwFetchFailedException` creates a `FetchFailedException` passing on the root cause of a failure, i.e. the input `e`.

Otherwise, `throwFetchFailedException` throws a `SparkException`:

```
Failed to get block [blockId], which is not a shuffle block
```

NOTE: `throwFetchFailedException` is used when <<next `ShuffleBlockFetcherIterator` is requested for the next element>>.
