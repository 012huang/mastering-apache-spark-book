== Windowed Operators

[NOTE]
====
Go to http://spark.apache.org/docs/latest/streaming-programming-guide.html#window-operations[Window Operations] to read the official documentation.

This document aims at presenting the _internals_ of window operators.
====

In short, *windowed operators* allow you to apply transformations over a *sliding window* of data, i.e. build a stateful computation across multiple batches.

NOTE: Windowed operators, windowed operations, and window-based operations are all the same concept.

By default, you apply transformations using different link:spark-streaming-dstreams.adoc#operators[stream operators] to a single RDD that represents a dataset that has been built out of data received from one or many link:spark-streaming-inputdstreams.adoc[input streams]. The transformations know nothing about the past (datasets received and already processed). The computations are hence _stateless_.

You can however build datasets based upon the past ones, and that is when windowed operators enter the stage. Using them allows you to cross the boundary of a single dataset (per batch) and have a series of datasets in your hands (as if the data they hold arrived in a single batch interval).
