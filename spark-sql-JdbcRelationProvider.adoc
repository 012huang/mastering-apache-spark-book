== [[JdbcRelationProvider]] JdbcRelationProvider

`JdbcRelationProvider` is a link:spark-sql-datasource.adoc#CreatableRelationProvider[CreatableRelationProvider] and link:spark-sql-datasource.adoc#RelationProvider[RelationProvider] that link:spark-sql-DataSourceRegister.adoc[registers `DataSources`] for link:spark-sql-DataFrameReader.adoc#jdbc[jdbc] format.

[source, scala]
----
val table = spark.read.jdbc(...)

// or the same as above in a more verbose way
val table = spark.read.format("jdbc").load(...)
----

=== [[createRelation-RelationProvider]] Creating JDBCRelation -- `createRelation` Method (from RelationProvider)

[source, scala]
----
createRelation(sqlContext: SQLContext, parameters: Map[String, String]): BaseRelation
----

`createRelation` creates a `JDBCPartitioningInfo` (using `JDBCOptions` and the input `parameters` that correspond to link:spark-sql-DataFrameReader.adoc#jdbc-options[Options for JDBC Data Source]).

NOTE: `createRelation` uses link:spark-sql-DataFrameReader.adoc#jdbc-[partitionColumn], link:spark-sql-DataFrameReader.adoc#jdbc-lowerBound[lowerBound], link:spark-sql-DataFrameReader.adoc#jdbc-upperBound[upperBound] and link:spark-sql-DataFrameReader.adoc#jdbc-numPartitions[numPartitions].

In the end, `createRelation` creates a link:spark-sql-JDBCRelation.adoc[JDBCRelation] using link:spark-sql-JDBCRelation.adoc#columnPartition[column partitions] and `JDBCOptions`.

NOTE: `createRelation` is a part of link:spark-sql-datasource.adoc#RelationProvider[RelationProvider Contract].

=== [[createRelation-CreatableRelationProvider]] `createRelation` Method (from CreatableRelationProvider)

[source, scala]
----
createRelation(
  sqlContext: SQLContext,
  mode: SaveMode,
  parameters: Map[String, String],
  df: DataFrame): BaseRelation
----

NOTE: `createRelation` is a part of CreatableRelationProvider Contract.
