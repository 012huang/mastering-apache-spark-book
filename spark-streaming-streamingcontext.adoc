== StreamingContext

`StreamingContext` is the main entry point for all Spark Streaming functionality.

=== [[creating-instance]] Creating Instance

When you create a new instance of `StreamingContext` (and you will eventually) it first checks whether a link:spark-sparkcontext.adoc[SparkContext] or the checkpoint directory are given.

[TIP]
====
`StreamingContext` will warn you when you use `local` or `local[1]` link:spark-deployment-environments.adoc#master-urls[master URLs]:

[options="wrap"]
----
WARN StreamingContext: spark.master should be set as local[n], n > 1 in local mode if you have receivers to get data, otherwise Spark jobs will not get resources to process the received data.
----
====

A link:spark-streaming-dstreams.adoc#DStreamGraph[DStreamGraph] is created.

A link:spark-streaming-jobscheduler.adoc[JobScheduler] is created.

A link:spark-streaming.adoc#StreamingJobProgressListener[StreamingJobProgressListener] is created.

The link:spark-streaming.adoc#StreamingTab[Streaming tab] in web UI is created (when spark.ui.enabled is set).

A link:spark-streaming.adoc#StreamingSource[StreamingSource] is instantiated.

At this point, it is assumed that the StreamingContext is `INITIALIZED`.

You should see the following INFO message in the logs upon successful start:

```
INFO StreamingContext: StreamingContext started
```

=== [[stopping]] Stopping StreamingContext (using stop methods)

You stop `StreamingContext` using one of the three variants of `stop` method:

* `stop(stopSparkContext: Boolean = true)`
* `stop(stopSparkContext: Boolean, stopGracefully: Boolean)`

NOTE: The first `stop` method uses link:spark-streaming-settings.adoc[spark.streaming.stopSparkContextByDefault] configuration setting that controls `stopSparkContext` input parameter.

`stop` methods stop the execution of the streams immediately (`stopGracefully` is `false`) or wait for the processing of all received data to be completed (`stopGracefully` is `true`).

`stop` reacts appropriately depending on the state of `StreamingContext`. The end state is always `STOPPED`.

When `INITIALIZED`, it prints the WARN message to the logs:

```
WARN StreamingContext: StreamingContext has not been started yet
```

When `STOPPED`, it prints the WARN message to the logs:

```
WARN StreamingContext: StreamingContext has already been stopped
```

It is only in `ACTIVE` state when `stop` does more than printing out the WARN messages to the logs, i.e. it does the following (in order):

* link:spark-streaming-jobscheduler.adoc#stopping[JobScheduler is stopped].

* link:spark-streaming.adoc#StreamingSource[StreamingSource] is removed from link:spark-metrics.adoc[MetricsSystem] (using `MetricsSystem.removeSource`)

* link:spark-streaming.adoc#StreamingTab[Streaming tab] is detached (using `StreamingTab.detach`).

* `ContextWaiter` is `notifyStop()`

* `shutdownHookRef` is cleared.

CAUTION: FIXME When is `shutdownHookRef` executed? It doesn't seem to be so at `stop`?

At that point, the following INFO message is printed out to the logs and `StreamingContext` enters `STOPPED` state.

```
INFO StreamingContext: StreamingContext stopped successfully
```

If a user requested to stop the underlying SparkContext (when `stopSparkContext` is `true`), link:spark-sparkcontext.adoc#stopping[it is now attempted to be stopped].
