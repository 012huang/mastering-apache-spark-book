== [[Column]] Columns

CAUTION: FIXME

`Column` type represents...FIXME

=== [[symbols-as-column-names]] Symbols As Column Names

[source, scala]
----
scala> val df = Seq((0, "hello"), (1, "world")).toDF("id", "text")
df: org.apache.spark.sql.DataFrame = [id: int, text: string]

scala> df.select('id)
res7: org.apache.spark.sql.DataFrame = [id: int]

scala> df.select('id).show
+---+
| id|
+---+
|  0|
|  1|
+---+
----

=== [[over]] over function

[source, scala]
----
over(window: expressions.WindowSpec): Column
----

`over` function defines a *windowing column* that allows for window computations to be applied to a window. Window functions are defined using link:spark-sql-windows.adoc#WindowSpec[WindowSpec].

TIP: Read about Windows in link:spark-sql-windows.adoc[Windows].

=== [[cast]] cast

`cast` method casts a column to a type. It makes for type-safe maps with link:spark-sql-dataframe-row.adoc[Row] objects of the proper type (not `Any`).

[source,scala]
----
cast(to: DataType): Column
----

==== [[cast-example]] cast Example

[source, scala]
----
scala> val df = Seq((0f, "hello")).toDF("label", "text")
df: org.apache.spark.sql.DataFrame = [label: float, text: string]

scala> df.printSchema
root
 |-- label: float (nullable = false)
 |-- text: string (nullable = true)

// without cast
import org.apache.spark.sql.Row
scala> df.select("label").map { case Row(label) => label.getClass.getName }.show(false)
+---------------+
|value          |
+---------------+
|java.lang.Float|
+---------------+

// with cast
import org.apache.spark.sql.types.DoubleType
scala> df.select(col("label").cast(DoubleType)).map { case Row(label) => label.getClass.getName }.show(false)
+----------------+
|value           |
+----------------+
|java.lang.Double|
+----------------+
----
