== [[ExecutorBackend]] ExecutorBackend -- Pluggable Interface for Executor Backends

`ExecutorBackend` is a pluggable interface that link:spark-executor-taskrunner.adoc[TaskRunners] use to <<statusUpdate, send task status updates>> to a scheduler.

.ExecutorBackend receives notifications from TaskRunners
image::images/executorbackend.png[align="center"]

NOTE: `TaskRunner` manages a single individual link:spark-taskscheduler-tasks.adoc[task] and is managed by an link:spark-executor.adoc#launchTask[`Executor` to launch a task].

CAUTION: FIXME What is "a scheduler" in this context?

The interface comes with one method:

[[statusUpdate]]
```
def statusUpdate(taskId: Long, state: TaskState, data: ByteBuffer)
```

It is effectively a bridge between the driver and an executor, i.e. there are two endpoints running.

CAUTION: FIXME What is cluster scheduler? Where is ExecutorBackend used?

Status updates include information about tasks, i.e. id, link:spark-taskscheduler-tasks.adoc#states[state], and data (as `ByteBuffer`).

At startup, an executor backend connects to the driver and creates an executor. It then launches and kills tasks. It stops when the driver orders so.

There are three concrete executor backends:

1. link:spark-executor-backends-CoarseGrainedExecutorBackend.adoc[CoarseGrainedExecutorBackend]

2. link:spark-LocalSchedulerBackend.adoc[LocalSchedulerBackend] (for link:spark-local.adoc[local run mode])

3. link:spark-executor-backends-MesosExecutorBackend.adoc[MesosExecutorBackend]
