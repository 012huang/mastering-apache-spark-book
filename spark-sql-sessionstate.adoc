== SessionState

`SessionState` is the <<sessionState, default separation layer>> for isolating state across sessions, including SQL configuration, tables, functions, UDFs, the link:spark-sql-sql-parsers.adoc#SparkSqlParser[SQL parser], and everything else that depends on a link:spark-sql-SQLConf.adoc[SQLConf].

CAUTION: FIXME Elaborate please.

It requires a link:spark-sql-sparksession.adoc[SparkSession] and manages its own link:spark-sql-SQLConf.adoc[SQLConf].

NOTE: Given the package `org.apache.spark.sql.internal` that `SessionState` belongs to, this one is truly _internal_. You've been warned.

NOTE: `SessionState` is a `private[sql]` class.

`SessionState` offers the following services:

* <<udf, udf>>
* <<newHadoopConf, newHadoopConf>> to create a new Hadoop's `Configuration`.
* link:spark-sql-sparksession.adoc#sessionState[sessionState]
* link:spark-sql-sql-parsers.adoc#SparkSqlParser[sqlParser]

=== [[udf]] udf Attribute

[source, scala]
----
udf: UDFRegistration
----

`udf` attribute points at shared `UDFRegistration` for a given Spark session.

=== [[newHadoopConf]] Creating New Hadoop Configuration (newHadoopConf method)

[source, scala]
----
newHadoopConf(): Configuration
----

`newHadoopConf` returns Hadoop's `Configuration` that it builds using link:spark-sparkcontext.adoc#hadoopConfiguration[SparkContext.hadoopConfiguration] (through link:spark-sql-sparksession.adoc[SparkSession]) with all configuration settings added.

NOTE: `newHadoopConf` is used by link:spark-sql-queryplanner.adoc#HiveSessionState[HiveSessionState] (for `HiveSessionCatalog`), `ScriptTransformation`, `ParquetRelation`, `StateStoreRDD`, and `SessionState` itself, and few other places.

CAUTION: FIXME What is `ScriptTransformation`? `StateStoreRDD`?
