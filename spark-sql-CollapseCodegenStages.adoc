== [[CollapseCodegenStages]] CollapseCodegenStages Physical Plan Preparation

`CollapseCodegenStages` is a physical plan preparation rule (i.e. link:spark-sql-catalyst-RuleExecutor.adoc#Rule[Rule[SparkPlan\]]) in link:spark-sql-QueryExecution.adoc#preparations[QueryExecution].

NOTE: link:spark-sql-QueryExecution.adoc#preparations[preparations batch of rules] is...FIXME

`CollapseCodegenStages` <<apply, finds physical operators that support codegen and collapse them together>> (as a single link:spark-sql-SparkPlan-WholeStageCodegenExec.adoc[WholeStageCodegenExec] physical operator).

NOTE: Only link:spark-sql-CodegenSupport.adoc[CodegenSupport] physical plans that have `supportCodegen` enabled support codegen.

NOTE: All link:spark-sql-Expression.adoc[Catalyst expressions] (but link:spark-sql-Expression.adoc#CodegenFallback[CodegenFallback]) support codegen.

[[conf]]
`CollapseCodegenStages` takes a link:spark-sql-SQLConf.adoc[SQLConf] when created.

`CollapseCodegenStages` uses the internal setting `spark.sql.codegen.maxFields` (default: `200`) to control the number of fields in input and output schemas before deactivating whole-stage codegen. It counts the fields included in complex types, i.e. link:spark-sql-StructType.adoc[StructType], `MapType`, `ArrayType`, `UserDefinedType`, and their combinations, recursively. See https://issues.apache.org/jira/browse/SPARK-14554[SPARK-14554].

`CollapseCodegenStages` inserts `InputAdapter` leaf nodes in a physical plan recursively that is then used to generate code that consumes an RDD iterator of link:spark-sql-InternalRow.adoc[InternalRow].

[TIP]
====
Import `CollapseCodegenStages` and apply the rule directly to a physical plan to learn how the rule works.

[source, scala]
----
// FIXME
// See spark-sql-Optimizer-ReorderJoin.adoc
----
====

=== [[apply]] Transforming Physical Plan -- `apply` Method

CAUTION: FIXME

=== [[supportCodegen]] `supportCodegen` Internal Method

CAUTION: FIXME
