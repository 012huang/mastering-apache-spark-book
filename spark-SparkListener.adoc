== [[SparkListener]] Spark Listeners

`SparkListener` is a developer API for custom Spark listeners. It is an abstract class that is a <<SparkListenerInterface, SparkListenerInterface>> with empty no-op implementations of all the _callback methods_.

With all the callbacks being no-ops, you can focus on events of your liking and process a subset of events.

TIP: Developing a custom SparkListener is an excellent introduction to low-level details of link:spark-execution-model.adoc[Spark's Execution Model]. Check out the exercise link:exercises/spark-exercise-custom-scheduler-listener.adoc[Developing Custom SparkListener to monitor DAGScheduler in Scala].

=== [[SparkListenerEvent]] SparkListenerEvents

CAUTION: FIXME Give a less code-centric description of the times for the events.

==== [[SparkListenerApplicationStart]] SparkListenerApplicationStart

[source, scala]
----
SparkListenerApplicationStart(
  appName: String,
  appId: Option[String],
  time: Long,
  sparkUser: String,
  appAttemptId: Option[String],
  driverLogs: Option[Map[String, String]] = None)
----

`SparkListenerApplicationStart` is posted when `SparkContext` does `postApplicationStart`.

==== [[SparkListenerJobStart]] SparkListenerJobStart

[source, scala]
----
SparkListenerJobStart(
  jobId: Int,
  time: Long,
  stageInfos: Seq[StageInfo],
  properties: Properties = null)
----

`SparkListenerJobStart` is posted when `DAGScheduler` does `handleJobSubmitted` and `handleMapStageSubmitted`.

==== [[SparkListenerStageSubmitted]] SparkListenerStageSubmitted

[source, scala]
----
SparkListenerStageSubmitted(stageInfo: StageInfo, properties: Properties = null)
----

`SparkListenerStageSubmitted` is posted when `DAGScheduler` does `submitMissingTasks`.

==== [[SparkListenerTaskStart]] SparkListenerTaskStart

[source, scala]
----
SparkListenerTaskStart(stageId: Int, stageAttemptId: Int, taskInfo: TaskInfo)
----

`SparkListenerTaskStart` is posted when `DAGScheduler` does `handleBeginEvent`.

==== [[SparkListenerTaskGettingResult]] SparkListenerTaskGettingResult

[source, scala]
----
SparkListenerTaskGettingResult(taskInfo: TaskInfo)
----

`SparkListenerTaskGettingResult` is posted when `DAGScheduler` does `handleGetTaskResult`.

==== [[SparkListenerTaskEnd]] SparkListenerTaskEnd

[source, scala]
----
SparkListenerTaskEnd(
  stageId: Int,
  stageAttemptId: Int,
  taskType: String,
  reason: TaskEndReason,
  taskInfo: TaskInfo,
  // may be null if the task has failed
  @Nullable taskMetrics: TaskMetrics)
----

`SparkListenerTaskEnd` is posted when `DAGScheduler` does `handleTaskCompletion`.

==== [[SparkListenerStageCompleted]] SparkListenerStageCompleted

[source, scala]
----
SparkListenerStageCompleted(stageInfo: StageInfo)
----

`SparkListenerStageCompleted` is posted when `DAGScheduler` does `markStageAsFinished`.

==== [[SparkListenerJobEnd]] SparkListenerJobEnd

[source, scala]
----
SparkListenerJobEnd(
  jobId: Int,
  time: Long,
  jobResult: JobResult)
----

`SparkListenerJobEnd` is posted when `DAGScheduler` does `cleanUpAfterSchedulerStop`, `handleTaskCompletion`, `failJobAndIndependentStages`, and markMapStageJobAsFinished.

==== [[SparkListenerApplicationEnd]] SparkListenerApplicationEnd

[source, scala]
----
SparkListenerApplicationEnd(time: Long)
----

`SparkListenerApplicationEnd` is posted when `SparkContext` does `postApplicationEnd`.

==== [[SparkListenerEnvironmentUpdate]] SparkListenerEnvironmentUpdate

[source, scala]
----
SparkListenerEnvironmentUpdate(environmentDetails: Map[String, Seq[(String, String)]])
----

`SparkListenerEnvironmentUpdate` is posted when `SparkContext` does `postEnvironmentUpdate`.

==== [[SparkListenerBlockManagerAdded]] SparkListenerBlockManagerAdded

[source, scala]
----
SparkListenerBlockManagerAdded(
  time: Long,
  blockManagerId: BlockManagerId,
  maxMem: Long)
----

`SparkListenerBlockManagerAdded` is posted when link:spark-BlockManagerMaster.adoc#RegisterBlockManager-register[`BlockManagerMasterEndpoint` registers a `BlockManager`].

==== [[SparkListenerBlockManagerRemoved]] SparkListenerBlockManagerRemoved

[source, scala]
----
SparkListenerBlockManagerRemoved(
  time: Long,
  blockManagerId: BlockManagerId)
----

`SparkListenerBlockManagerRemoved` is posted when link:spark-BlockManagerMaster.adoc#BlockManagerMasterEndpoint-removeBlockManager[`BlockManagerMasterEndpoint` removes a `BlockManager`].

==== [[SparkListenerBlockUpdated]] SparkListenerBlockUpdated

[source, scala]
----
SparkListenerBlockUpdated(blockUpdatedInfo: BlockUpdatedInfo)
----

`SparkListenerBlockUpdated` is posted when link:spark-BlockManagerMaster.adoc#BlockManagerMasterEndpoint[`BlockManagerMasterEndpoint` receives `UpdateBlockInfo` message].

==== [[SparkListenerUnpersistRDD]] SparkListenerUnpersistRDD

[source, scala]
----
SparkListenerUnpersistRDD(rddId: Int)
----

`SparkListenerUnpersistRDD` is posted when `SparkContext` does `unpersistRDD`.

==== [[SparkListenerExecutorAdded]] SparkListenerExecutorAdded

[source, scala]
----
SparkListenerExecutorAdded(
  time: Long,
  executorId: String,
  executorInfo: ExecutorInfo)
----

`SparkListenerExecutorAdded` is posted when link:spark-scheduler-backends-coarse-grained.adoc#RegisterExecutor[`DriverEndpoint` RPC endpoint (of `CoarseGrainedSchedulerBackend`) handles `RegisterExecutor` message], `MesosFineGrainedSchedulerBackend` does `resourceOffers`, and `LocalSchedulerBackendEndpoint` starts.

==== [[SparkListenerExecutorRemoved]] SparkListenerExecutorRemoved

[source, scala]
----
SparkListenerExecutorRemoved(
  time: Long,
  executorId: String,
  reason: String)
----

`SparkListenerExecutorRemoved` is posted when link:spark-scheduler-backends-coarse-grained.adoc#removeExecutor[`DriverEndpoint` RPC endpoint (of `CoarseGrainedSchedulerBackend`) does `removeExecutor`] and `MesosFineGrainedSchedulerBackend` does `removeExecutor`.

=== [[known-implementations]] Known Implementations

The following is the complete list of all known Spark listeners:

* link:spark-scheduler-listeners-eventlogginglistener.adoc[EventLoggingListener]
* `ExecutorsListener` that prepares information to be displayed on the *Executors* tab in link:spark-webui.adoc[web UI].

* `SparkFirehoseListener` that allows users to receive all <<SparkListenerEvent, SparkListenerEvent>> events by overriding the single `onEvent` method only.

* `ExecutorAllocationListener`

* link:spark-sparkcontext-HeartbeatReceiver.adoc[HeartbeatReceiver]
* web UI and link:spark-scheduler-listeners-eventlogginglistener.adoc[EventLoggingListener] listeners

CAUTION: FIXME Make it complete.

=== [[SparkListenerInterface]] SparkListenerInterface

`SparkListenerInterface` is an internal interface for listeners of events from the Spark scheduler.
