== DataFrameWriter

`DataFrameWriter` is used to write link:spark-sql-dataframe.adoc[DataFrame] to external storage systems or <<streams, data streams>>.

Use link:spark-sql-dataframe.adoc#write[write method] on a `DataFrame` to access it.

[source, scala]
----
import org.apache.spark.sql.DataFrameWriter
val df = ...
val writer: DataFrameWriter = df.write
----

It has a direct support for many <<writing-dataframes-to-files, file formats>> and <<format, interface for new ones>>. It assumes <<parquet, parquet>> as the default data source format that you can change using link:spark-sql-settings.adoc[spark.sql.sources.default] setting.

=== [[writing-dataframes-to-files]] Writing DataFrames to Files

CAUTION: FIXME

=== [[format]] Specifying Data Format (format method)

CAUTION: FIXME Compare to DataFrameReader.

=== [[parquet]] Parquet

CAUTION: FIXME

NOTE: Parquet is the default data source format.

=== [[streams]][[startStream]] Data Streams (startStream methods)

`DataFrameWriter` comes with `startStream` methods to return a link:spark-sql-continuousquery.adoc[ContinuousQuery] object.

[source, scala]
----
startStream(): ContinuousQuery
startStream(path: String): ContinuousQuery
----

`startStream(path: String)` sets `path` option to `path` and calls `startStream()`.

NOTE: It is available since Spark *2.0.0*.
