== DataFrameWriter

`DataFrameWriter` is used to write link:spark-sql-dataframe.adoc[DataFrame] to external storage systems or <<streams, data streams>>.

Use link:spark-sql-dataframe.adoc#write[write method] on a `DataFrame` to access it.

[source, scala]
----
import org.apache.spark.sql.DataFrameWriter
val df = ...
val writer: DataFrameWriter = df.write
----

It has a direct support for many <<writing-dataframes-to-files, file formats>> and <<format, interface for new ones>>. It assumes <<parquet, parquet>> as the default data source format that you can change using link:spark-sql-settings.adoc[spark.sql.sources.default] setting.

=== [[streams]][[startStream]] Data Streams (startStream methods)

`DataFrameWriter` comes with two `startStream` methods to return a link:spark-sql-continuousquery.adoc[ContinuousQuery] object to continually write data.

[source, scala]
----
startStream(): ContinuousQuery
startStream(path: String): ContinuousQuery  // <1>
----
<1> Sets `path` option to `path` and calls `startStream()`

NOTE: `startStream` uses link:spark-sql-continuousquerymanager.adoc#startQuery[ContinuousQueryManager.startQuery] to create link:spark-sql-continuousquery.adoc[ContinuousQuery].

NOTE: Whether or not you have to specify `path` option depends on the link:spark-sql-datasource.adoc[DataSource] in use.

Recognized options:

* `queryName` is the name of active streaming query.
* `checkpointLocation` is the directory for checkpointing.

NOTE: Define options using <<option, option>> or <<options, options>> methods.

NOTE: It is a new feature of Spark *2.0.0*.

=== [[option]][[options]] Writer Configuration (option and options methods)

CAUTION: FIXME

=== [[writing-dataframes-to-files]] Writing DataFrames to Files

CAUTION: FIXME

=== [[format]] Specifying Data Format (format method)

CAUTION: FIXME Compare to DataFrameReader.

=== [[parquet]] Parquet

CAUTION: FIXME

NOTE: Parquet is the default data source format.
