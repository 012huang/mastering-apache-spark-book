== WebUI - UI for Spark Monitoring

Spark comes with *Web UI* (aka *webUI*) to inspect job executions using a browser.

.Welcome page - Jobs page
image::images/spark-webui-jobs.png[align="center"]

link:spark-sparkcontext.adoc#initialization[Every SparkContext launches its own instance of Web UI] which is available at `http://[master]:4040` by default (the port can be changed using <<settings, `spark.ui.port`>>).

It offers pages (tabs) with the following information:

* Jobs
* Stages
* Storage (with RDD size and memory use)
* <<environment-tab, Environment>>
* link:spark-execution-model.adoc#executor[Executors]
* SQL

This information is available only until the application is running by default.

TIP: You can use the web UI after the application is finished by enabling link:spark-scheduler-listeners-eventlogginglistener.adoc#settings[spark.eventLog.enabled].

=== [[environment-tab]] Environment Tab

.Environment tab in Web UI
image::images/spark-webui-environment.png[align="center"]

=== [[JobProgressListener]] JobProgressListener

`JobProgressListener` is link:spark-scheduler-listeners.adoc[SparkListener] for web UI.

It tracks information to be displayed in the UI.

CAUTION: FIXME What information does this track?

=== [[settings]] Settings

* `spark.ui.enabled` (default: `true`) setting controls whether the web UI is started at all.
* `spark.ui.port` (default: `4040`) controls the port Web UI binds to.
+
If multiple SparkContexts attempt to run on the same host (it is not possible to have two or more Spark contexts on a single JVM, though), they will bind to successive ports beginning with `spark.ui.port`.
* `spark.ui.killEnabled` (default: `true`) - whether or not you can kill stages in web UI.
