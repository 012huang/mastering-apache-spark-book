== WebUI - UI for Spark Monitoring

*Web UI* (aka *webUI* or *Spark UI* after <<SparkUI, SparkUI>>) is a web interface to inspect job executions using a browser.

.Welcome page - Jobs page
image::images/spark-webui-jobs.png[align="center"]

link:spark-sparkcontext.adoc#creating-instance[Every SparkContext launches its own instance of Web UI] which is available at `http://[master]:4040` by default (the port can be changed using <<settings, `spark.ui.port`>>).

It offers tabs (with pages) with the following information:

* Jobs
* link:spark-webui-stages.adoc[Stages]
* Storage (with RDD size and memory use)
* <<environment-tab, Environment>>
* link:spark-execution-model.adoc#executor[Executors]
* SQL

This information is available only until the application is running by default.

TIP: You can use the web UI after the application is finished by link:spark-scheduler-listeners-eventlogginglistener.adoc[persisting events using EventLoggingListener].

=== [[environment-tab]] Environment Tab

.Environment tab in Web UI
image::images/spark-webui-environment.png[align="center"]

=== [[SparkUI]] SparkUI

`SparkUI` is...FIXME

==== [[SparkUI-createLiveUI]] createLiveUI

CAUTION: FIXME

==== [[SparkUI-appUIAddress]] appUIAddress

CAUTION: FIXME

=== [[settings]] Settings

==== [[spark.ui.enabled]] spark.ui.enabled

`spark.ui.enabled` (default: `true`) setting controls whether the web UI is started at all.

==== [[spark.ui.port]] spark.ui.port

`spark.ui.port` (default: `4040`) controls the port Web UI binds to.

If multiple SparkContexts attempt to run on the same host (it is not possible to have two or more Spark contexts on a single JVM, though), they will bind to successive ports beginning with `spark.ui.port`.

==== [[spark.ui.killEnabled]] spark.ui.killEnabled

`spark.ui.killEnabled` (default: `true`) - whether or not you can kill stages in web UI.
