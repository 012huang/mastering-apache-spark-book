== WebUI - UI for Spark Monitoring

Spark comes with *Web UI* (aka *webUI*) to monitor jobs execution.

.Welcome page - Jobs page
image::images/spark-webui-jobs.png[align="center"]

link:spark-sparkcontext.adoc#initialization[Every SparkContext launches its own instance of Web UI] that is by default available at `http://[master]:4040` (the port can be changed using <<settings, `spark.ui.port`>>).

If multiple SparkContexts are running on the same host (it's not possible to have two or more on a single JVM, though), they will bind to successive ports beginning with `spark.ui.port`.

It offers pages (tabs) with the following information:

* Jobs
* Stages
* Storage (with RDD size and memory use)
* <<environment-tab, Environment>>
* link:spark-execution-model.adoc#executor[Executors]
* SQL

This information is available only until the application is running by default.

You can view the web UI after the fact after setting link:spark-scheduler-listeners.adoc#event-logging[spark.eventLog.enabled] to `true` before starting the
application.

=== [[environment-tab]] Environment Tab

.Environment tab in Web UI
image::images/spark-webui-environment.png[align="center"]

=== [[JobProgressListener]] JobProgressListener

`JobProgressListener` is link:spark-scheduler-listeners.adoc[the listener] for Web UI.

It tracks information to be displayed in the UI.

CAUTION: FIXME What information does this track?

=== [[settings]] Settings

* `spark.ui.enabled` (default: `true`) setting controls whether the web UI is started at all.
* `spark.ui.port` (default: `4040`) controls the port Web UI binds to.
