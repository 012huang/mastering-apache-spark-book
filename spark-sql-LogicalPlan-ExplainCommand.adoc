== [[ExplainCommand]] ExplainCommand Logical Command

`ExplainCommand` is a link:spark-sql-LogicalPlan-RunnableCommand.adoc[logical command] that allows users to see how a structured query will be executed. It takes in a `LogicalPlan` and creates a link:spark-sql-QueryExecution.adoc[QueryExecution] that is used to output a single-column `DataFrame` with the following:

1. _codegen explain_, i.e. link:spark-sql-whole-stage-codegen.adoc[WholeStageCodegen] subtrees if `codegen` flag is enabled.

2. _extended explain_, i.e. the parsed, analyzed, optimized logical plans with the physical plan if `extended` flag is enabled.

3. _simple explain_, i.e. the physical plan only when no `codegen` and `extended` flags are enabled.

`ExplainCommand` is used for Dataset's link:spark-sql-Dataset.adoc#explain[explain] operator and `EXPLAIN` SQL statement (accepting `EXTENDED` and `CODEGEN` options).

[source, scala]
----
// Explain in SQL

scala> sql("EXPLAIN EXTENDED show tables").show(truncate = false)
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|plan                                                                                                                                                                                                                                           |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|== Parsed Logical Plan ==
ShowTablesCommand

== Analyzed Logical Plan ==
tableName: string, isTemporary: boolean
ShowTablesCommand

== Optimized Logical Plan ==
ShowTablesCommand

== Physical Plan ==
ExecutedCommand
   +- ShowTablesCommand|
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
----

The following EXPLAIN variants in SQL queries are not supported:

* `EXPLAIN FORMATTED`
* `EXPLAIN LOGICAL`

[source, scala]
----
scala> sql("EXPLAIN LOGICAL show tables")
org.apache.spark.sql.catalyst.parser.ParseException:
Operation not allowed: EXPLAIN LOGICAL(line 1, pos 0)

== SQL ==
EXPLAIN LOGICAL show tables
^^^
...
----

=== [[output]] `output` Attribute

CAUTION: FIXME

=== [[creating-instance]] Creating ExplainCommand Instance

`ExplainCommand` takes the following when created:

* [[logicalPlan]] link:spark-sql-LogicalPlan.adoc[LogicalPlan]
* [[extended]] Flag whether to create extended output when `ExplainCommand` <<run, is executed>> (disabled by default)
* [[codegen]] Flag whether to create codegened output when `ExplainCommand` <<run, is executed>> (disabled by default)
* [[cost]] Flag whether to create output with cost when `ExplainCommand` <<run, is executed>> (disabled by default)

`ExplainCommand` initializes <<output, output>> attribute.

NOTE: `ExplainCommand` is created when...FIXME

=== [[run]] Computing Text Representation of QueryExecution (as Single Row) -- `run` Method

[source, scala]
----
run(sparkSession: SparkSession): Seq[Row]
----

`run` computes link:spark-sql-QueryExecution.adoc[QueryExecution] and returns its text representation in a single link:spark-sql-Row.adoc[Row].

NOTE: `run` is a part of link:spark-sql-LogicalPlan-RunnableCommand.adoc#run[RunnableCommand Contract] to execute commands.

Internally, `run` creates a `IncrementalExecution` for a streaming dataset directly or requests `SessionState` to link:spark-sql-SessionState.adoc#executePlan[execute the `LogicalPlan`].

NOTE: *Streaming Dataset* is a part of Spark Structured Streaming.

`run` then requests link:spark-sql-QueryExecution.adoc[QueryExecution] to build the output text representation, i.e. <<codegenString, codegened>>, link:spark-sql-QueryExecution.adoc#toString[extended] (with logical and physical plans), link:spark-sql-QueryExecution.adoc#toStringWithStats[with stats], or link:spark-sql-QueryExecution.adoc#simpleString[simple].

In the end, `run` link:spark-sql-Row.adoc#apply[creates a `Row`] with the text representation.
