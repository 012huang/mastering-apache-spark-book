== Checkpointing

=== [[streamingcontext-checkpoint]] Marking StreamingContext as  Checkpointed

[source, scala]
----
checkpoint(directory: String): Unit
----

You use link:spark-streaming-streamingcontext.adoc#checkpoint[StreamingContext.checkpoint] method to set up a HDFS-compatible *checkpoint directory* where <<checkpoint-data, checkpoint data>> will be persisted, as follows:

[source, scala]
----
ssc.checkpoint("_checkpoint")
----

=== [[checkpoing-interval]] Checkpoint Interval

You can set up periodic checkpointing every *checkpoint interval* using `checkpoint(interval: Duration)` method.

[source, scala]
----
checkpoint(interval: Duration): DStream[T]
----

NOTE: You can only enable the checkpoint interval before link:spark-streaming-streamingcontext.adoc#start[StreamingContext is started]. Otherwise, `UnsupportedOperationException` is thrown.

CAUTION: FIXME the exception

Internally, `checkpoint` method calls link:spark-streaming-dstreams.adoc#cache-persist[persist] (that sets the default `MEMORY_ONLY_SER` storage level).

If checkpoint interval has been enabled, the <<streamingcontext-checkpoint, checkpoint directory>> is mandatory. Spark validates it when link:spark-streaming-streamingcontext.adoc#start[StreamingContext starts]. Otherwise, `IllegalArgumentException` is thrown  (as depicted in the following figure).

.StreamingContext refuses to start when checkpoint directory not set
image::images/spark-streaming-checkpoint-directory-not-set.png[align="center"]

You can see the checkpoint interval for a stream in the logs when the link:spark-streaming-dstreams.adoc#validateAtStart[DStream is validated]:

```
INFO Checkpoint interval = [checkpointDuration]
```

=== [[checkpoint-data]] Checkpoint Data

CAUTION: What is checkpoint data? Code review `DStreamCheckpointData`.
