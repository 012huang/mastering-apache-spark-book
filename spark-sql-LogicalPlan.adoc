== [[LogicalPlan]] LogicalPlan -- Logical Query Plan / Logical Operator

`LogicalPlan` is a link:spark-sql-catalyst-QueryPlan.adoc[QueryPlan] and corresponds to a logical operator being the entire structured query to execute in Spark SQL.

NOTE: `LogicalPlan` uses link:spark-sql-catalyst.adoc[Catalyst Framework] to represent itself as a tree of children ``LogicalPlan``s which are logical operators.

A `LogicalPlan` is what makes a link:spark-sql-Dataset.adoc[Dataset] that you can ask for through its link:spark-sql-QueryExecution.adoc[QueryExecution].

[source, scala]
----
val plan = dataset.queryExecution.logical
----

[[analyzed]]
A logical plan can be *analyzed* which is to say that the plan (including children) has gone through analysis and verification.

[source, scala]
----
scala> plan.analyzed
res1: Boolean = true
----

A logical plan can also be *resolved* to a specific schema.

[source, scala]
----
scala> plan.resolved
res2: Boolean = true
----

A logical plan knows the size of objects that are results of query operators, like `join`, through `Statistics` object.

[source, scala]
----
scala> val stats = plan.statistics
stats: org.apache.spark.sql.catalyst.plans.logical.Statistics = Statistics(8,false)
----

A logical plan knows the maximum number of records it can compute.

[source, scala]
----
scala> val maxRows = plan.maxRows
maxRows: Option[Long] = None
----

A logical plan can be <<isStreaming, streaming>> if it contains one or more link:spark-sql-streaming-source.adoc[structured streaming sources].

[[specialized-logical-plans]]
.Logical Query Operators / Specialized Logical Plans
[cols="1,2",options="header",width="100%"]
|===
| LogicalPlan
| Description

| [[LeafNode]] `LeafNode`
| Logical operator with no child operators

| [[UnaryNode]] `UnaryNode`
| Logical operator with a single child operator

| [[BinaryNode]] `BinaryNode`
| Logical operator with two child operators

| <<Command, Command>>
|

| link:spark-sql-LogicalPlan-RunnableCommand.adoc[RunnableCommand]
|
|===

[[internal-registries]]
.LogicalPlan's Internal Registries and Counters (in alphabetical order)
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[statsCache]] `statsCache`
| Cached plan statistics (as `Statistics`) of the `LogicalPlan`

Computed and cached in <<stats, stats>>.

Used in <<stats, stats>> and <<verboseStringWithSuffix, verboseStringWithSuffix>>.

Reset in <<invalidateStatsCache, invalidateStatsCache>>
|===

=== [[stats]] Getting Cached or Calculating Statistics -- `stats` Method

[source, scala]
----
stats(conf: CatalystConf): Statistics
----

`stats` returns the <<statsCache, cached plan statistics>> or <<computeStats, computes a new one>> (and caches it as <<statsCache, statsCache>>).

[NOTE]
====
`stats` is used when:

* A `LogicalPlan` <<computeStats, computes `Statistics`>>
* `QueryExecution` link:spark-sql-QueryExecution.adoc#completeString[builds complete text representation]
* `JoinSelection` link:spark-sql-JoinSelection.adoc#canBroadcast[checks whether a plan can be broadcast] et al
* `CostBasedJoinReorder` attempts to reorder inner joins.
* `LimitPushDown` link:spark-sql-Optimizer-LimitPushDown.adoc#apply[is executed] (for link:spark-sql-joins.adoc#FullOuter[FullOuter] join)
* `AggregateEstimation` estimates `Statistics`
* `FilterEstimation` estimates child `Statistics`
* `InnerOuterEstimation` estimates `Statistics` of the left and right sides of a join
* `LeftSemiAntiEstimation` estimates `Statistics`
* `ProjectEstimation` estimates `Statistics`
====

=== [[computeStats]] Computing Statistics -- `computeStats` method

[source, scala]
----
computeStats(conf: CatalystConf): Statistics
----

CAUTION: FIXME

NOTE: `computeStats` is a `protected` method that logical operators are expected to override to provide their own custom plan statistics calculation.

NOTE: `computeStats` is used when `LogicalPlan` <<stats, is requested for plan statistics>>.

=== [[invalidateStatsCache]] `invalidateStatsCache` method

CAUTION: FIXME

=== [[verboseStringWithSuffix]] `verboseStringWithSuffix` method

CAUTION: FIXME

=== [[resolveQuoted]] `resolveQuoted` method

CAUTION: FIXME

=== [[setAnalyzed]] `setAnalyzed` method

CAUTION: FIXME

=== [[Command]] `Command` -- Logical Commands

`Command` is the base for <<LeafNode, leaf logical plans>> that represent non-query commands to be executed by the system. It defines `output` to return an empty collection of link:spark-sql-catalyst-Attribute.adoc[Attributes].

Known commands are:

1. `CreateTable`
2. Any link:spark-sql-LogicalPlan-RunnableCommand.adoc[RunnableCommand]

=== [[isStreaming]] Is Logical Plan Structured Streaming -- `isStreaming` method

[source, scala]
----
isStreaming: Boolean
----

`isStreaming` is a part of the public API of `LogicalPlan` and is enabled (i.e. `true`) when a logical plan is a link:spark-sql-streaming-source.adoc[streaming source].

By default, it walks over subtrees and calls itself, i.e. `isStreaming`, on every child node to find a streaming source.

[source, scala]
----
val spark: SparkSession = ...

// Regular dataset
scala> val ints = spark.createDataset(0 to 9)
ints: org.apache.spark.sql.Dataset[Int] = [value: int]

scala> ints.queryExecution.logical.isStreaming
res1: Boolean = false

// Streaming dataset
scala> val logs = spark.readStream.format("text").load("logs/*.out")
logs: org.apache.spark.sql.DataFrame = [value: string]

scala> logs.queryExecution.logical.isStreaming
res2: Boolean = true
----
