== [[ImperativeAggregate]] ImperativeAggregate -- Base Expression for Aggregate Functions with Imperative Methods

`ImperativeAggregate` is the <<contract, contract>> for link:spark-sql-Expression-AggregateFunction.adoc[aggregate functions] that are expressed in terms of imperative <<initialize, initialize>>, <<update, update>>, and <<merge, merge>> methods (that operate on Row-based aggregation buffers).

`ImperativeAggregate` is a link:spark-sql-Expression.adoc[Catalyst expression] with link:spark-sql-Expression.adoc#CodegenFallback[CodegenFallback].

[[implementations]]
.ImperativeAggregate's Direct Implementations
[width="100%",cols="1,2",options="header"]
|===
| Name
| Description

| `HyperLogLogPlusPlus`
|

| `PivotFirst`
|

| link:spark-sql-Expression-ImperativeAggregate-ScalaUDAF.adoc[ScalaUDAF]
|

| `TypedImperativeAggregate`
|===

=== [[contract]] ImperativeAggregate Contract

[source, scala]
----
package org.apache.spark.sql.catalyst.expressions.aggregate

abstract class ImperativeAggregate {
  def initialize(mutableAggBuffer: InternalRow): Unit
  val inputAggBufferOffset: Int
  def merge(mutableAggBuffer: InternalRow, inputAggBuffer: InternalRow): Unit
  val mutableAggBufferOffset: Int
  def update(mutableAggBuffer: InternalRow, inputRow: InternalRow): Unit
  def withNewInputAggBufferOffset(newInputAggBufferOffset: Int): ImperativeAggregate
  def withNewMutableAggBufferOffset(newMutableAggBufferOffset: Int): ImperativeAggregate
}
----

.ImperativeAggregate Contract (in alphabetical order)
[cols="1,2",options="header",width="100%"]
|===
| Method
| Description

| [[initialize]] `initialize`
|

| [[inputAggBufferOffset]] `inputAggBufferOffset`
|

| [[merge]] `merge`
|

| [[mutableAggBufferOffset]] `mutableAggBufferOffset`
|

| [[update]] `update`
|

| [[withNewInputAggBufferOffset]] `withNewInputAggBufferOffset`
|

| [[withNewMutableAggBufferOffset]] `withNewMutableAggBufferOffset`
|
|===
