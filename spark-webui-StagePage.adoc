== [[StagePage]] Stage Details

`StagePage` renders a page available under `/stage` URL that requires two <<parameters, request parameters>> -- `id` and `attempt`, e.g. http://localhost:4040/stages/stage/?id=2&attempt=0.

It is a part of link:spark-webui-stages.adoc[StagesTab].

It uses the parent's link:spark-webui-JobProgressListener.adoc[JobProgressListener] and `RDDOperationGraphListener` to calculate the <<metrics, metrics>>.

.Details for Stage 2 (Attempt 0)
image::images/spark-webui-stage-details.png[align="center"]

=== [[parameters]] Request Parameters

`id` is...

`attempt` is...

NOTE: `id` and `attempt` uniquely identify the stage in link:spark-webui-JobProgressListener.adoc#stageIdToData[JobProgressListener.stageIdToData] to retrieve `StageUIData`.

`task.page` (default: `1`) is...

`task.sort` (default: `Index`)

`task.desc` (default: `false`)

`task.pageSize` (default: `100`)

`task.prevPageSize` (default: `task.pageSize`)

=== [[metrics]] Metrics

Scheduler Delay is...FIXME

Task Deserialization Time is...FIXME

Result Serialization Time is...FIXME

Getting Result Time is...FIXME

Peak Execution Memory is...FIXME

Shuffle Read Time is...FIXME

Executor Computing Time is...FIXME

Shuffle Write Time is...FIXME

.DAG Visualization
image::images/spark-webui-stage-dagvisualization.png[align="center"]

.Event Timeline
image::images/spark-webui-stage-eventtimeline.png[align="center"]

.Stage Task and Shuffle Stats
image::images/spark-webui-stage-header.png[align="center"]

.Summary Metrics for Completed Tasks
image::images/spark-webui-stage-summary-metrics-tasks.png[align="center"]

=== Aggregated Metrics by Executor

`ExecutorTable` table shows the following columns:

* Executor ID
* Address
* Task Time
* Total Tasks
* Failed Tasks
* Killed Tasks
* Succeeded Tasks
* (optional) Input Size / Records (only when the stage has an input)
* (optional) Output Size / Records (only when the stage has an output)
* (optional) Shuffle Read Size / Records (only when the stage read bytes for a shuffle)
* (optional) Shuffle Write Size / Records (only when the stage wrote bytes for a shuffle)
* (optional) Shuffle Spill (Memory) (only when the stage spilled memory bytes)
* (optional) Shuffle Spill (Disk) (only when the stage spilled bytes to disk)

.Aggregated Metrics by Executor
image::images/spark-webui-stage-aggregated-metrics-by-executor.png[align="center"]

It gets `executorSummary` from `StageUIData` (for the stage and stage attempt id) and creates rows per executor.

It also link:spark-webui-JobProgressListener.adoc#blockManagerIds[requests BlockManagers (from JobProgressListener)] to map executor ids to a pair of host and port to display in Address column.

=== [[accumulators]] Accumulators

Stage page displays the table with link:spark-accumulators.adoc#named[named accumulators] (only if they exist). It contains the name and value of the accumulators.

.Accumulators Section
image::images/spark-webui-stage-accumulators.png[align="center"]

NOTE: The information with name and value is stored in link:spark-accumulators.adoc#AccumulableInfo[AccumulableInfo] (that is available in link:spark-webui-JobProgressListener.adoc#StageUIData[StageUIData]).

=== [[tasks]] Tasks

.Tasks Section
image::images/spark-webui-stage-tasks.png[align="center"]

=== [[settings]] Settings

==== [[spark.ui.timeline.tasks.maximum]] spark.ui.timeline.tasks.maximum

`spark.ui.timeline.tasks.maximum` (default: `1000`) ...FIXME

==== [[spark.sql.unsafe.enabled]] spark.sql.unsafe.enabled

`spark.sql.unsafe.enabled` (default: `true`)...FIXME
