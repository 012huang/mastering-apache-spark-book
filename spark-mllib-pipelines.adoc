== ML Pipelines - High-Level API for MLlib

Both http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html[scikit-learn] and http://graphlab.com/learn/userguide/index.html#Deployment[GraphLab] have the concept of *pipelines* built into their system.

Concepts:

* *transformers*

Use of a machine learning algorithm is only one component of *a predictive analytic workflow*. There can also be *pre-processing steps* for the machine learning algorithm to work.

Example: In text classification, preprocessing steps like n-gram extraction, and TF-IDF feature weighting are often necessary before training of a classification model like an SVM.

Upon deploying a model, your system must not only know the SVM weights to apply to input features, but also transform raw data into the format the model is trained on.

* Pipeline for text categorization
* Pipeline for image classification

Pipelines are like a query plan in a database system.

Components of ML Pipeline:

* *Pipeline Construction Framework* â€“ A DSL for the construction of pipelines that includes concepts of *Nodes* and *Pipelines*.
** Nodes are data transformation steps (*transformers*)
** Pipelines are a DAG of Nodes.
+
Pipelines become objects that can be saved out and applied in real-time to new data.

It can help creating domain-specific feature transformers, general purpose transformers, statistical utilities and nodes.

=== Further reading

* https://amplab.cs.berkeley.edu/ml-pipelines/[ML Pipelines]
* https://databricks.com/blog/2015/01/07/ml-pipelines-a-new-high-level-api-for-mllib.html[ML Pipelines: A New High-Level API for MLlib]
