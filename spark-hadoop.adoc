== Spark and Hadoop

* Hadoop is HDFS, MapReduce, and YARN.
* Hadoop is storage and compute platform.
** MapReduce is the computing part.
** HDFS is the storage.
* Hadoop is a resource and cluster manager (YARN)
* Spark runs on YARN clusters, and can read from and save data to HDFS.
** leverages link:spark-data-locality.adoc[data locality]
* Spark needs distributed file system and HDFS (or Amazon S3, but slower) is a great choice.
* HDFS allows for link:spark-data-locality.adoc[data locality].
* Excellent throughput when Spark and Hadoop are both distributed and co-located on the same (YARN or Mesos) cluster nodes.
* HDFS offers (important for initial loading of data):
** high data locality
** high throughput when co-located with Spark
** low latency because of data locality
** very reliable because of replication
