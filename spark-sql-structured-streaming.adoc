== Structured Streaming (aka Streaming Datasets)

*Structured Streaming* is a high-level streaming API built on link:spark-sql-dataset.adoc[Dataset] over Spark SQL engine for continuous incremental execution of structured queries.

NOTE: It is slated for Spark 2.0 in June 2016.

Structured streaming is to unify streaming, interactive, and batch queries that paves the way for *continuous applications*.

It introduces the *streaming datasets* that are _infinite datasets_ as well as the primitives like *event time*, *windowing*, *sessions*, *sources* and *sinks*.

Among the data abstractions you can find:

* link:spark-sql-continuousquery.adoc[ContinuousQuery]
* link:spark-sql-source.adoc[Source]

Every *trigger* (time) a computation on DataFrames should be performed.

NOTE: The feature has also been called *Streaming Spark SQL Query* or *Streaming DataFrames* or *Continuous DataFrames* or *Continuous Queries*.

TIP: Watch https://issues.apache.org/jira/browse/SPARK-8360[SPARK-8360 Streaming DataFrames] to track progress of the feature.

Below is a complete example of a streaming dataset that streams data from `hello` Parquet file into a link:spark-sql-sink.adoc#MemorySink[MemorySink].

[source, scala]
----
val in = spark
  .read
  .format("text")
  .stream("hello")

scala> in.isStreaming
res0: Boolean = true

import scala.concurrent.duration._
import org.apache.spark.sql.ProcessingTime
val out = in.write
  .format("memory")
  .trigger(ProcessingTime(10.seconds))
  .queryName("memStream")
  .startStream()
----

=== [[i-want-more]] Further reading or watching

* (video) https://youtu.be/oXkxXDG0gNk[The Future of Real Time in Spark] from Spark Summit East 2016 in which Reynold Xin presents the concept of *Streaming DataFrames* to the public.
* (video) https://youtu.be/i7l3JQRx7Qw?t=19m15s[Structuring Spark: DataFrames, Datasets, and Streaming]
* http://www.infoworld.com/article/3052924/analytics/what-sparks-structured-streaming-really-means.html[What Spark's Structured Streaming really means]
