== Structured Streaming (aka Streaming Datasets)

*Structured Streaming* is a high-level streaming API over Spark SQL engine for continuous execution of structured queries.

It introduces *streaming datasets* that are _infinite datasets_ and primitives like *event time*, *windowing*, *sessions*, *sources* and *sinks*.

NOTE: It is slated for Spark 2.0 at the end of April or beginning of May, 2016.

Structured Streaming is to unify streaming, interactive, and batch queries.

Among the data abstractions you can find:

* link:spark-sql-continuousquery.adoc[ContinuousQuery]
* link:spark-sql-source.adoc[Source]

Every *trigger* (time) a computation on DataFrames should be performed.

NOTE: The feature has also been called *Streaming Spark SQL Query* or *Streaming DataFrames* or *Continuous DataFrames* or *Continuous Queries*.

TIP: Watch https://issues.apache.org/jira/browse/SPARK-8360[SPARK-8360 Streaming DataFrames] to track progress of the feature.

Below is a complete example of a streaming dataset that streams data from `hello` Parquet file into a link:spark-sql-sink.adoc#MemorySink[MemorySink].

[source, scala]
----
val reader = sqlContext.read
val in = reader.stream("hello")

scala> in.isStreaming
res0: Boolean = true

val out = in.write
  .format("memory")
  .queryName("memStream")
  .startStream()
----

=== [[i-want-more]] Further reading or watching

* (video) https://youtu.be/oXkxXDG0gNk[The Future of Real Time in Spark] from Spark Summit East 2016 in which Reynold Xin presents the concept of *Streaming DataFrames* to the public.
* (video) https://youtu.be/i7l3JQRx7Qw?t=19m15s[Structuring Spark: DataFrames, Datasets, and Streaming]
* http://www.infoworld.com/article/3052924/analytics/what-sparks-structured-streaming-really-means.html[What Spark's Structured Streaming really means]
