== Structured Streaming (aka Streaming Datasets)

*Structured Streaming* is a high-level streaming API built on link:spark-sql-dataset.adoc[Dataset] over Spark SQL engine for continuous incremental execution of structured queries.

NOTE: It is _supposed_ to be included in Spark 2.0.

Structured streaming is to unify streaming, interactive, and batch queries that paves the way for *continuous applications*.

It introduces the *streaming datasets* that are _infinite datasets_ as well as the primitives like *event time*, *windowing*, *sessions*, *sources* and *sinks*.

It lives in `org.apache.spark.sql.streaming` package with the following main data abstractions:

* link:spark-sql-StreamingQueryManager.adoc[StreamingQueryManager]
* link:spark-sql-StreamingQuery.adoc[StreamingQuery]
* link:spark-sql-source.adoc[Source]
* link:spark-sql-sink.adoc[Sink]

Every *trigger* (time) a computation on DataFrames should be performed.

NOTE: The feature has also been called *Streaming Spark SQL Query* or *Streaming DataFrames* or *Continuous DataFrames* or *Continuous Queries*.

TIP: Watch https://issues.apache.org/jira/browse/SPARK-8360[SPARK-8360 Streaming DataFrames] to track progress of the feature.

=== [[example]] Example

Below is a complete example of a streaming dataset that streams data from `hello` Parquet file into a link:spark-sql-sink.adoc#MemorySink[MemorySink].

[source, scala]
----
import org.apache.spark.sql.types._
val schema = StructType(
  StructField("f1", IntegerType, true) ::
  StructField("f2", LongType, false) ::
  StructField("f3", BooleanType, false) :: Nil
)

val in = spark.readStream
  .schema(schema)
  .format("csv")
  .load("hello")

scala> in.isStreaming
res0: Boolean = true

import scala.concurrent.duration._
import org.apache.spark.sql.streaming.ProcessingTime
val out = in.writeStream
  .format("console")
  .trigger(ProcessingTime(10.seconds))
  .queryName("textStream")
  .start()
----

=== [[i-want-more]] Further reading or watching

* (video) https://youtu.be/oXkxXDG0gNk[The Future of Real Time in Spark] from Spark Summit East 2016 in which Reynold Xin presents the concept of *Streaming DataFrames* to the public.
* (video) https://youtu.be/i7l3JQRx7Qw?t=19m15s[Structuring Spark: DataFrames, Datasets, and Streaming]
* http://www.infoworld.com/article/3052924/analytics/what-sparks-structured-streaming-really-means.html[What Spark's Structured Streaming really means]
