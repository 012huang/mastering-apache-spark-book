== Accumulators

TIP: Read the official documentation about http://spark.apache.org/docs/latest/programming-guide.html#accumulators[Accumulators] before looking for anything useful here. This document is not ready for prime time yet.

You can create accumulators using the link:spark-sparkcontext.adoc#accumulator[SparkContext.accumulator] methods. You can create accumulators with or without a name. *Named accumulators* are displayed in Spark's webUI under Stages tab for a given stage.

.Accumulators in the Spark UI
image::images/spark-webui-accumulators.png[align="center"]

Internally, `accumulator` methods create an instance of <<Accumulator, Accumulator>> and register it to link:spark-service-contextcleaner.adoc[ContextCleaner] for cleanup (using link:spark-service-contextcleaner.adoc#registerAccumulatorForCleanup[registerAccumulatorForCleanup] method).

Each task creates its own local accumulator.

Noticed on the user@spark mailing list that using an external key-value store (like HBase, Redis, Cassandra) and performing lookups/updates inside of your mappers (creating a connection within a link:spark-rdd-transformations.adoc#mapPartitions[mapPartitions] code block to avoid the connection setup/teardown overhead) might be a better solution.

If hbase is used as the external key value store, atomicity is guaranteed

=== [[Accumulator]] Accumulator

=== [[AccumulatorParam]] AccumulatorParam

=== [[i-want-more]] Further reading or watching

* http://www.cs.berkeley.edu/~agearh/cs267.sp10/files/mosharaf-spark-bc-report-spring10.pdf[Performance and Scalability of Broadcast in Spark]
