== [[WindowExpression]] WindowExpression

`WindowExpression` is an link:spark-sql-catalyst-Expression.adoc#Unevaluable[Unevaluable expression] (i.e. `eval` and `doGenCode` are not supported).

[source, scala]
----
import org.apache.spark.sql.catalyst.expressions.WindowExpression
scala> val windowExpr = spark.emptyDataset[Int]
  .selectExpr("count() OVER (PARTITION BY value) AS count")
  .queryExecution
  .logical      // <1>
  .expressions
  .toList(0)
  .children(0)
  .asInstanceOf[WindowExpression]
windowExpr: org.apache.spark.sql.catalyst.expressions.WindowExpression = 'count() windowspecdefinition('value, UnspecifiedFrame)

scala> windowExpr.sql
res2: String = count() OVER (PARTITION BY `value` UnspecifiedFrame)
----
<1> Use `sqlParser` directly as in the <<WithWindowDefinition-example, WithWindowDefinition Example>> below.

[[windowFunction]][[windowSpec]]
`WindowExpression` is created for `windowFunction` and `WindowSpecDefinition` link:spark-sql-catalyst-Expression.adoc[expressions].

NOTE: `WindowExpression` is used in `Analyzer` in link:spark-sql-Analyzer.adoc#ExtractWindowExpressions[ExtractWindowExpressions], link:spark-sql-Analyzer.adoc#ResolveWindowOrder[ResolveWindowOrder] link:spark-sql-Analyzer.adoc#ResolveWindowFrame[ResolveWindowFrame], link:spark-sql-Analyzer.adoc#WindowsSubstitution[WindowsSubstitution] rules.

NOTE: `WindowExpression` is also used in `Analyzer` for link:spark-sql-Analyzer-CheckAnalysis.adoc[analysis validation] for the following checks: FIXME...

NOTE: `WindowExpression` is used in link:spark-sql-Optimizer-NullPropagation.adoc[NullPropagation] optimization.

[[properties]]
.WindowExpression's Properties (in alphabetical order)
[width="100%",cols="1,2",options="header"]
|===
| Name
| Description

| `children`
| Collection of two link:spark-sql-catalyst-Expression.adoc[expressions], i.e. <<windowFunction, windowFunction>> and <<windowSpec, WindowSpecDefinition>>, for which `WindowExpression` was created.

| `dataType`
| link:spark-sql-DataType.adoc[DataType] of <<windowFunction, windowFunction>>

| `foldable`
| Whether or not <<windowFunction, windowFunction>> is foldable.

| `nullable`
| Whether or not <<windowFunction, windowFunction>> is nullable.

| `sql`
| `"[windowFunction].sql OVER [windowSpec].sql"`

| `toString`
| `"[windowFunction] [windowSpec]"`
|===

=== [[WithWindowDefinition]] WithWindowDefinition Unary Logical Plan

`WithWindowDefinition` is a link:spark-sql-LogicalPlan.adoc#UnaryNode[unary logical plan] with a single `child` logical plan and a `windowDefinitions` lookup table of `WindowSpecDefinition` per name.

`WithWindowDefinition` is created exclusively when `AstBuilder` link:spark-sql-AstBuilder.adoc#withWindows[parses windows].

[[WithWindowDefinition-properties]]
.WithWindowDefinition's Properties (in alphabetical order)
[width="100%",cols="1,2",options="header"]
|===
| Name
| Description

| `output`
| Output of the `child` logical plan.
|===

==== [[WithWindowDefinition-example]] WithWindowDefinition Example

[source, scala]
----
// Table for FROM clauses below
(0 to 5).toDF("id").createOrReplaceTempView("ids")

// Example with window specification alias and definition

val sqlText = """
  SELECT count(*) OVER anotherWindowSpec
  FROM ids
  WINDOW
    anotherWindowSpec AS myWindowSpec,
    myWindowSpec AS (
      PARTITION BY id
      RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
    )
"""

import spark.sessionState.{analyzer,sqlParser}

scala> sqlParser.parsePlan(sqlText)
res1: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan =
'WithWindowDefinition Map(anotherWindowSpec -> windowspecdefinition('id, RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), myWindowSpec -> windowspecdefinition('id, RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW))
+- 'Project [unresolvedalias(unresolvedwindowexpression('count(1), WindowSpecReference(anotherWindowSpec)), None)]
   +- 'UnresolvedRelation `ids`

scala> sql(sqlText)
res2: org.apache.spark.sql.DataFrame = [count(1) OVER (PARTITION BY id RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW): bigint]

scala> analyzer.execute(sqlParser.parsePlan(sqlText))
res3: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan =
Project [count(1) OVER (PARTITION BY id RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#12L]
+- Project [id#3, count(1) OVER (PARTITION BY id RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#12L, count(1) OVER (PARTITION BY id RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#12L]
   +- Window [count(1) windowspecdefinition(id#3, RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS count(1) OVER (PARTITION BY id RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#12L], [id#3]
      +- Project [id#3]
         +- SubqueryAlias ids
            +- Project [value#1 AS id#3]
               +- LocalRelation [value#1]
----
