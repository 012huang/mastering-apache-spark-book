== [[YarnSchedulerEndpoint]] YarnSchedulerEndpoint RPC Endpoint

`YarnSchedulerEndpoint` is a link:spark-rpc.adoc#ThreadSafeRpcEndpoint[ThreadSafeRpcEndpoint] that allows for communication between link:spark-yarn-yarnschedulerbackend.adoc[YarnSchedulerBackend] (on the driver) and link:spark-yarn-applicationmaster.adoc[ApplicationMaster] (on YARN).

CAUTION: FIXME Picture it.

[TIP]
====
Enable `INFO` logging level for `org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint=INFO
```

Refer to link:spark-logging.adoc[Logging].
====

=== [[RegisterClusterManager]] RegisterClusterManager

[source, scala]
----
RegisterClusterManager(am: RpcEndpointRef)
----

When `RegisterClusterManager` arrives, the following INFO message is printed out to the logs:

```
INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as [am]
```

The internal reference to the remote AM RPC Endpoint (`amEndpoint`) is set (to `am`).

If the internal link:spark-yarn-yarnschedulerbackend.adoc#shouldResetOnAmRegister[shouldResetOnAmRegister] flag is enabled (i.e. `true`), link:spark-yarn-yarnschedulerbackend.adoc#reset[YarnSchedulerBackend is reset]. It is disabled (i.e. `false`) initially, so `shouldResetOnAmRegister` is turned on.

=== [[RequestExecutors]] RequestExecutors

=== [[RemoveExecutor]] RemoveExecutor

=== [[KillExecutors]] KillExecutors

=== [[AddWebUIFilter]] AddWebUIFilter

=== [[RetrieveLastAllocatedExecutorId]] RetrieveLastAllocatedExecutorId

=== [[onDisconnected]] onDisconnected

=== [[onStop]] onStop
