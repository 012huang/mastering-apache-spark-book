== [[CreatableRelationProvider]] CreatableRelationProvider -- Data Sources with Tuples with Fixed Schema

`CreatableRelationProvider` is a <<contract, contract>> for data sources that <<createRelation, manage a collection of tuples with a fixed schema>>.

`CreatableRelationProvider` is used when:

* `DataSource` is requested to link:spark-sql-DataSource.adoc#write[write the result of a structured query to data source per save mode] (after `DataFrameWriter` is requested to link:spark-sql-dataframewriter.adoc#save[save])

* `DataSource` is requested to link:spark-sql-DataSource.adoc#writeAndRead[write the result of a structured query to data source per save mode followed by reading rows back] (after `DataFrameWriter` is requested to link:spark-sql-dataframewriter.adoc#saveAsTable[save to a non-Hive table] or for link:spark-sql-SparkSqlAstBuilder.adoc#visitCreateTable[Create Table As Select] SQL statements)

[[available-implementations]]
.CreatableRelationProvider's Available Implementations
[width="100%",cols="1,2",options="header"]
|===
| Name
| Description

| link:spark-sql-JdbcRelationProvider.adoc[JdbcRelationProvider]
|

| link:spark-sql-DataSourceRegister-KafkaSourceProvider.adoc[KafkaSourceProvider]
|
|===

CAUTION: FIXME Can a CreatableRelationProvider create a BaseRelation with different schema than the input `data` DataFrame? Can a CreatableRelationProvider somehow optimize the schema?

=== [[contract]] CreatableRelationProvider Contract

[source, scala]
----
package org.apache.spark.sql.sources

trait CreatableRelationProvider {
  def createRelation(
    sqlContext: SQLContext,
    mode: SaveMode,
    parameters: Map[String, String],
    data: DataFrame): BaseRelation
}
----

.CreatableRelationProvider Contract
[cols="1,2",options="header",width="100%"]
|===
| Method
| Description

| [[createRelation]] `createRelation`
| Creates a link:spark-sql-BaseRelation.adoc[BaseRelation]
|===
