== [[SparkSqlParser]] SparkSqlParser

`SparkSqlParser` is the default parser of the SQL statements supported in Spark SQL. It is available as link:spark-sql-SessionState.adoc#sqlParser[sqlParser] (as the current link:spark-sql-ParserInterface.adoc[ParserInterface]) through `SessionState`.

The common idiom in Spark SQL is as follows:

[source, scala]
----
sparkSession.sessionState.sqlParser
----

`SparkSqlParser` is a link:spark-sql-AbstractSqlParser.adoc[AbstractSqlParser] with the `astBuilder` being link:spark-sql-SparkSqlAstBuilder.adoc[SparkSqlAstBuilder]. It supports <<VariableSubstitution, variable substitution>>.

`SparkSqlParser` is used to parse expression strings into their corresponding link:spark-sql-columns.adoc[Columns] objects in the following:

1. link:spark-sql-functions.adoc#expr[expr] function
2. link:spark-sql-Dataset.adoc#selectExpr[selectExpr] method (of `Dataset`)
3. link:spark-sql-Dataset.adoc#filter[filter] method (of `Dataset`)
4. link:spark-sql-Dataset.adoc#where[where] method (of `Dataset`)

[source, scala]
----
scala> expr("token = 'hello'")
16/07/07 18:32:53 INFO SparkSqlParser: Parsing command: token = 'hello'
res0: org.apache.spark.sql.Column = (token = hello)
----

`SparkSqlParser` is used to parse table strings into their corresponding table identifiers in the following:

1. `table` methods in link:spark-sql-dataframereader.adoc#table[DataFrameReader] and link:spark-sql-sparksession.adoc#table[SparkSession]
2. link:spark-sql-dataframewriter.adoc#insertInto[insertInto] and link:spark-sql-dataframewriter.adoc#saveAsTable[saveAsTable] methods of `DataFrameWriter`
3. `createExternalTable` and `refreshTable` methods of link:spark-sql-Catalog.adoc[Catalog] (and link:spark-sql-SessionState.adoc#refreshTable[SessionState])

`SparkSqlParser` is used to parse sql strings into their corresponding link:spark-sql-LogicalPlan.adoc[logical query plans] in the following:

1. link:spark-sql-sparksession.adoc#sql[sql] method in `SparkSession`

[[logging]]
[TIP]
====
Enable `INFO` logging level for `org.apache.spark.sql.execution.SparkSqlParser` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.sql.execution.SparkSqlParser=INFO
```

Refer to link:spark-logging.adoc[Logging].
====

=== [[VariableSubstitution]] Variable Substitution

CAUTION: FIXME See `SparkSqlParser` and `substitutor`.
