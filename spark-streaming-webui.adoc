== web UI and Streaming Statistics Page

When you link:spark-streaming-streamingcontext.adoc#start[start a Spark Streaming application], you can use link:spark-webui.adoc[web UI] to monitor streaming statistics in *Streaming* tab (aka _page_).

.Streaming Tab in web UI
image::images/spark-streaming-webui-streaming-tab.png[align="center"]

The page is made up of three sections (aka _tables_) - the unnamed, top-level one with <<basic-info, basic information>> about the streaming application (right below the title *Streaming Statistics*), <<active-batches, Active Batches>> and <<catched-batches, Completed Batches>>.

NOTE: The Streaming page uses link:spark-streaming-streaminglisteners.adoc#StreamingJobProgressListener[StreamingJobProgressListener] for most of the information displayed.

=== [[basic-info]] Basic Information

*Basic Information* section is the top-level section in the Streaming page that offers basic information about the streaming application.

.Basic Information section in Streaming Page (with Receivers)
image::images/spark-streaming-webui-streaming-statistics.png[align="center"]

The section shows the link:spark-streaming-dstreamgraph.adoc#batchDuration[batch duration] (in _Running batches of [batch duration]_), and the time it runs for and since link:spark-streaming-streamingcontext.adoc#creating-instance[StreamingContext was created] (_not_ when this streaming application has been started!).

It shows the number of *completed batches* and *received records* (in parenthesis). These information are later displayed in detail in <<active-batches, Active Batches>> and <<catched-batches, Completed Batches>> sections.

Below is the table for link:spark-streaming-streaminglisteners.adoc#retainedBatches[retained batches] (i.e. waiting, running, and completed batches).

In *Input Rate* row, you can show and hide details of each input stream.

If there are link:spark-streaming-receiverinputdstreams.adoc[input streams with receivers], the numbers of all the receivers and active ones are displayed (as depicted in the Figure 2 above).

The average event rate for all registered streams is displayed (as _Avg: [avg] events/sec_).

==== [[scheduling-delay]] Scheduling Delay

*Scheduling Delay* is the time spent from link:spark-streaming-jobscheduler.adoc#submitJobSet[when the collection of streaming jobs for a batch was submitted] to link:spark-streaming-jobscheduler.adoc#JobStarted[when the first streaming job (out of possibly many streaming jobs in the collection) was started].

.Scheduling Delay in Streaming Page
image::images/spark-streaming-webui-streaming-page-scheduling-delay.png[align="center"]

It should be as low as possible meaning that the streaming jobs in batches are scheduled almost instantly.

You may see increase in scheduling delay when streaming jobs are queued up as in the following example:

[source, scala]
----
// batch duration = 5 seconds
val messages: InputDStream[(String, String)] = ...
messages.foreachRDD { rdd =>
  println(">>> Taking a 15-second sleep")
  rdd.foreach(println)
  java.util.concurrent.TimeUnit.SECONDS.sleep(15)
}
----

.Scheduling Delay Increased in Streaming Page
image::images/spark-streaming-webui-scheduling-delay-increase.png[align="center"]

==== [[processing-time]] Processing Time

*Processing Time* is the time spent to run all jobs of a batch.

==== [[total-delay]] Total Delay

*Total Delay* is the time spent from submitting to complete all jobs of a batch.

=== [[active-batches]] Active Batches

*Active Batches* section presents `waitingBatches` and `runningBatches` together.

=== [[completed-batches]] Completed Batches

*Completed Batches* section presents `completedBatchUIData`.

=== Example - Kafka Direct Stream in web UI

.Two Batches with Incoming Data inside for Kafka Direct Stream in web UI (Streaming tab)
image::images/spark-streaming-webui-streaming-tab-kafka-directstream-two-batches.png[align="center"]

.Two Jobs for Kafka Direct Stream in web UI (Jobs tab)
image::images/spark-streaming-webui-kafka-directinputstream-two-jobs.png[align="center"]
