== BlockManagerMaster -- BlockManager for Driver

`BlockManagerMaster` link:spark-sparkenv.adoc#BlockManagerMaster[runs on the driver and executors].

`BlockManagerMaster` uses <<BlockManagerMasterEndpoint, BlockManagerMasterEndpoint>> registered under `BlockManagerMaster` RPC endpoint name on the driver (with the endpoint references on executors) to allow executors for sending block status updates to it and hence keep track of block statuses.

NOTE: An instance of `BlockManagerMaster` is created in link:spark-sparkenv.adoc#BlockManagerMaster[SparkEnv (for the driver and executors)], and immediately used to create their link:spark-blockmanager.adoc[BlockManagers].

[TIP]
====
Enable `INFO` or `DEBUG` logging level for `org.apache.spark.storage.BlockManagerMaster` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.storage.BlockManagerMaster=INFO
```

Refer to link:spark-logging.adoc[Logging].
====

=== [[creating-instance]] Creating BlockManagerMaster Instance

An instance of `BlockManagerMaster` requires a <<BlockManagerMasterEndpoint, BlockManagerMaster RPC endpoint>> reference, link:spark-configuration.adoc[SparkConf], and the `isDriver` flag to control whether it is created for the driver or executors.

NOTE: An instance of `BlockManagerMaster` is created as part of link:spark-sparkenv.adoc#BlockManagerMaster[creating an instance of SparkEnv for the driver and executors].

=== [[removeExecutor]] Removing Executor (removeExecutor method)

[source, scala]
----
removeExecutor(execId: String): Unit
----

`removeExecutor` posts `RemoveExecutor(execId)` to <<BlockManagerMasterEndpoint, BlockManagerMaster RPC endpoint>> and waits for a response.

If `false` in response comes in, a `SparkException` is thrown with the following message:

```
BlockManagerMasterEndpoint returned false, expected true.
```

If all goes fine, you should see the following INFO message in the logs:

```
INFO BlockManagerMaster: Removed executor [execId]
```

=== [[removeBlock]] Removing Block -- `removeBlock` Method

[source, scala]
----
removeBlock(blockId: BlockId): Unit
----

`removeBlock` simply posts a `RemoveBlock` blocking message to <<BlockManagerMasterEndpoint, BlockManagerMaster RPC endpoint>> (and ultimately disregards the reponse).

=== [[removeRdd]] Removing RDD Blocks (removeRdd method)

[source, scala]
----
removeRdd(rddId: Int, blocking: Boolean)
----

`removeRdd` removes all the blocks of `rddId` RDD, possibly in a `blocking` fashion.

It posts a `RemoveRdd(rddId)` message to <<BlockManagerMasterEndpoint, BlockManagerMaster RPC endpoint>> on a separate thread.

If there is an issue, you should see the following WARN message in the logs and the entire exception:

```
WARN Failed to remove RDD [rddId] - [exception]
```

If it is a `blocking` operation, it waits for a result for link:spark-rpc.adoc#spark.rpc.askTimeout[spark.rpc.askTimeout], link:spark-rpc.adoc#spark.network.timeout[spark.network.timeout] or `120` secs.

=== [[removeShuffle]] Removing Shuffle Blocks (removeShuffle method)

[source, scala]
----
removeShuffle(shuffleId: Int, blocking: Boolean)
----

`removeShuffle` removes all the blocks of `shuffleId` shuffle, possibly in a `blocking` fashion.

It posts a `RemoveShuffle(shuffleId)` message to <<BlockManagerMasterEndpoint, BlockManagerMaster RPC endpoint>> on a separate thread.

If there is an issue, you should see the following WARN message in the logs and the entire exception:

```
WARN Failed to remove shuffle [shuffleId] - [exception]
```

If it is a `blocking` operation, it waits for the result for link:spark-rpc.adoc#spark.rpc.askTimeout[spark.rpc.askTimeout], link:spark-rpc.adoc#spark.network.timeout[spark.network.timeout] or `120` secs.

=== [[removeBroadcast]] Removing Broadcast Blocks (removeBroadcast method)

[source, scala]
----
removeBroadcast(broadcastId: Long, removeFromMaster: Boolean, blocking: Boolean)
----

`removeBroadcast` removes all the blocks of `broadcastId` broadcast, possibly in a `blocking` fashion.

It posts a `RemoveBroadcast(broadcastId, removeFromMaster)` message to <<BlockManagerMasterEndpoint, BlockManagerMaster RPC endpoint>> on a separate thread.

If there is an issue, you should see the following WARN message in the logs and the entire exception:

```
WARN Failed to remove broadcast [broadcastId] with removeFromMaster = [removeFromMaster] - [exception]
```

If it is a `blocking` operation, it waits for the result for link:spark-rpc.adoc#spark.rpc.askTimeout[spark.rpc.askTimeout], link:spark-rpc.adoc#spark.network.timeout[spark.network.timeout] or `120` secs.

=== [[stop]] Stopping BlockManagerMaster (stop method)

[source, scala]
----
stop(): Unit
----

`stop` sends a `StopBlockManagerMaster` message to <<BlockManagerMasterEndpoint, BlockManagerMaster RPC endpoint>> and waits for a response.

NOTE: It is only executed for the driver.

If all goes fine, you should see the following INFO message in the logs:

```
INFO BlockManagerMaster: BlockManagerMaster stopped
```

Otherwise, a `SparkException` is thrown.

```
BlockManagerMasterEndpoint returned false, expected true.
```

=== [[registerBlockManager]] Registering BlockManager to Driver (registerBlockManager method)

[source, scala]
----
registerBlockManager(
  blockManagerId: BlockManagerId,
  maxMemSize: Long,
  slaveEndpoint: RpcEndpointRef): Unit
----

When `registerBlockManager` runs, you should see the following INFO message in the logs:

```
INFO BlockManagerMaster: Trying to register BlockManager
```

.Registering BlockManager with the Driver
image::images/spark-BlockManagerMaster-RegisterBlockManager.png[align="center"]

It then informs the driver about the new `BlockManager` by sending <<RegisterBlockManager, `RegisterBlockManager` to BlockManagerMaster RPC endpoint>> and waiting for a response.

If all goes fine, you should see the following INFO message in the logs:

```
INFO BlockManagerMaster: Registered BlockManager
```

Otherwise, a `SparkException` is thrown.

```
BlockManagerMasterEndpoint returned false, expected true.
```

NOTE: `registerBlockManager` is called while link:spark-blockmanager.adoc#initialize[BlockManager is being initialized] (on the driver and executors) and while link:spark-blockmanager.adoc#reregister[re-registering blocks to the driver].

=== [[updateBlockInfo]] Sending UpdateBlockInfo to Driver (updateBlockInfo method)

[source, scala]
----
updateBlockInfo(
  blockManagerId: BlockManagerId,
  blockId: BlockId,
  storageLevel: StorageLevel,
  memSize: Long,
  diskSize: Long): Boolean
----

`updateBlockInfo` sends a `UpdateBlockInfo` message to <<BlockManagerMasterEndpoint, BlockManagerMaster RPC endpoint>> and waits for a response.

You should see the following DEBUG message in the logs:

```
DEBUG BlockManagerMaster: Updated info of block [blockId]
```

The response from the BlockManagerMaster RPC endpoint is returned.

=== [[getLocations-block]] Get Block Locations of One Block (getLocations method)

[source, scala]
----
getLocations(blockId: BlockId): Seq[BlockManagerId]
----

`getLocations` posts `GetLocations(blockId)` message to <<BlockManagerMasterEndpoint, BlockManagerMaster RPC endpoint>> and waits for a response which becomes the return value.

=== [[getLocations-block-array]] Get Block Locations for Multiple Blocks (getLocations method)

[source, scala]
----
getLocations(blockIds: Array[BlockId]): IndexedSeq[Seq[BlockManagerId]]
----

`getLocations` posts `GetLocationsMultipleBlockIds(blockIds)` message to <<BlockManagerMasterEndpoint, BlockManagerMaster RPC endpoint>> and waits for a response which becomes the return value.

=== [[getPeers]] getPeers

[source, scala]
----
getPeers(blockManagerId: BlockManagerId): Seq[BlockManagerId]
----

`getPeers` posts `GetPeers(blockManagerId)` message <<BlockManagerMasterEndpoint, BlockManagerMaster RPC endpoint>> and waits for a response which becomes the return value.

=== [[getExecutorEndpointRef]] getExecutorEndpointRef

[source, scala]
----
getExecutorEndpointRef(executorId: String): Option[RpcEndpointRef]
----

`getExecutorEndpointRef` posts `GetExecutorEndpointRef(executorId)` message to <<BlockManagerMasterEndpoint, BlockManagerMaster RPC endpoint>> and waits for a response which becomes the return value.

=== [[getMemoryStatus]] getMemoryStatus

[source, scala]
----
getMemoryStatus: Map[BlockManagerId, (Long, Long)]
----

`getMemoryStatus` posts a `GetMemoryStatus` message <<BlockManagerMasterEndpoint, BlockManagerMaster RPC endpoint>> and waits for a response which becomes the return value.

=== [[getStorageStatus]] getStorageStatus

[source, scala]
----
getStorageStatus: Array[StorageStatus]
----

`getStorageStatus` posts a `GetStorageStatus` message to <<BlockManagerMasterEndpoint, BlockManagerMaster RPC endpoint>> and waits for a response which becomes the return value.

=== [[getBlockStatus]] getBlockStatus

[source, scala]
----
getBlockStatus(
  blockId: BlockId,
  askSlaves: Boolean = true): Map[BlockManagerId, BlockStatus]
----

`getBlockStatus` posts a `GetBlockStatus(blockId, askSlaves)` message to <<BlockManagerMasterEndpoint, BlockManagerMaster RPC endpoint>> and waits for a response (of type `Map[BlockManagerId, Future[Option[BlockStatus]]]`).

It then builds a sequence of future results that are `BlockStatus` statuses and waits for a result for link:spark-rpc.adoc#spark.rpc.askTimeout[spark.rpc.askTimeout], link:spark-rpc.adoc#spark.network.timeout[spark.network.timeout] or `120` secs.

No result leads to a `SparkException` with the following message:

```
BlockManager returned null for BlockStatus query: [blockId]
```

=== [[getMatchingBlockIds]] getMatchingBlockIds

[source, scala]
----
getMatchingBlockIds(
  filter: BlockId => Boolean,
  askSlaves: Boolean): Seq[BlockId]
----

`getMatchingBlockIds` posts a `GetMatchingBlockIds(filter, askSlaves)` message to <<BlockManagerMasterEndpoint, BlockManagerMaster RPC endpoint>> and waits for a response which becomes the result for link:spark-rpc.adoc#spark.rpc.askTimeout[spark.rpc.askTimeout], link:spark-rpc.adoc#spark.network.timeout[spark.network.timeout] or `120` secs.

=== [[hasCachedBlocks]] hasCachedBlocks

[source, scala]
----
hasCachedBlocks(executorId: String): Boolean
----

`hasCachedBlocks` posts a `HasCachedBlocks(executorId)` message to <<BlockManagerMasterEndpoint, BlockManagerMaster RPC endpoint>> and waits for a response which becomes the result.

=== [[BlockManagerMasterEndpoint]] BlockManagerMasterEndpoint -- BlockManagerMaster RPC Endpoint

`BlockManagerMasterEndpoint` is the RPC endpoint for <<BlockManagerMaster, BlockManagerMaster>> on the driver (aka master node) to track statuses of the block managers on executors.

NOTE: It is used to register the `BlockManagerMaster` RPC endpoint when link:spark-sparkenv.adoc#BlockManagerMaster[creating SparkEnv].

[TIP]
====
Enable `INFO` logging level for `org.apache.spark.storage.BlockManagerMasterEndpoint` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.storage.BlockManagerMasterEndpoint=INFO
```

Refer to link:spark-logging.adoc[Logging].
====

==== [[BlockManagerMasterEndpoint-internal-registries]] Internal Registries

===== [[BlockManagerMasterEndpoint-blockLocations]] blockLocations

`blockLocations` is a collection of `BlockId` and its locations (as `BlockManagerId`).

NOTE: It is used in `removeRdd` to remove blocks for a RDD, `removeBlockManager` to remove blocks after a BlockManager gets removed, `removeBlockFromWorkers`, `updateBlockInfo`, and <<BlockManagerMasterEndpoint-getLocations, getLocations>>.

==== RemoveExecutor

[source, scala]
----
RemoveExecutor(execId: String)
----

When `RemoveExecutor` is received, <<BlockManagerMasterEndpoint-removeExecutor, executor `execId` is removed>> and the response `true` sent back.

==== [[BlockManagerHeartbeat]] BlockManagerHeartbeat

CAUTION: FIXME

==== [[GetLocations]] GetLocations

[source, scala]
----
GetLocations(blockId: BlockId)
----

When `GetLocations` comes in, the internal <<BlockManagerMasterEndpoint-getLocations, getLocations>> method is executed and the result becomes the response sent back.

NOTE: `GetLocations` is used to <<getLocations, get the block locations of a single block>>.

==== [[RegisterBlockManager]] RegisterBlockManager

[source, scala]
----
RegisterBlockManager(
  blockManagerId: BlockManagerId,
  maxMemSize: Long,
  sender: RpcEndpointRef)
----

When `RegisterBlockManager` is received, the internal <<RegisterBlockManager-register, register>> method is executed.

NOTE: `RegisterBlockManager` is used to <<registerBlockManager, register a `BlockManager` to the driver>>.

===== [[RegisterBlockManager-register]] register

[source, scala]
----
register(id: BlockManagerId, maxMemSize: Long, slaveEndpoint: RpcEndpointRef): Unit
----

`register` records the current time and registers `BlockManager` by `id` if it has not been already registered (using the internal `blockManagerInfo` registry).

Registering a BlockManager can only happen once for an executor (identified by `BlockManagerId.executorId` using the internal `blockManagerIdByExecutor` registry).

If another `BlockManager` has earlier been registered for the executor, you should see the following ERROR message in the logs:

```
ERROR Got two different block manager registrations on same executor - will replace old one [oldId] with new one [id]
```

And then <<BlockManagerMasterEndpoint-removeExecutor, executor is removed>>.

You should see the following INFO message in the logs:

```
INFO Registering block manager [hostPort] with [bytes] RAM, [id]
```

The `BlockManager` is recorded in the internal registries: `blockManagerIdByExecutor` and `blockManagerInfo`.

CAUTION: FIXME Why does `blockManagerInfo` require a new `System.currentTimeMillis()` since `time` was already recorded?

In either case, link:spark-SparkListener.adoc#SparkListenerBlockManagerAdded[SparkListenerBlockManagerAdded(time, id, maxMemSize)] is posted to link:spark-sparkcontext.adoc#listenerBus[listenerBus].

NOTE: The method can only be executed on the driver where `listenerBus` is available.

CAUTION: FIXME Describe `listenerBus` + omnigraffle it.

==== Other RPC Messages

* UpdateBlockInfo
* GetLocationsMultipleBlockIds
* GetPeers
* GetRpcHostPortForExecutor
* GetMemoryStatus
* GetStorageStatus
* GetBlockStatus
* GetMatchingBlockIds
* RemoveRdd
* RemoveShuffle
* RemoveBroadcast
* RemoveBlock
* StopBlockManagerMaster
* BlockManagerHeartbeat
* HasCachedBlocks

==== [[BlockManagerMasterEndpoint-removeExecutor]] Removing Executor (removeExecutor method)

[source, scala]
----
removeExecutor(execId: String)
----

When executed, `removeExecutor` prints the following INFO message to the logs:

```
INFO BlockManagerMasterEndpoint: Trying to remove executor [execId] from BlockManagerMaster.
```

If the `execId` executor is found in the internal `blockManagerIdByExecutor` registry, <<BlockManagerMasterEndpoint-removeBlockManager, the `BlockManager` for the executor is removed>>.

==== [[BlockManagerMasterEndpoint-removeBlockManager]] Removing BlockManager (removeBlockManager method)

[source, scala]
----
removeBlockManager(blockManagerId: BlockManagerId)
----

When executed, `removeBlockManager` looks up `blockManagerId` and removes the executor it was working on from the internal `blockManagerIdByExecutor` as well as from `blockManagerInfo`.

NOTE: It is a private helper method that is exclusively used while <<BlockManagerMasterEndpoint-removeExecutor, removing an executor>>.

It then goes over all the blocks for the `BlockManager`, and removes the executor for each block from `blockLocations` registry.

link:spark-SparkListener.adoc#SparkListenerBlockManagerRemoved[SparkListenerBlockManagerRemoved(System.currentTimeMillis(), blockManagerId)] is posted to link:spark-sparkcontext.adoc#listenerBus[listenerBus].

You should then see the following INFO message in the logs:

```
INFO BlockManagerMasterEndpoint: Removing block manager [blockManagerId]
```

==== [[BlockManagerMasterEndpoint-getLocations]] Get Block Locations (getLocations method)

[source, scala]
----
getLocations(blockId: BlockId): Seq[BlockManagerId]
----

When executed, `getLocations` looks up `blockId` in the `blockLocations` internal registry and returns the locations (as a collection of `BlockManagerId`) or an empty collection.
