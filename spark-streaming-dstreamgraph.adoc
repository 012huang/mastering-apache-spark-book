== DStreamGraph

`DStreamGraph` (is a final helper class that) manages link:spark-streaming-dstreams.adoc[input and output streams].

It maintains the collections of link:spark-streaming-inputdstreams.adoc[InputDStream] instances (as `inputStreams`) and output link:spark-streaming-dstreams.adoc[DStream] instances (as `outputStreams`), but, more importantly, <<DStreamGraph-generateJobs, it generates streaming jobs for output streams for a batch>>.

[NOTE]
====
`DStreamGraph` holds `batchDuration` (using `setBatchDuration(duration: Duration)`) for other parts of the Streaming application.

It appears that it is _the_ place for the value since it must be set before link:spark-streaming-jobgenerator.adoc[JobGenerator] can be instantiated.

It _is_ set while link:spark-streaming-streamingcontext.adoc[StreamingContext] is being instantiated and is validated (using `validate()` method of `StreamingContext` and `DStreamGraph`) before `StreamingContext` is started.
====

When `DStreamGraph` is started (using `start(time: Time)` method), it saves `time` as `startTime`, and calls `initialize()` and `remember()` methods on every output stream (one by one). It then starts the input streams (in parallel).

[TIP]
====
Enable `DEBUG` logging level for `org.apache.spark.streaming.DStreamGraph` logger to see what happens in `DStreamGraph`.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.streaming.DStreamGraph=DEBUG
```

Refer to link:spark-logging.adoc[Logging].
====

=== [[DStreamGraph-generateJobs]] Generating Streaming Jobs for Output Streams for Time

`generateJobs(time: Time): Seq[Job]` is responsible for generating streaming jobs for output streams at a given `time`.

NOTE: `generateJobs` is called by link:spark-streaming-jobgenerator.adoc[JobGenerator] to link:spark-streaming-jobgenerator.adoc#GenerateJobs[generate jobs for a given time] or link:spark-streaming-jobgenerator.adoc#restarting[be restarted from checkpoint].

When `generateJobs` method executes, you should see the following DEBUG message in the logs:

```
DEBUG DStreamGraph: Generating jobs for time [time] ms
```

`generateJobs` then walks over each link:spark-streaming-dstreams.adoc#register[registered output stream] (in `outputStreams` internal registry) and generates a streaming job (using link:spark-streaming-dstreams.adoc#generateJob[DStream.generateJob]).

Right before the method finishes, you should see the following DEBUG message with the number of streaming jobs generated (as `jobs.length`):

```
DEBUG DStreamGraph: Generated [jobs.length] jobs for time [time] ms
```

=== [[dstreamgraph-validation]] Validation Check (using validate method)

`validate()` method checks whether batch duration and at least one output stream have been set. It will throw `java.lang.IllegalArgumentException` when either is not.

NOTE: It is called when link:spark-streaming-streamingcontext.adoc#start[StreamingContext starts].

=== [[clearMetadata]] Metadata Cleanup

NOTE: It is called when  link:spark-streaming-jobgenerator.adoc#ClearMetadata[JobGenerator clears metadata].

When `clearMetadata(time: Time)` is called, you should see the following DEBUG message in the logs:

```
DEBUG DStreamGraph: Clearing metadata for time [time] ms
```

It merely walks over the collection of output streams and (synchronously, one by one) asks to do link:spark-streaming-dstreams.adoc#clearMetadata[its own metadata cleaning].

When finishes, you should see the following DEBUG message in the logs:

```
DEBUG DStreamGraph: Cleared old metadata for time [time] ms
```
