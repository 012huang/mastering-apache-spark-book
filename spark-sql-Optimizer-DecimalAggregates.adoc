== [[DecimalAggregates]] DecimalAggregates Logical Optimization

`DecimalAggregates` is a link:spark-sql-Optimizer.adoc#DecimalAggregates[logical optimization] (aka `Rule[LogicalPlan]`) in link:spark-sql-Optimizer.adoc[Optimizer] that transforms `Sum` and `Average` aggregate functions on fixed-precision `DecimalType` values to use `UnscaledValue` (unscaled Long) values in link:spark-sql-Expression-WindowExpression.adoc[WindowExpression] and link:spark-sql-Expression-AggregateExpression.adoc[AggregateExpression] expressions.

NOTE: `DecimalAggregates` is the only optimization in the fixed-point link:spark-sql-Optimizer.adoc#Decimal-Optimizations[Decimal Optimizations] optimization rule batch in `Optimizer`.

[TIP]
====
Import `DecimalAggregates` and apply the rule directly on your structured queries to learn how the rule works.

[source, scala]
----
import org.apache.spark.sql.catalyst.optimizer.DecimalAggregates

val spark: org.apache.spark.sql.SparkSession = ...
val da = DecimalAggregates(spark.sessionState.conf)

// Build analyzed logical plan
scala> val plan = sql("select * from range(1)").queryExecution.analyzed
plan: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan =
Project [id#3L]
+- Range (0, 1, step=1, splits=None)

// Apply DecimalAggregates rule
scala> da.apply(plan)
res3: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan =
Project [id#3L]
+- Range (0, 1, step=1, splits=None)
----
====
