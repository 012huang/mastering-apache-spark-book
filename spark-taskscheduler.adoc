== Task Scheduler

A *Task Scheduler* schedules link:spark-taskscheduler-tasks.adoc[tasks] for a link:spark-anatomy-spark-application.adoc[single Spark application] according to <<scheduling-mode, scheduling mode>> (aka *order task policy*).

.TaskScheduler works for a single SparkContext
image::images/sparkstandalone-sparkcontext-taskscheduler-schedulerbackend.png[align="center"]

A Task Scheduler tracks the following mappings:

* TaskSets by stage and attempt ids (`taskSetsByStageIdAndAttempt`)
* tasks to their link:spark-tasksetmanager.adoc[TaskSetManagers] (`taskIdToTaskSetManager`)
* tasks to link:spark-executor.adoc[executors] (`taskIdToExecutorId`)
* the number of tasks running per link:spark-executor.adoc[executor] (`executorIdToTaskCount`)
* the set of link:spark-executor.adoc[executors] on each host (`executorsByHost`)
* the set of hosts per rack (`hostsByRack`)
* executor ids to corresponding host (`executorIdToHost`).

CAUTION: FIXME How are these mappings used?

CAUTION: FIXME Why `hasReceivedTask` and `hasLaunchedTask`?

It counts how many tasks have already been scheduled for execution (`nextTaskId`).

A TaskScheduler gets sets of tasks (as <<taskset, TaskSets>>) submitted to it from the link:spark-dagscheduler.adoc[DAGScheduler] for each stage, and is responsible for sending the tasks to the cluster, running them, retrying if there are failures, and mitigating stragglers.

A TaskScheduler emits events to the DAGScheduler.

The base implementation of Task Scheduler in Spark is https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/TaskSchedulerImpl.scala[org.apache.spark.scheduler.TaskSchedulerImpl]. There are two specialized implementations for link:spark-yarn.adoc[Spark on YARN cluster mode] - https://github.com/apache/spark/blob/master/yarn/src/main/scala/org/apache/spark/scheduler/cluster/YarnScheduler.scala[YarnScheduler] and https://github.com/apache/spark/blob/master/yarn/src/main/scala/org/apache/spark/scheduler/cluster/YarnClusterScheduler.scala[YarnClusterScheduler].

The default implementation `TaskSchedulerImpl` can schedule tasks for multiple types of clusters by acting through a link:spark-scheduler-backends.adoc[Scheduler Backend]. It handles common logic, like determining a scheduling order across jobs, waking up to launch speculative tasks, etc.

.TaskScheduler uses SchedulerBackend for different clusters
image::diagrams/taskscheduler-uses-schedulerbackend.png[align="center"]

When a Task Scheduler is started, it starts a Scheduler Backend.

.TaskScheduler.start
image::images/taskscheduler-start.png[align="center"]

DAGScheduler uses <<submitTasks, submitTasks() operation >> to submit a TaskSet to Task Scheduler and can cancel tasks in a stage.

=== TaskContextImpl

CAUTION: FIXME

* stage
* partition
* task attempt
* attempt number
* runningLocally = false

=== TaskMemoryManager

CAUTION: FIXME

=== TaskMetrics

CAUTION: FIXME

=== [[taskset]] TaskSet

A *TaskSet* is a set of tasks submitted together to TaskScheduler that belong to a single stage and an attempt.

A TaskSet represents the missing partitions of a stage.

The pair of a stage and an attempt uniquely describes a TaskSet and that is what you can see in the logs:

```
TaskSet [stageId].[stageAttemptId]
```

TaskSet has *priority* and *properties*. Priority is used in FIFO scheduling mode. Properties are the properties of the first job in a stage.

CAUTION: FIXME Where are `properties` of a TaskSet used?

A TaskSet contains a fully-independent sequence of tasks that can run right away based on the data that is already on the cluster, e.g. map output files from previous stages, though it may fail if this data becomes unavailable.

TaskSet can be <<submitTasks, submitted>>, i.e. started.

=== [[TaskResultGetter]] TaskResultGetter

FIXME

=== [[scheduling-mode]] Scheduling Modes

Task Scheduler uses a scheduling mode that determines policy to order tasks across a Schedulable's sub-queues.

It is configured by <<settings, spark.scheduler.mode>> setting that can accept the following values:

* *FIFO* - no pools; one root pool with link:spark-tasksetmanager.adoc[TaskSetManager]; lower priority gets Schedulable sooner or earlier stage wins.
* *FAIR* - more advanced FIXME
* *NONE* means no sub-queues

=== TaskSet's priority field and FIFO scheduling

A TaskSet has `priority` field that turns into the *priority* field's value of link:spark-tasksetmanager.adoc[TaskSetManager] (which is a Schedulable).

The `priority` field is used in `FIFOSchedulingAlgorithm` in which equal priorities give stages an advantage (not to say _priority_).

`FIFOSchedulingAlgorithm` is only used for `FIFO` scheduling mode in a `Pool` which is a Schedulable collection of `Schedulable`'s.

Effectively, the `priority` field is the job's id of the first job this stage was part of (for FIFO scheduling).

=== [[speculative-execution]] Speculative execution of tasks

*Speculative tasks* (also *speculatable tasks* or *task strugglers*) are tasks that run slower than most of the all tasks in a job.

*Speculative execution of tasks* is a health-check procedure that checks for tasks to be *speculated*, i.e. running slower in a stage than the median of all successfully completed tasks in a taskset. Such slow tasks will be re-launched in another worker. It will not stop the slow tasks, but run a new copy in parallel.

It is executed periodically by the TaskScheduler for link:spark-cluster.adoc[clustered deployment modes], when link:spark-tasksetmanager.adoc#tasksetmanager-settings[spark.speculation] is enabled (`true`).

With `spark.speculation` enabled, the following INFO message appears in the logs:

```
INFO Starting speculative execution thread
```

It is scheduled using *task-scheduler-speculation* daemon thread pool using `j.u.c.ScheduledThreadPoolExecutor` with core pool size `1`.

It is executed for link:spark-tasksetmanager.adoc#zombie-state[non-zombie TaskSetManagers] with more than one task to execute.

The process computes link:spark-tasksetmanager.adoc#tasksetmanager-settings[spark.speculation.quantile] of all the tasks and checks whether the number is greater than the number of tasks completed successfully.

You can find the DEBUG message in the logs:

```
DEBUG Checking for speculative tasks: minFinished =
```

It then computes the median duration of all the completed task length threshold for speculation to have it multiplied by link:spark-tasksetmanager.adoc#tasksetmanager-settings[spark.speculation.multiplier]. It has to be at least `100`.

In the logs at DEBUG level:

```
DEBUG Task length threshold for speculation:
```

For each active task for which there is only one copy running and the task takes more time than the threshold, it gets marked as *speculatable*.

In the logs at INFO level:

```
INFO Marking task %d in stage %s (on %s) as speculatable because it ran more than %.0f ms
```

The job with speculatable tasks should finish while speculative tasks are running, and it will leave these tasks running - no KILL command yet.

The check procedure is in link:spark-tasksetmanager.adoc[TaskSetManager.checkSpeculatableTasks] method.

1. How does Spark handle repeated results of speculative tasks since there are copies launched?

=== [[submitTasks]] submitTasks

Tasks (as a <<taskset, TaskSet>>) are submitted for execution using `submitTasks(taskSet: TaskSet)` method.

.TaskScheduler.submitTasks
image::images/taskscheduler-submitTasks.png[align="center"]

You should see the following INFO message in the logs:

```
INFO TaskSchedulerImpl: Adding task set 0.0 with 8 tasks
```

It creates a new link:spark-tasksetmanager.adoc[TaskSetManager] for the given TaskSet and the acceptable number of task failures.

CAUTION: FIXME There are other steps not included here.

It then calls `backend.reviveOffers()`.

TIP: Use `dag-scheduler-event-loop` thread to step through the code in a debugger.

=== [[resourceOffers]] resourceOffers

`resourceOffers(offers: Seq[WorkerOffer])` method is called by a cluster manager or `LocalEndpoint` for local mode to offer free resources available on the executors to run tasks on.

.TaskSchedulerImpl.resourceOffers under the hood
image::images/taskscheduler-resourceOffers.png[align="center"]

Consult link:spark-local.adoc#LocalBackend[LocalBackend] for Spark local mode.

A `WorkerOffer` is a 3-tuple with executor id, host, and free cores available.

For each offer, the method tracks hosts per executor id (using `executorIdToHost`) and sets `0` as the number of tasks running on the executor if there is no tasks running already (using `executorIdToTaskCount`). It also tracks executor id per host.

WARNING: FIXME BUG? Why is the executor id *not* added to `executorsByHost`?

`DAGScheduler.executorAdded(executorId, host)` is called for a new host.

WARNING: FIXME BUG? Why is `executorAdded` called for a new host added? Can't we have more executors on a host? The name of the method is misleading then.

CAUTION: FIXME a picture with `executorAdded` call from TaskSchedulerImpl to DAGScheduler.

FIXME Why is `getRackForHost` important?

It builds a list of tasks (using `TaskDescription`) to assign to each worker.

CAUTION: FIXME What does the line `val sortedTaskSets = rootPool.getSortedTaskSetQueue` mean? It uses no method's local variables. There can be many TaskSetManagers in the result.

`rootPool.getSortedTaskSetQueue` is called to build a collection of tasksets (as TaskSetManagers in `sortedTaskSets`).

For each taskset (represented by a TaskSetManager), the following DEBUG message is printed out to the logs:

```
DEBUG parentName: [taskSet.parent.name], name: [taskSet.name], runningTasks: [taskSet.runningTasks]
```

And if a new host was added to the pool (using `newExecAvail` - FIXME when exactly?), each TaskSetManager gets notified about new executor added (using `TaskSetManager.executorAdded()`). FIXME So what?

WARNING: FIXME BUG? Why is the name `newExecAvail` since it's called for a new host added? Can't we have more executors on a host? The name of the method could be misleading.

For each taskset in `sortedTaskSets`, different locality preferences are checked...FIXME

Check whether the number of cores in an offer is more than the number of cores needed for a task (using <<settings, spark.task.cpus>>).

When `resourceOffers` managed to launch a task, the internal field `hasLaunchedTask` is set.

CAUTION: FIXME Why is there a need for `hasLaunchedTask`? Can TaskSchedulerImpl launch more tasks later?

=== [[settings]] Settings

* `spark.task.maxFailures` (default: `4` for link:spark-cluster.adoc[cluster mode] and `1` for link:spark-local.adoc[local] except link:spark-local.adoc[local-with-retries]) - The number of individual task failures before giving up on the entire TaskSet and the job afterwards.
+
Internally, it is used in `org.apache.spark.scheduler.TaskSchedulerImpl` to initialize link:spark-tasksetmanager.adoc[TaskSetManager].
* `spark.task.cpus` (default: `1`) - how many CPUs to request per task in a SparkContext. You cannot have different number of CPUs per task in a single SparkContext.
* `spark.scheduler.mode` (default: `FIFO`) can be of any of `FAIR`, `FIFO`, or `NONE`. Refer to <<scheduling-mode, scheduling mode>>.
* `spark.speculation.interval` (default: `100ms`) - how often to check for speculative tasks.
* `spark.starvation.timeout` (default: `15s`) - Threshold above which Spark warns a user that an initial TaskSet may be starved.
