=== Spark's Execution model

Jobs, Tasks, Stages, Blocks in Spark

Explain task execution in Spark and understand Sparkâ€™s underlying execution model.

New vocabulary often faced in Spark UI

* *actions*
* *jobs* - triggered as a result of executing an action in a Spark application. Spark examines the graph of RDDs and creates an execution plan.
* *execution plan* - starts with the earliest RDDs (those with no dependencies on other RDDs or reference cached data) and ends with the RDD that produces the result of the action that has been called to execute.
* *stages* - transformations; a collection of tasks that execute the same code, each on separate subset of data. Each stage contains a sequence of transformations that can be completed without _shuffling_ the entire data set.
* *tasks* - units of physical execution that run parts of your Spark application

Jobs are at the top of the execution hierarchy.
