== [[SparkPlanner]] SparkPlanner -- Default Query Planner (with no Hive Support)

`SparkPlanner` is a link:spark-sql-catalyst-QueryPlanner.adoc[query planner] that transforms a link:spark-sql-LogicalPlan.adoc[logical plan] to a collection of link:spark-sql-SparkPlan.adoc[physical plans] with support for custom plan transformations.

NOTE: `SparkPlanner` extends link:spark-sql-catalyst-QueryPlanner.adoc#SparkStrategies[SparkStrategies].

[[transformations]]
.SparkPlanner's Plan Transformations (in alphabetic order)
[cols="1,2",options="header",width="100%"]
|===
| SparkStrategy
| Description

| link:spark-sql-SparkStrategy-Aggregation.adoc[Aggregation]
|

| link:spark-sql-SparkStrategy-BasicOperators.adoc[BasicOperators]
|

| link:spark-sql-SparkStrategy-DataSourceStrategy.adoc[DataSourceStrategy]
|

| link:spark-sql-SparkStrategy-DDLStrategy.adoc[DDLStrategy]
|

| link:spark-sql-SparkStrategy-FileSourceStrategy.adoc[FileSourceStrategy]
|

| `InMemoryScans`
|

| link:spark-sql-SparkStrategy-JoinSelection.adoc[JoinSelection]
|

| `SpecialLimits`
|
|===

`SparkPlanner` requires a link:spark-sparkcontext.adoc[SparkContext], a link:spark-sql-SQLConf.adoc[SQLConf], and a collection of `Strategy` objects (as `extraStrategies`) when created.

`SparkPlanner` defines `numPartitions` method that returns the value of link:spark-sql-SQLConf.adoc#spark.sql.shuffle.partitions[spark.sql.shuffle.partitions] for the number of partitions to use for link:spark-sql-joins.adoc[joins] and link:spark-sql-basic-aggregation.adoc[aggregations]. It is later used in link:spark-sql-SparkStrategy-BasicOperators.adoc[`BasicOperators` strategy] with `RepartitionByExpression` logical operator.

The required `strategies` collection uses `extraStrategies` extension point (defined as the argument to the constructor) and the predefined collection of `Strategy` objects.

`collectPlaceholders` required method returns a collection of `PlanLater` and the corresponding link:spark-sql-LogicalPlan.adoc[logical plans].

`prunePlans` required method does nothing, i.e. it returns what it gets directly.

[NOTE]
====
The order of the `SparkStrategy` transformations in `SparkPlanner` is as follows:

1. `extraStrategies`
2. link:spark-sql-SparkStrategy-FileSourceStrategy.adoc[FileSourceStrategy]
3. link:spark-sql-SparkStrategy-DataSourceStrategy.adoc[DataSourceStrategy]
4. link:spark-sql-SparkStrategy-DDLStrategy.adoc[DDLStrategy]
5. SpecialLimits
6. link:spark-sql-SparkStrategy-Aggregation.adoc[Aggregation]
7. link:spark-sql-SparkStrategy-JoinSelection.adoc[JoinSelection]
8. InMemoryScans
9. link:spark-sql-SparkStrategy-BasicOperators.adoc[BasicOperators]
====
