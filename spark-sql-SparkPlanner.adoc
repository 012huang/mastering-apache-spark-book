== [[SparkPlanner]] SparkPlanner -- Default Query Planner (no Hive Support)

`SparkPlanner` is a Catalyst link:spark-sql-catalyst-QueryPlanner.adoc[query planner] that converts a link:spark-sql-LogicalPlan.adoc[logical plan] to a collection of link:spark-sql-SparkPlan.adoc[physical plans] using <<strategies, execution planning strategies>> with support for <<extraStrategies, extra strategies>> (by means of <<experimentalMethods, ExperimentalMethods>>) and <<extraPlanningStrategies, extraPlanningStrategies>>.

`SparkPlanner` is <<creating-instance, created>> in:

1. link:spark-sql-BaseSessionStateBuilder.adoc[BaseSessionStateBuilder]
1. `HiveSessionStateBuilder`
1. Structured Streaming's `IncrementalExecution`

`SparkPlanner` is available as link:spark-sql-SessionState.adoc#planner[planner] of a `SessionState`.

[source, scala]
----
val spark: SparkSession = ...
spark.sessionState.planner
----

[[strategies]]
.SparkPlanner's Execution Planning Strategies (in execution order)
[cols="1,2",options="header",width="100%"]
|===
| SparkStrategy
| Description

| [[extraStrategies]] ``ExperimentalMethods``'s link:spark-sql-ExperimentalMethods.adoc#extraStrategies[extraStrategies]
|

| <<extraPlanningStrategies, extraPlanningStrategies>>
|

| link:spark-sql-SparkStrategy-FileSourceStrategy.adoc[FileSourceStrategy]
|

| link:spark-sql-SparkStrategy-DataSourceStrategy.adoc[DataSourceStrategy]
|

| `SpecialLimits`
|

| link:spark-sql-SparkStrategy-Aggregation.adoc[Aggregation]
|

| link:spark-sql-SparkStrategy-JoinSelection.adoc[JoinSelection]
|

| `InMemoryScans`
|

| link:spark-sql-SparkStrategy-BasicOperators.adoc[BasicOperators]
|
|===

NOTE: `SparkPlanner` extends link:spark-sql-catalyst-QueryPlanner.adoc#SparkStrategies[SparkStrategies] abstract class.

=== [[extraPlanningStrategies]] `extraPlanningStrategies` Method

CAUTION: FIXME

=== [[collectPlaceholders]] `collectPlaceholders` Method

CAUTION: FIXME

`collectPlaceholders` required method returns a collection of link:spark-sql-SparkStrategy.adoc#PlanLater[PlanLater] physical operators and the corresponding link:spark-sql-LogicalPlan.adoc[logical plans].

=== [[prunePlans]] `prunePlans` Method

CAUTION: FIXME

`prunePlans` required method does nothing, i.e. it returns what it gets directly.

=== [[pruneFilterProject]] `pruneFilterProject` Method

CAUTION: FIXME

=== [[creating-instance]] Creating SparkPlanner Instance

`SparkPlanner` takes the following when created:

* [[sparkContext]] link:spark-sparkcontext.adoc[SparkContext]
* [[conf]] link:spark-sql-SQLConf.adoc[SQLConf]
* [[experimentalMethods]] link:spark-sql-ExperimentalMethods.adoc[ExperimentalMethods]
