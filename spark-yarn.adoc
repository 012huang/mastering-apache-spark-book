== Spark on YARN

You can submit your Spark applications to a Hadoop YARN cluster using `yarn` <<masterURL, master URL>> in link:spark-yarn-client-yarnclientschedulerbackend.adoc[client] (default) or link:spark-yarn-cluster-yarnclusterschedulerbackend.adoc[cluster] deploy modes.

NOTE: Since Spark *2.0.0*, `yarn` master URL is the only proper master URL and you can use `--deploy-mode` to choose `client` or `cluster` modes.

In that sense, a Spark application is a YARN-compatible execution framework that can be deployed to a YARN cluster.

You need to <<yarn-support, build Spark distribution with YARN support>> to deploy applications to YARN clusters.

Spark on YARN supports <<multiple-application-attempts, multiple application attempts>>.

There are few settings that are specific to YARN (see <<settings, Settings>>).

TIP: You can start link:spark-submit.adoc[spark-submit] with `--verbose` command-line option to have some settings displayed, including YARN-specific. See <<spark-submit, spark-submit and YARN options>>.

=== [[spark-submit]] spark-submit and YARN options

When you submit your Spark applications using link:spark-submit.adoc[spark-submit] you can use the following YARN-specific command-line options:

* `--archives`
* `--executor-cores`
* `--keytab`
* `--num-executors`
* `--principal`
* link:spark-submit.adoc#queue[--queue]

TIP: Read about the corresponding settings in <<settings, Settings>> in this document.

=== [[yarn-support]] Spark with YARN support

You need to have Spark that link:spark-building-from-sources.adoc[has been compiled with YARN support], i.e. the class link:spark-yarn-client.adoc[org.apache.spark.deploy.yarn.Client] must be on the CLASSPATH.

Otherwise, you will see the following error in the logs and Spark will exit.

```
Error: Could not load YARN classes. This copy of Spark may not have been compiled with YARN support.
```

=== [[masterURL]] Master URL

Since Spark *2.0.0*, the only proper master URL is `yarn`.

```
./bin/spark-submit --master yarn ...
```

Before Spark 2.0.0, you could have used `yarn-client` or `yarn-cluster`, but it is now deprecated. When you use the master URL other than `yarn` you will see the following warning in the logs:

```
Warning: Master yarn-client is deprecated since 2.0. Please use master "yarn" with specified deploy mode instead.
```

=== [[keytab]] Keytab

CAUTION: FIXME

When a principal is specified a keytab must be specified, too.

The settings `spark.yarn.principal` and `spark.yarn.principal` will be set to respective values and `UserGroupInformation.loginUserFromKeytab` will be called with their values as input arguments.

=== [[settings]] Settings

CAUTION: FIXME Where and how are they used?

The following settings (aka system properties) are specific to Spark on YARN.

==== [[spark.yarn.queue]] spark.yarn.queue

CAUTION: FIXME Where is this used?

==== Others

* `spark.yarn.dist.jars`
* `spark.yarn.dist.files`
* `spark.yarn.dist.archives` -- See the corresponding <<spark-submit, --archives command-line option for spark-submit>>.
* `spark.yarn.principal` -- See the corresponding <<spark-submit, --principal command-line option for spark-submit>>.
* `spark.yarn.keytab` -- See the corresponding <<spark-submit, --keytab command-line option for spark-submit>>.

There are others which are supported:

* `spark.executor.memory`
* `spark.driver.memory`

[[spark.yarn.report.interval]]
* `spark.yarn.report.interval` (default: `1s`) is the interval (in milliseconds) between reports of the current app status. Used in link:spark-yarn-client.adoc#monitorApplication[Client.monitorApplication].

=== How it works

The Spark driver in Spark on YARN launches a number of executors. Each executor processes a partition of HDFS-based data.

=== YarnAllocator

`YarnAllocator` requests containers from the YARN ResourceManager and decides what to do with containers when YARN fulfils these requests. It uses YARN's `AMRMClient` APIs.

=== Misc

* `SPARK_YARN_MODE` property and environment variable
** `true` when `yarn-client` used for master URL
** It's set by Spark internally for YARN mode
* `org.apache.spark.deploy.yarn.YarnSparkHadoopUtil`
* YARN integration has some advantages, like link:spark-dynamic-allocation.adoc[dynamic allocation]. If you enable dynamic allocation, after the stage including InputSplits gets submitted, Spark will try to request an appropriate number of executors.
* On YARN, a Spark executor maps to a single YARN container.
* The memory in the YARN resource requests is `--executor-memory` + what's set for `spark.yarn.executor.memoryOverhead`, which defaults to 10% of `--executor-memory`.
* if YARN has enough resources it will deploy the executors distributed across the cluster, then each of them will try to process the data locally (`NODE_LOCAL` in Spark Web UI), with as many splits in parallel as you defined in link:spark-executor.adoc#spark.executor.cores[spark.executor.cores].

==== [[multiple-application-attempts]] Multiple Application Attempts

Spark on YARN supports *multiple application attempts* in link:spark-yarn-cluster-yarnclusterschedulerbackend.adoc[cluster mode].

CAUTION: FIXME

=== [[getInitialTargetExecutorNumber]] YarnSparkHadoopUtil.getInitialTargetExecutorNumber

[source, scala]
----
getInitialTargetExecutorNumber(
  conf: SparkConf,
  numExecutors: Int = DEFAULT_NUMBER_EXECUTORS): Int
----

`getInitialTargetExecutorNumber` calculates the initial number of executors for Spark on YARN. It varies by whether link:spark-dynamic-allocation.adoc#isDynamicAllocationEnabled[dynamic allocation is enabled or not].

NOTE: The default number of executors (aka `DEFAULT_NUMBER_EXECUTORS`) is `2`.

If dynamic allocation is enabled, the result is the value of link:spark-dynamic-allocation.adoc#spark.dynamicAllocation.initialExecutors[spark.dynamicAllocation.initialExecutors] or link:spark-dynamic-allocation.adoc#spark.dynamicAllocation.minExecutors[spark.dynamicAllocation.minExecutors] or `0`.

Otherwise, if dynamic allocation is disabled, the result is the value of link:spark-executor.adoc#spark.executor.instances[spark.executor.instances] setting or `SPARK_EXECUTOR_INSTANCES` environment variable, or the default value (of the input parameter `numExecutors`) `2`.

NOTE: It is used to calculate link:spark-yarn-yarnschedulerbackend.adoc#totalExpectedExecutors[totalExpectedExecutors] to link:spark-yarn-client-yarnclientschedulerbackend.adoc#totalExpectedExecutors[start Spark on YARN in client mode] or link:spark-yarn-cluster-yarnclusterschedulerbackend.adoc#totalExpectedExecutors[cluster mode].
