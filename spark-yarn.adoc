== Spark on YARN

=== Introduction to YARN

http://www.ibm.com/developerworks/library/bd-yarn-intro/index.html[Introduction to YARN] by Adam Kawa is an excellent introduction to YARN. Here are the most important facts to get you going.

* Hadoop 2.0 comes with *Yet Another Resource Negotiator (YARN)* that includes:
** *ResourceManager* runs as a master daemon and manages ApplicationMasters and NodeManagers.
** *ApplicationMaster* manages execution of tasks of an application and asks for containers for tasks.
** *NodeManager* offers resources (RAM, CPU) as containers.
** *NameNode*
** *Container* can run tasks, including ApplicationMasters.
* YARN manages distributed applications.
* YARN is for resource management.
* Hadoop for storing and processing large amount of data on a cluster of commodity hardware.

=== Misc

* `SPARK_YARN_MODE` property and environment variable
** `true` when `yarn-client` used for master URL
** It's set by Spark internally for YARN mode
* `yarn-cluster` and `yarn-client` modes
* `spark-submit --deploy-mode cluster`
* `org.apache.spark.deploy.yarn.YarnSparkHadoopUtil`
* YARN integration has some advantages, like link:spark-dynamic-allocation.adoc[dynamic allocation]. If you enable dynamic allocation, after the stage including InputSplits gets submitted, Spark will try to request an appropriate number of executors.
* On YARN, a Spark executor maps to a single YARN container.
* The memory in the YARN resource requests is `--executor-memory` + what's set for `spark.yarn.executor.memoryOverhead`, which defaults to 10% of `--executor-memory`.
* if YARN has enough resources it will deploy the executors distributed across the cluster, then each of them will try to process the data locally (`NODE_LOCAL` in Spark Web UI), with as many splits in parallel as you defined in `spark.executor.cores`.
* _"YarnClusterScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources"_
* Mandatory settings (`spark-defaults.conf`) for dynamic allocation:
+
```
spark.dynamicAllocation.enabled          true
spark.shuffle.service.enabled            true
```
* Optional settings for dynamic allocation (to tune it):
+
```
spark.dynamicAllocation.minExecutors     0
spark.dynamicAllocation.maxExecutors     N
spark.dynamicAllocation.initialExecutors 0
```
* `spark.dynamicAllocation.minExecutors` requires `spark.dynamicAllocation.initialExecutors`
* Review `spark.dynamicAllocation.*` settings
* YARN UI under scheduler - pools where Spark operates
* `spark.scheduler.mode=FIFO` on the Spark UI
