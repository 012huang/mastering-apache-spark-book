== Spark on YARN

=== Introduction to YARN

http://www.ibm.com/developerworks/library/bd-yarn-intro/index.html[Introduction to YARN] by *Adam Kawa* is an excellent introduction to YARN. Here are the most important facts to get you going.

* Hadoop 2.0 comes with *Yet Another Resource Negotiator (YARN)* that is _a generic cluster resource management framework that can run applications on a Hadoop cluster._ (see http://twill.incubator.apache.org/[Apache Twill])

* YARN is a bunch of processes, i.e:
** *ResourceManager* runs as a master daemon and manages ApplicationMasters and NodeManagers.
** *ApplicationMaster* is a lightweight process that coordinates the execution of tasks of an application and asks the ResourceManager for resource containers for tasks. It monitors tasks, restarts failed ones, etc. It can run any type of tasks, be them MapReduce tasks or Giraph tasks, or Spark tasks.
** *NodeManager* offers resources (memory and CPU) as resource containers.
** *NameNode*
** *Container* can run tasks, including ApplicationMasters.
* YARN manages distributed applications.
* Hadoop for storing and processing large amount of data on a cluster of commodity hardware.
* The Pre-YARN MapReduce engine - *MRv1* - was rewritten for YARN. It became yet another YARN distributed application called *MRv2*.

[CAUTION]
====
FIXME: Where is `ApplicationMaster.registerAM` used?

* Registering the ApplicationMaster with the RM.
* Contains a map with hints about where to allocate containers.
====

=== YarnAllocator

`YarnAllocator` requests containers from the YARN ResourceManager and decides what to do with containers when YARN fulfills these requests. It uses YARN's AMRMClient APIs.

=== ExecutorAllocationClient

`ExecutorAllocationClient` is a client class that communicates with the cluster manager to request or kill executors. This is currently supported only in YARN mode.

CAUTION: FIXME See the code and deduce its use.

=== Misc

* `SPARK_YARN_MODE` property and environment variable
** `true` when `yarn-client` used for master URL
** It's set by Spark internally for YARN mode
* `yarn-cluster` and `yarn-client` modes
* `spark-submit --deploy-mode cluster`
* `org.apache.spark.deploy.yarn.YarnSparkHadoopUtil`
* YARN integration has some advantages, like link:spark-dynamic-allocation.adoc[dynamic allocation]. If you enable dynamic allocation, after the stage including InputSplits gets submitted, Spark will try to request an appropriate number of executors.
* On YARN, a Spark executor maps to a single YARN container.
* The memory in the YARN resource requests is `--executor-memory` + what's set for `spark.yarn.executor.memoryOverhead`, which defaults to 10% of `--executor-memory`.
* if YARN has enough resources it will deploy the executors distributed across the cluster, then each of them will try to process the data locally (`NODE_LOCAL` in Spark Web UI), with as many splits in parallel as you defined in `spark.executor.cores`.
* _"YarnClusterScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources"_
* Mandatory settings (`spark-defaults.conf`) for dynamic allocation:
+
```
spark.dynamicAllocation.enabled          true
spark.shuffle.service.enabled            true
```
* Optional settings for dynamic allocation (to tune it):
+
```
spark.dynamicAllocation.minExecutors     0
spark.dynamicAllocation.maxExecutors     N
spark.dynamicAllocation.initialExecutors 0
```
* `spark.dynamicAllocation.minExecutors` requires `spark.dynamicAllocation.initialExecutors`
* Review `spark.dynamicAllocation.*` settings
* YARN UI under scheduler - pools where Spark operates
* `spark.scheduler.mode=FIFO` on the Spark UI
