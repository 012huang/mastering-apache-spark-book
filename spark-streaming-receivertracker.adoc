== ReceiverTracker

=== [[introduction]] Introduction

`ReceiverTracker` manages execution of all the link:spark-streaming-receivers.adoc[Receivers] of link:spark-streaming-dstreams.adoc#ReceiverInputDStream[ReceiverInputDStreams]. It uses link:spark-rpc.adoc[RPC environment] for communication with link:spark-streaming-receiversupervisors.adoc[ReceiverSupervisors].

NOTE: It is started when link:spark-streaming-jobscheduler.adoc[JobScheduler] starts.

It can only be started once and sets up the `ReceiverTracker` RPC endpoint (using <<ReceiverTrackerEndpoint, ReceiverTrackerEndpoint>>).

When `ReceiverTracker` starts, you should see the following INFO message in the logs:

```
INFO ReceiverTracker: Starting [receivers.length] receivers
```

`ReceiverTracker` can be in one of the following states:

* `Initialized` - it is in the state after having been instantiated.
* `Started` - <<ReceiverTrackerEndpoint, ReceiverTrackerEndpoint>> has been set up.
* `Stopping`
* `Stopped`

It posts <<ReceiverTrackerEndpoint-StartAllReceivers, StartAllReceivers>> to <<ReceiverTrackerEndpoint, ReceiverTracker RPC endpoint>>.

A successful startup of `ReceiverTracker` finishes with the following INFO message in the logs:

```
INFO ReceiverTracker: ReceiverTracker started
```

=== [[ReceiverTrackerEndpoint]] ReceiverTrackerEndpoint

CAUTION: FIXME

==== [[ReceiverTrackerEndpoint-StartAllReceivers]] StartAllReceivers

`StartAllReceivers(receivers)` is a local message sent by <<ReceiverTracker, ReceiverTracker>> when it starts (using `ReceiverTracker.launchReceivers()`).

It schedules receivers (using `ReceiverSchedulingPolicy.scheduleReceivers(receivers, getExecutors)`).

CAUTION: FIXME What does `ReceiverSchedulingPolicy.scheduleReceivers(receivers, getExecutors)` do?

It does _some_ bookkeeping.

CAUTION: FIXME What is _the_ bookkeeping?

It finally starts every receiver (using the helper method <<ReceiverTrackerEndpoint-startReceiver, ReceiverTrackerEndpoint.startReceiver>>).

===== [[ReceiverTrackerEndpoint-startReceiver]] ReceiverTrackerEndpoint.startReceiver

CAUTION: FIXME When is the method called?

`ReceiverTrackerEndpoint.startReceiver(receiver: Receiver[_], scheduledLocations: Seq[TaskLocation])` starts a `receiver` link:spark-streaming.adoc#Receiver[Receiver] at the given `Seq[TaskLocation]` locations.

CAUTION: FIXME When the scaladoc says https://github.com/apache/spark/blob/master/streaming/src/main/scala/org/apache/spark/streaming/scheduler/ReceiverTracker.scala#L543[_"along with the scheduled executors"_], does it mean that the executors are already started and waiting for the receiver?!

It defines an internal function (`startReceiverFunc`) to start `receiver` on a worker (in Spark cluster).

Namely, the internal `startReceiverFunc` function checks that the task attempt is `0`.

CAUTION: FIXME When could `TaskContext.get().attemptNumber()` be different than `0`?

It then starts a link:spark-streaming-receiversupervisors.adoc[ReceiverSupervisor] for `receiver` and keeps awaiting termination, i.e. once the task is run it does so until _a termination message_ comes from _some_ other external source). The task is a long-running task for `receiver`.

CAUTION: FIXME When does `supervisor.awaitTermination()` finish?

Having the internal function, it creates `receiverRDD` - an instance of `RDD[Receiver[_]]` - that uses link:spark-sparkcontext.adoc#makeRDD[SparkContext.makeRDD] with a one-element collection with the only element being `receiver`. When the collection of `TaskLocation` is empty, it uses exactly one partition. Otherwise, it distributes the one-element collection across the nodes (and potentially even executors) for `receiver`. The RDD has the name `Receiver [receiverId]`.

The Spark job's description is set to `Streaming job running receiver [receiverId]`.

CAUTION: FIXME What does `sparkContext.setJobDescription` actually do and how does this influence Spark jobs? It uses `ThreadLocal` so it assumes that a single thread will do a job?

Having done so, it submits a job (using link:spark-sparkcontext.adoc#submitJob[SparkContext.submitJob]) on the instance of `RDD[Receiver[_]]` with the function `startReceiverFunc` that runs `receiver`. It has link:spark-rdd-operations.adoc#FutureAction[SimpleFutureAction] to monitor `receiver`.

[NOTE]
====
The method demonstrates how you could use Spark Core as the distributed computation platform to launch _any_ process on clusters and let Spark handle the distribution.

_Very clever indeed!_
====

When it completes (successfully or not), `onReceiverJobFinish(receiverId)` is called, but only for cases when the tracker is fully up and running, i.e. started. When the tracker is being stopped or has already stopped, the following INFO message appears in the logs:

```
INFO Restarting Receiver [receiverId]
```

And a `RestartReceiver(receiver)` message is sent.

When there was a failure submitting the job, you should also see the ERROR message in the logs:

```
ERROR Receiver has been stopped. Try to restart it.
```

Ultimately, right before the method exits, the following INFO message appears in the logs:

```
INFO Receiver [receiver.streamId] started
```
