== RPC Environment (RpcEnv) on Netty

TIP: Read link:spark-rpc.adoc[RPC Environment (RpcEnv)] about the concept of RpcEnv in Spark.

The class https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rpc/netty/NettyRpcEnv.scala[org.apache.spark.rpc.netty.NettyRpcEnv] is the implementation of link:spark-rpc.adoc[RpcEnv] using http://netty.io/[Netty] - _"an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers & clients"_.

The Netty-based implementation uses the following properties:

* `spark.shuffle.io.numConnectionsPerPeer` (default: `1`)
* `spark.rpc.io.threads` (default: `0`) - the number of threads to use for the Netty client and server thread pools, and up to `8`.
** `spark.shuffle.io.serverThreads`
** `spark.shuffle.io.clientThreads`
* `spark.rpc.netty.dispatcher.numThreads` (default: the maximum number of processors available to JVM)
* `spark.rpc.connect.threads` (default: `64`) - used in cluster mode to communicate with a remote RPC endpoint

NettyRpcEnv uses the daemon single-thread scheduled thread pool `netty-rpc-env-timeout`.

```
"netty-rpc-env-timeout" #87 daemon prio=5 os_prio=31 tid=0x00007f887775a000 nid=0xc503 waiting on condition [0x0000000123397000]
```

Upon NettyRpcEnv startup, the following message is printed out as INFO in the logs:

```
INFO Utils: Successfully started service 'NettyRpcEnv' on port 0.
```

=== Netty RPC Endpoints

* `endpoint-verifier`

=== Message Dispatcher

A message dispatcher is responsible for routing RPC messages to the appropriate endpoint(s).

It uses the daemon fixed thread pool `dispatcher-event-loop` with `spark.rpc.netty.dispatcher.numThreads` threads for dispatching messages.

```
"dispatcher-event-loop-0" #26 daemon prio=5 os_prio=31 tid=0x00007f8877153800 nid=0x7103 waiting on condition [0x000000011f78b000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x0000000784ce81c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:218)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
```
