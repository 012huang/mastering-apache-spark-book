== Join Operators

.Joins
[frame="topbot",options="header",width="100%"]
|======================
| SQL | JoinType | Alias / joinType
| `CROSS` | `Cross` | `cross`
| `INNER` | `Inner` | `inner`
| `FULL OUTER` | `FullOuter` | `outer`, `full`, `fullouter`
| `LEFT ANTI` | `LeftAnti` | `leftanti`
| `LEFT OUTER` | `LeftOuter` | `leftouter`, `left`
| `LEFT SEMI` | `LeftSemi` | `leftsemi`
| `RIGHT OUTER` | `RightOuter` | `rightouter`, `right`
| `NATURAL` | `NaturalJoin` | Special case for `Inner`, `LeftOuter`, `RightOuter`, `FullOuter`
| `USING` | `UsingJoin` | Special case for `Inner`, `LeftOuter`, `LeftSemi`, `RightOuter`, `FullOuter`, `LeftAnti`
|======================

=== [[join]] `join` Methods

[source, scala]
----
join(right: Dataset[_]): DataFrame // <1>
join(right: Dataset[_], usingColumn: String): DataFrame // <2>
join(right: Dataset[_], usingColumns: Seq[String]): DataFrame // <3>
join(right: Dataset[_], usingColumns: Seq[String], joinType: String): DataFrame // <4>
join(right: Dataset[_], joinExprs: Column): DataFrame // <5>
join(right: Dataset[_], joinExprs: Column, joinType: String): DataFrame // <6>
----
<1> Inner join
<2> Inner join
<3> Inner join
<4> Equi-join with explicit join type
<5> Inner join
<6> Join with explicit join type

`join` joins two ``Dataset``s.

Internally, `join` creates a `DataFrame` for the current `SparkSession` and link:spark-sql-Join.adoc[`Join` logical operator].

CAUTION: FIXME

=== [[joinWith]] `joinWith` Method

[source, scala]
----
joinWith[U](other: Dataset[U], condition: Column): Dataset[(T, U)]  // <1>
joinWith[U](other: Dataset[U], condition: Column, joinType: String): Dataset[(T, U)]
----
<1> Inner join

CAUTION: FIXME

=== [[crossJoin]] `crossJoin` Method

[source, scala]
----
crossJoin(right: Dataset[_]): DataFrame
----

CAUTION: FIXME

=== [[broadcast-join]] Broadcast Join (aka Map-Side Join)

CAUTION: FIXME: Review `BroadcastNestedLoop`.

You can use link:spark-sql-functions.adoc#broadcast[broadcast] function to mark a link:spark-sql-dataset.adoc[Dataset] to be broadcast when used in a `join` operator.

NOTE: According to the article http://dmtolpeko.com/2015/02/20/map-side-join-in-spark/[Map-Side Join in Spark], *broadcast join* is also called a *replicated join* (in the distributed system community) or a *map-side join* (in the Hadoop community).

NOTE: At long last! I have always been wondering what a map-side join is and it appears I am close to uncover the truth!

And later in the article http://dmtolpeko.com/2015/02/20/map-side-join-in-spark/[Map-Side Join in Spark], you can find that with the broadcast join, you can very effectively join a large table (fact) with relatively small tables (dimensions), i.e. to perform a *star-schema join* you can avoid sending all data of the large table over the network.

`CanBroadcast` object matches a link:spark-sql-catalyst-LogicalPlan.adoc[LogicalPlan] with output small enough for broadcast join.

NOTE: Currently statistics are only supported for Hive Metastore tables where the command `ANALYZE TABLE [tableName] COMPUTE STATISTICS noscan` has been run.

It uses link:spark-sql-settings.adoc#autoBroadcastJoinThreshold[spark.sql.autoBroadcastJoinThreshold] setting to control the size of a table that will be broadcast to all worker nodes when performing a join.
