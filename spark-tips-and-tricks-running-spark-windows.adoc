== Running Spark Applications on Windows

Running Spark applications on Windows in general is no different than running it on other operating systems like Linux or macOS.

NOTE: A Spark application could be link:spark-shell.adoc[spark-shell] or your own custom Spark application.

What makes the huge difference between the operating systems is Hadoop that is used internally for file system access in Spark.

You may run into few minor issues when you are on Windows due to the way Hadoop works with Windows' POSIX-incompatible NTFS filesystem.

NOTE: You do not have to install Apache Hadoop to work with Spark or run Spark applications.

TIP: Read the Apache Hadoop project's https://wiki.apache.org/hadoop/WindowsProblems[Problems running Hadoop on Windows].

Among the issues is a permission error when running Spark Shell.

```
15/01/29 17:21:27 ERROR Shell: Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
  at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:318)
  at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:333)
  at org.apache.hadoop.util.Shell.<clinit>(Shell.java:326)
  at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
```

NOTE: You need to have Administrator rights on your laptop. All the following commands must be executed in a command-line window (`cmd`) ran as Administrator, i.e. using *Run As Administrator* option while executing `cmd`.

Download `winutils.exe` binary from https://github.com/steveloughran/winutils repository. You should select the version of Hadoop the Spark distribution was compiled with, e.g. use `hadoop-2.7.1` for Spark 2 (https://github.com/steveloughran/winutils/blob/master/hadoop-2.7.1/bin/winutils.exe[here is the direct link to `winutils.exe` binary]).

Save `winutils.exe` binary to a directory of your choice, e.g. `c:\hadoop\bin`.

Set `HADOOP_HOME` to reflect the directory with `winutils.exe` (without `bin`).

```
set HADOOP_HOME=c:\hadoop
```

Set `PATH` environment variable to include `%HADOOP_HOME%\bin` as follows:

```
set PATH=%HADOOP_HOME%\bin;%PATH%
```

TIP: Define `HADOOP_HOME` and `PATH` environment variables in Control Panel so any Windows program would use them.

Create `c:\tmp\hive` directory.

Execute the following command in `cmd` that you started using the option *Run As Administrator*.

```
winutils.exe chmod -R 777 \tmp\hive
```

Check the permissions:

```
winutils.exe ls \tmp\hive
```

Open `spark-shell` and...report SUCCESS!
