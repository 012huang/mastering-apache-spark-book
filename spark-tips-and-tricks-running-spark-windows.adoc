== Running Spark on Windows

Running Spark on Windows is not much different from other operating systems like Linux or Mac OS X, but there is one issue that people report often - a permission error when running Spark Shell.

```
15/01/29 17:21:27 ERROR Shell: Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
        at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:318)
        at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:333)
        at org.apache.hadoop.util.Shell.<clinit>(Shell.java:326)
        at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
```

Download https://github.com/steveloughran/winutils/raw/master/hadoop-2.6.0/bin/winutils.exe[winutils.exe] and save it to a directory, say `c:\hadoop\bin`.

Set `HADOOP_HOME`.

```
set HADOOP_HOME=c:\hadoop
```

Set `PATH` to include `%HADOOP_HOME%\bin` as follows:

```
set PATH=%HADOOP_HOME%\bin;%PATH%
```

Create `c:\tmp\hive` folder and execute the following command as Administrator (using "Run As Administrator" option while executing `cmd`):

```
winutils.exe chmod -R 777 \tmp\hive
```

You may want to check the permissions as follows:

```
winutils.exe ls \tmp\hive
```
