== Block Manager

*Block Manager* is a key-value store for blocks of data in Spark. Block Manager acts as a local cache that runs on every node in Spark cluster, i.e. the link:spark-driver.adoc[driver] and link:spark-executor.adoc[executors]. It provides interface for uploading and fetching blocks both locally and remotely using various stores, i.e. memory, disk, and off-heap. See <<stores, Stores>> in this document.

A `BlockManager` is a link:spark-blockdatamanager.adoc[BlockDataManager], i.e. manages the storage for blocks that can represent a cached RDD partition, an intermediate shuffle data, a broadcast data, etc.

*Cached blocks* are blocks with non-zero sum of memory and disk sizes.

It is created when a Spark application starts (as part of link:spark-sparkenv.adoc#create[SparkEnv.create]).

A BlockManager must be <<initialize,initialized>> before it is fully operable.

A BlockManager relies on the following services:

* link:spark-rpc.adoc[RpcEnv]
* link:spark-BlockManagerMaster.adoc[BlockManagerMaster]
* Serializer
* MemoryManager
* link:spark-service-mapoutputtracker.adoc[MapOutputTracker]
* link:spark-shuffle-manager.adoc[ShuffleManager]
* link:spark-blocktransferservice.adoc[BlockTransferService]
* SecurityManager

[TIP]
====
Enable `TRACE` logging level for `org.apache.spark.storage.BlockManager` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.storage.BlockManager=TRACE
```

Refer to link:spark-logging.adoc[Logging].
====

[TIP]
====
You may want to shut off WARN messages being printed out about the current state of blocks using the following line to cut the noise:

```
log4j.logger.org.apache.spark.storage.BlockManager=OFF
```
====

=== [[stores]] Stores

A *Store* is the place where blocks are held.

There are the following possible stores:

* `MemoryStore` for memory storage level.
* `DiskStore` for disk storage level.
* `ExternalBlockStore` for OFF_HEAP storage level.

==== [[MemoryStore]] MemoryStore

CAUTION: FIXME

==== [[DiskStore]] DiskStore

CAUTION: FIXME

=== [[doPutBytes]] doPutBytes

CAUTION: FIXME

=== [[doPutIterator]] doPutIterator

CAUTION: FIXME

=== [[removeBlock]] Removing Blocks From Memory and Disk (removeBlock method)

CAUTION: FIXME

=== [[removeRdd]] Removing RDD (removeRdd method)

CAUTION: FIXME

=== [[removeBroadcast]] Removing Broadcast (removeBroadcast method)

CAUTION: FIXME

=== [[getStatus]] Getting Block Status (getStatus method)

CAUTION: FIXME

=== [[dropFromMemory]] Removing Blocks From Memory Only (dropFromMemory method)

CAUTION: FIXME

=== [[initialize]] Initializing BlockManager (initialize method)

[source, scala]
----
initialize(appId: String): Unit
----

`initialize` method is called to initialize a `BlockManager` instance on the driver and the executors (see link:spark-sparkcontext.adoc#creating-instance[Creating SparkContext Instance] and link:spark-executor.adoc#creating-instance[Creating Executor Instance], respectively).

NOTE: The method must be called before a `BlockManager` can be considered fully operable.

It does the following:

1. It initializes link:spark-blocktransferservice.adoc[BlockTransferService].
2. It initializes a shuffle client, be it link:spark-shuffleclient.adoc#ExternalShuffleClient[ExternalShuffleClient] or link:spark-blocktransferservice.adoc[BlockTransferService].
3. It creates an instance of <<BlockManagerId, BlockManagerId>> given an executor id, host name and port for link:spark-blocktransferservice.adoc[BlockTransferService].
4. It creates the address of the server that serves this executor's shuffle files (using `shuffleServerId`)

If an external shuffle service is used, the following INFO appears in the logs:

```
INFO external shuffle service port = [externalShuffleServicePort]
```

It link:spark-BlockManagerMaster.adoc#registerBlockManager[registers itself to the driver's BlockManagerMaster] passing the <<BlockManagerId, BlockManagerId>>, the maximum memory (as `maxMemory`), and the <<BlockManagerSlaveEndpoint, BlockManagerSlaveEndpoint>>.

Ultimately, if the initialization happens on an executor and an external shuffle service is used, it registers to the external shuffle service.

While registering to the external shuffle service, you should see the following INFO message in the logs:

```
INFO Registering executor with local external shuffle service.
```

Using `shuffleClient` (that is link:spark-shuffleclient.adoc#ExternalShuffleClient[ExternalShuffleClient]) it calls `registerWithShuffleServer` synchronously using `shuffleServerId` and a ExecutorShuffleInfo (based on <<DiskBlockManager, DiskBlockManager>> for the executor and the short name of link:spark-shuffle-manager.adoc[ShuffleManager]).

Any issues while connecting to the external shuffle service are reported as ERROR messages in the logs:

```
ERROR Failed to connect to external shuffle server, will retry [attempts] more times after waiting [SLEEP_TIME_SECS] seconds...
```

=== [[reregister]] Re-registering Blocks to Driver (reregister method)

[source, scala]
----
reregister(): Unit
----

When is called, you should see the following INFO in the logs:

```
INFO BlockManager: BlockManager re-registering with master
```

It link:spark-BlockManagerMaster.adoc#registerBlockManager[registers itself to the driver's BlockManagerMaster] (just as it was when <<initialize, BlockManager was initializing>>). It passes the <<BlockManagerId, BlockManagerId>>, the maximum memory (as `maxMemory`), and the <<BlockManagerSlaveEndpoint, BlockManagerSlaveEndpoint>>.

CAUTION: FIXME Where is `maxMemory` used once passed to the driver?

`reregister` will then report all the local blocks to the link:spark-BlockManagerMaster.adoc[BlockManagerMaster].

You should see the following INFO message in the logs:

```
INFO BlockManager: Reporting [blockInfoManager.size] blocks to the master.
```

For each block metadata (in `BlockInfoManager`) it <<getCurrentBlockStatus, gets block current status>> and <<tryToReportBlockStatus, sends it to the BlockManagerMaster>>.

If there is an issue communicating to the link:spark-BlockManagerMaster.adoc[BlockManagerMaster], you should see the following ERROR message in the logs:

```
ERROR BlockManager: Failed to report [blockId] to master; giving up.
```

After the ERROR message, `reregister` stops reporting.

NOTE: `reregister` is called by link:spark-executor.adoc#heartbeats-and-active-task-metrics[Executor when it was told to re-register while sending heartbeats].

=== [[getCurrentBlockStatus]] Calculate Current Block Status (getCurrentBlockStatus method)

[source, scala]
----
getCurrentBlockStatus(blockId: BlockId, info: BlockInfo): BlockStatus
----

`getCurrentBlockStatus` returns the current `BlockStatus` of the `BlockId` block (with the block's current link:spark-rdd-caching.adoc#StorageLevel[StorageLevel], memory and disk sizes). It uses <<MemoryStore, MemoryStore>> and <<DiskStore, DiskStore>> for size and other information.

NOTE: Most of the information to build `BlockStatus` is already in `BlockInfo` except that it may not necessarily reflect the current state per <<MemoryStore, MemoryStore>> and <<DiskStore, DiskStore>>.

Internally, it uses the input `BlockInfo` to know about the block's storage level. If the storage level is not set (i.e. `null`), the returned `BlockStatus` assumes the link:spark-rdd-caching.adoc#StorageLevel[default NONE storage level] and the memory and disk sizes being `0`.

If however the storage level is set, `getCurrentBlockStatus` uses <<MemoryStore, MemoryStore>> or <<DiskStore, DiskStore>> to check whether the block is stored in the storages or not and request for their sizes in the storages respectively (using their `getSize` or assume `0`).

NOTE: It is acceptable that the `BlockInfo` says to use memory or disk yet the block is not in the storages (yet or anymore). The method will give current status.

NOTE: `getCurrentBlockStatus` is used when <<reregister, executor's BlockManager is requested to report the current status of the local blocks to the master>>, <<doPutBytes, saving a block to a storage>> or <<dropFromMemory, removing a block from memory only>> or <<removeBlock, both, i.e. from memory and disk>>.

=== [[BlockManagerSlaveEndpoint]] BlockManagerSlaveEndpoint

`BlockManagerSlaveEndpoint` is a link:spark-rpc.adoc#ThreadSafeRpcEndpoint[thread-safe RPC endpoint] for remote communication between executors and the driver.

CAUTION: FIXME the intro needs more love.

When a BlockManager is created, it sets up the RPC endpoint with the name *BlockManagerEndpoint[randomId]* and `BlockManagerSlaveEndpoint` as the class to handle <<BlockManagerSlaveEndpoint-messages, RPC messages>>.

[TIP]
====
Enable `DEBUG` logging level for `org.apache.spark.storage.BlockManagerSlaveEndpoint` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.storage.BlockManagerSlaveEndpoint=DEBUG
```
====

==== [[BlockManagerSlaveEndpoint-RemoveBlock]] RemoveBlock Message

[source, scala]
----
RemoveBlock(blockId: BlockId)
----

When a `RemoveBlock` message comes in, you should see the following DEBUG message in the logs:

```
DEBUG BlockManagerSlaveEndpoint: removing block [blockId]
```

It then calls <<removeBlock, BlockManager to remove `blockId` block>>.

NOTE: Handling `RemoveBlock` messages happens on a separate thread. See <<BlockManagerSlaveEndpoint-asyncThreadPool, BlockManagerSlaveEndpoint Thread Pool>>.

When the computation is successful, you should see the following DEBUG in the logs:

```
DEBUG BlockManagerSlaveEndpoint: Done removing block [blockId], response is [response]
```

And `true` response is sent back. You should see the following DEBUG in the logs:

```
DEBUG BlockManagerSlaveEndpoint: Sent response: true to [senderAddress]
```

In case of failure, you should see the following ERROR in the logs and the stack trace.

```
ERROR BlockManagerSlaveEndpoint: Error in removing block [blockId]
```

==== [[BlockManagerSlaveEndpoint-RemoveRdd]] RemoveRdd Message

[source, scala]
----
RemoveRdd(rddId: Int)
----

When a `RemoveRdd` message comes in, you should see the following DEBUG message in the logs:

```
DEBUG BlockManagerSlaveEndpoint: removing RDD [rddId]
```

It then calls <<removeRdd, BlockManager to remove `rddId` RDD>>.

NOTE: Handling `RemoveRdd` messages happens on a separate thread. See <<BlockManagerSlaveEndpoint-asyncThreadPool, BlockManagerSlaveEndpoint Thread Pool>>.

When the computation is successful, you should see the following DEBUG in the logs:

```
DEBUG BlockManagerSlaveEndpoint: Done removing RDD [rddId], response is [response]
```

And the number of blocks removed is sent back. You should see the following DEBUG in the logs:

```
DEBUG BlockManagerSlaveEndpoint: Sent response: [#blocks] to [senderAddress]
```

In case of failure, you should see the following ERROR in the logs and the stack trace.

```
ERROR BlockManagerSlaveEndpoint: Error in removing RDD [rddId]
```

==== [[BlockManagerSlaveEndpoint-RemoveShuffle]] RemoveShuffle Message

[source, scala]
----
RemoveShuffle(shuffleId: Int)
----

When a `RemoveShuffle` message comes in, you should see the following DEBUG message in the logs:

```
DEBUG BlockManagerSlaveEndpoint: removing shuffle [shuffleId]
```

If link:spark-service-mapoutputtracker.adoc[MapOutputTracker] was given (when the RPC endpoint was created), it calls link:spark-service-mapoutputtracker.adoc#unregisterShuffle[MapOutputTracker to unregister the `shuffleId` shuffle].

It then calls link:spark-shuffle-manager.adoc#unregisterShuffle[ShuffleManager to unregister the `shuffleId` shuffle].

NOTE: Handling `RemoveShuffle` messages happens on a separate thread. See <<BlockManagerSlaveEndpoint-asyncThreadPool, BlockManagerSlaveEndpoint Thread Pool>>.

When the computation is successful, you should see the following DEBUG in the logs:

```
DEBUG BlockManagerSlaveEndpoint: Done removing shuffle [shuffleId], response is [response]
```

And the result is sent back. You should see the following DEBUG in the logs:

```
DEBUG BlockManagerSlaveEndpoint: Sent response: [response] to [senderAddress]
```

In case of failure, you should see the following ERROR in the logs and the stack trace.

```
ERROR BlockManagerSlaveEndpoint: Error in removing shuffle [shuffleId]
```

==== [[BlockManagerSlaveEndpoint-RemoveBroadcast]] RemoveBroadcast Message

[source, scala]
----
RemoveBroadcast(broadcastId: Long)
----

When a `RemoveBroadcast` message comes in, you should see the following DEBUG message in the logs:

```
DEBUG BlockManagerSlaveEndpoint: removing broadcast [broadcastId]
```

It then calls <<removeBroadcast, BlockManager to remove the `broadcastId` broadcast>>.

NOTE: Handling `RemoveBroadcast` messages happens on a separate thread. See <<BlockManagerSlaveEndpoint-asyncThreadPool, BlockManagerSlaveEndpoint Thread Pool>>.

When the computation is successful, you should see the following DEBUG in the logs:

```
DEBUG BlockManagerSlaveEndpoint: Done removing broadcast [broadcastId], response is [response]
```

And the result is sent back. You should see the following DEBUG in the logs:

```
DEBUG BlockManagerSlaveEndpoint: Sent response: [response] to [senderAddress]
```

In case of failure, you should see the following ERROR in the logs and the stack trace.

```
ERROR BlockManagerSlaveEndpoint: Error in removing broadcast [broadcastId]
```

==== [[BlockManagerSlaveEndpoint-GetBlockStatus]] GetBlockStatus Message

[source, scala]
----
GetBlockStatus(blockId: BlockId)
----

When a `GetBlockStatus` message comes in, it responds with the result of <<getStatus, calling BlockManager about the status of `blockId`>>.

==== [[BlockManagerSlaveEndpoint-GetMatchingBlockIds]] GetMatchingBlockIds Message

[source, scala]
----
GetMatchingBlockIds(filter: BlockId => Boolean)
----

When a `GetMatchingBlockIds` message comes in, it responds with the result of <<getMatchingBlockIds, calling BlockManager for matching blocks for `filter`>>.

==== [[BlockManagerSlaveEndpoint-TriggerThreadDump]] TriggerThreadDump Message

When a `TriggerThreadDump` message comes in, a thread dump is generated and sent back.

==== [[BlockManagerSlaveEndpoint-asyncThreadPool]] BlockManagerSlaveEndpoint Thread Pool

`BlockManagerSlaveEndpoint` uses *block-manager-slave-async-thread-pool* daemon thread pool (`asyncThreadPool`) for some messages to talk to other Spark services, i.e. `BlockManager`, link:spark-service-mapoutputtracker.adoc[MapOutputTracker], link:spark-shuffle-manager.adoc[ShuffleManager] in a non-blocking, asynchronous way.

The reason for the async thread pool is that the block-related operations might take quite some time and to release the main RPC thread other threads are spawned to talk to the external services and pass responses on to the clients.

NOTE: `BlockManagerSlaveEndpoint` uses Java's https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ThreadPoolExecutor.html[java.util.concurrent.ThreadPoolExecutor].

=== [[broadcast]] Broadcast Values

When a new broadcast value is created, `TorrentBroadcast` - the default implementation of `Broadcast` - blocks are put in the block manager. See link:spark-service-broadcastmanager.adoc#TorrentBroadcast[TorrentBroadcast].

You should see the following `TRACE` message:

```
TRACE Put for block [blockId] took [startTimeMs] to get into synchronized block
```

It puts the data in the memory first and drop to disk if the memory store can't hold it.

```
DEBUG Put block [blockId] locally took [startTimeMs]
```

=== [[BlockManagerId]] BlockManagerId

FIXME

=== [[DiskBlockManager]] DiskBlockManager

DiskBlockManager creates and maintains the logical mapping between logical blocks and physical on-disk locations.

By default, one block is mapped to one file with a name given by its BlockId. It is however possible to have a block map to only a segment of a file.

Block files are hashed among the directories listed in `spark.local.dir` (or in `SPARK_LOCAL_DIRS` if set).

CAUTION: FIXME Review me.

=== [[execution-context]] Execution Context

*block-manager-future* is the execution context for...FIXME

=== [[metrics]] Metrics

Block Manager uses link:spark-metrics.adoc[Spark Metrics System] (via `BlockManagerSource`) to report metrics about internal status.

The name of the source is *BlockManager*.

It emits the following numbers:

* memory / maxMem_MB - the maximum memory configured
* memory / remainingMem_MB - the remaining memory
* memory / memUsed_MB - the memory used
* memory / diskSpaceUsed_MB - the disk used

=== Misc

The underlying abstraction for blocks in Spark is a `ByteBuffer` that limits the size of a block to 2GB (`Integer.MAX_VALUE` - see http://stackoverflow.com/q/8076472/1305344[Why does FileChannel.map take up to Integer.MAX_VALUE of data?] and https://issues.apache.org/jira/browse/SPARK-1476[SPARK-1476 2GB limit in spark for blocks]). This has implication not just for managed blocks in use, but also for shuffle blocks (memory mapped blocks are limited to 2GB, even though the API allows for `long`), ser-deser via byte array-backed output streams.

When a non-local executor starts, it initializes a `BlockManager` object for the `spark.app.id` id.

If a task result is bigger than the message frame size - `spark.akka.frameSize` - executors use the block manager to send the result back. Task results are configured using `spark.driver.maxResultSize` (default: `1g`).

=== [[settings]] Settings

* `spark.shuffle.service.enabled` (default: `false`) whether an external shuffle service is enabled or not. See link:spark-shuffle-manager.adoc#external-shuffle-service[External Shuffle Service].

* `spark.broadcast.compress` (default: `true`) whether to compress stored broadcast variables.

* `spark.shuffle.compress` (default: `true`) whether to compress stored shuffle output.

* `spark.rdd.compress` (default: `false`) whether to compress RDD partitions that are stored serialized.

* `spark.shuffle.spill.compress` (default: `true`) whether to compress shuffle output temporarily spilled to disk.
