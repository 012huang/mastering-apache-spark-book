== Repartition and RepartitionByExpression Logical Operators

<<Repartition, Repartition>> and <<RepartitionByExpression, RepartitionByExpression>> are link:spark-sql-LogicalPlan.adoc#UnaryNode[unary logical operators] (with a single child logical plan) that create a new `RDD` that has exactly <<numPartitions, numPartitions>> partitions.

The difference between <<Repartition, Repartition>> and <<RepartitionByExpression, RepartitionByExpression>> is that `Repartition` is the result of link:spark-sql-dataset-operators.adoc#coalesce[coalesce] or link:spark-sql-dataset-operators.adoc#repartition[repartition] operators (that a Spark developer has used explicitly in the code) while `RepartitionByExpression` is when a consumer of the output requires some specific ordering or distribution of the data.

`Repartition` and `RepartitionByExpression` are described by:

* [[shuffle]] `shuffle` flag
* [[numPartitions]] target number of partitions

NOTE: link:spark-sql-Optimizer.adoc#CollapseRepartition[CollapseRepartition] logical optimization collapses adjacent repartition operations.

NOTE: `Repartition` allows link:spark-sql-Optimizer.adoc#FoldablePropagation[FoldablePropagation] and link:spark-sql-Optimizer-PushDownPredicate.adoc[PushDownPredicate] logical optimizations to "push through".

NOTE: link:spark-sql-Optimizer-PropagateEmptyRelation.adoc[PropagateEmptyRelation] logical optimization may result in an empty link:spark-sql-LogicalPlan-LocalRelation.adoc[LocalRelation] for `Repartition`.

=== [[Repartition]] Repartition Logical Operator

NOTE: link:spark-sql-BasicOperators.adoc[BasicOperators] strategy maps `Repartition` to link:spark-sql-SparkPlan-ShuffleExchange.adoc[ShuffleExchange] (with `RoundRobinPartitioning` expression) or link:spark-sql-SparkPlan-CoalesceExec.adoc[CoalesceExec] physical operators for when shuffle is enabled or not, respectively.

=== [[RepartitionByExpression]] RepartitionByExpression Logical Operator

NOTE: link:spark-sql-BasicOperators.adoc[BasicOperators] strategy maps `RepartitionByExpression` to link:spark-sql-SparkPlan-ShuffleExchange.adoc[ShuffleExchange] physical operators with `HashPartitioning` expression.
