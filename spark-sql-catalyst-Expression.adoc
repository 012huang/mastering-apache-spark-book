== [[Expression]] Expression

`Expression` in Catalyst is described by the <<contract, Expression contract>> and represents a part of a structured query.

.Top-Level Expressions
[cols="1,2,2,1",options="header",width="100%"]
|===
| Name
| Scala Kind
| Behaviour
| Examples

| [[BinaryExpression]] `BinaryExpression`
| abstract class
|
|

| [[CodegenFallback]] `CodegenFallback`
| trait
|
|

| [[ExpectsInputTypes]] `ExpectsInputTypes`
| trait
|
|

| [[LeafExpression]] `LeafExpression`
| abstract class
|  Has no children, i.e. `children` method returns always an empty collection.
|

| [[NamedExpression]] `NamedExpression`
|
| Can later be referenced in a dataflow graph.
|

| <<Nondeterministic, Nondeterministic>>
| trait
|
|

| [[NonSQLExpression]] `NonSQLExpression`
| trait
| Expression with no SQL representation

Gives the only custom <<sql, sql>> method that is non-overridable (i.e. `final`).

When requested <<sql, SQL representation>>, `NonSQLExpression` transforms link:spark-sql-catalyst-Attribute.adoc[Attributes] to be ``PrettyAttribute``s to build text representation.
| link:spark-sql-ImperativeAggregate-ScalaUDAF.adoc[ScalaUDAF]

| [[TernaryExpression]] `TernaryExpression`
| abstract class
|
|

| [[UnaryExpression]] `UnaryExpression`
| abstract class
|
|

| [[Unevaluable]] `Unevaluable`
| trait
| Cannot be evaluated, i.e. `eval` and `doGenCode` are not supported and immediately report an `UnsupportedOperationException`

FIXME: What's the purpose?

a|

* `CurrentDatabase`
* link:spark-sql-Expression-WindowExpression.adoc[WindowExpression]
|===

=== [[contract]] Expression Contract

The contract of an expression in Spark SQL is described by the `Expression` abstract class.

[source, scala]
----
abstract class Expression extends TreeNode[Expression]
----

A `Expression` is a `TreeNode` that obeys the following contract:

. [[foldable]] May or may not be `foldable`.
. It may or may not be `deterministic`.
. It may or may not be `nullable`.
. It uses `references`.
. It can be ``eval``uated to a JVM object given a link:spark-sql-InternalRow.adoc[InternalRow].
. It can `genCode` to produce a `ExprCode`.
. It can `doGenCode` to produce a `ExprCode`.
. It may or may not be `resolved`.
. It is of `dataType` link:spark-sql-DataType.adoc[data type].
. It may or may not have `childrenResolved`.
. It has a `canonicalized` representation.
. It may or may not be `semanticEquals` given another `Expression`.
. It has a `semanticHash`.
. It can be <<checkInputDataTypes, checkInputDataTypes>>
. It has a `prettyName`.
. [[sql]] Can be represented in a `sql` text.

=== [[checkInputDataTypes]] `checkInputDataTypes` Method

CAUTION: FIXME

=== [[Nondeterministic]] `Nondeterministic` Expression

`Nondeterministic` expressions are non-deterministic and non-<<foldable, foldable>>, i.e. `deterministic` and `foldable` properties are disabled (i.e. `false`). They require explicit initialization before evaluation.

`Nondeterministic` expressions have two additional methods:

1. `initInternal` for internal initialization (called before `eval`)
2. `evalInternal` to ``eval``uate a link:spark-sql-InternalRow.adoc[InternalRow] into a JVM object.

NOTE: `Nondeterministic` is a Scala trait.

`Nondeterministic` expressions have the additional `initialized` flag that is enabled (i.e. `true`) after the other additional `initInternal` method has been called.

Examples of `Nondeterministic` expressions are `InputFileName`, `MonotonicallyIncreasingID`, `SparkPartitionID` functions and the abstract `RDG` (that is the base for `Rand` and `Randn` functions).

NOTE: `Nondeterministic` expressions are the target of `PullOutNondeterministic` logical plan rule.
